[{"content":"Base\ngo 常用命令 build: 编译包和依赖 clean: 移除对象文件 doc: 显示包或者符号的文档 env: 打印go的环境信息 bug: 启动错误报告 fix: 运行go tool fix fmt: 运行gofmt进行格式化 generate: 从processing source生成go文件 get: 下载并安装包和依赖 install: 编译并安装包和依赖 list: 列出包 run: 编译并运行go程序 test: 运行测试 tool: 运行go提供的工具 version: 显示go的版本 vet: 运行go tool vet 标识符的组成 1.标识符由数字、字母和下划线 (_) 组成。\n2.只能以字母和下划线 (_) 开头。\n3.标识符区分大小写。\nGo是一门区分大小写的语言 命名规则涉及变量、常量、全局函数、结构、接口、方法等的命名。\nGO语言从语法层面进行了以下限定：\n任何需要对外暴露的名字必须以大写字母开头，\n不需要对外暴露的则应该以小写字母开头。\n短变量声明只能在函数里使用。\n包名称 保持packāge的名字和目录保持一致，尽量采取有意义的包名，简短，有意义，尽量和标准库不要冲突。==包名应该为小写单词==，不要使用下线或者混合大小写。\npackage dao package service 文件命名 尽量采取有意义的文件名，简短，有意义，==应该为小写单词==，使用下划线分隔各个单词。\ncustomer_dao.go 结构体命名 ==采用驼峰命名法==，首字母根据访问控制大写或者小写\nstruct申明和初始化格式采用多行，例如下面：\ntype Customerorder struct{ Name string Address string } order:=CustomerOrder{\u0026#34;tom\u0026#34;,\u0026#34;北京海淀\u0026#34;} 错误处理 错误处理的原则就是不能丢弃任何有返回 err 的调用，不要使用_丢弃，必须全部处理。\n接收到错误，\n要么返回 err, 或者使用 log 记录下来尽早return , 一旦有错误发生，马上返回 尽量不要使用 panic ,除非你知道你在做什么， 错误描述如果是英文必须为小写，不需要标点结尾，采用独立的错误流进行处理. //正确写法 if err != nil{ //错误处理 return } //正常代码 单元测试 单元测试文件名命名规范为example_test.go测试用例的函数名称必须以Test开头，例如：TestExample\n每个重要的函数都要首先编写测试用例，测试用例和正规代码一起提交方便进行回归测试。\n常量 定义常量的语法\n定义一个常量使用const关键字，语法格式如下：\nconst constantName [type]=value\nconst: 定义常量关键字 constantName: 常量名称 type: 常量类型 value: 常量的值 iota iota比较特殊，可以被认为是一个可被编译器修改的常量，它默认开始值是g,每调用一次加1。遇到const关键字时被重置为0。 实例\npackage Base import \u0026#34;fmt\u0026#34; func Iota() { const ( a1 = iota a2 = iota a3 = iota ) fmt.Printf(\u0026#34;a1:%v\\n\u0026#34;, a1) fmt.Printf(\u0026#34;a2:%v\\n\u0026#34;, a2) fmt.Printf(\u0026#34;a3:%v\\n\u0026#34;, a3) } ======== a1:0 a2:1 a3:2 跳过1 func Iota() { const ( a1 = iota _ a3 = iota ) fmt.Printf(\u0026#34;a1:%v\\n\u0026#34;, a1) fmt.Printf(\u0026#34;a3:%v\\n\u0026#34;, a3) } ====== a1:0 a3:2 跳过2 func Iota() { const ( a1 = iota a2 = 100 a3 = iota ) fmt.Printf(\u0026#34;a1:%v\\n\u0026#34;, a1) fmt.Printf(\u0026#34;a2:%v\\n\u0026#34;, a2) fmt.Printf(\u0026#34;a3:%v\\n\u0026#34;, a3) } ====== a1:0 a2:100 a3:2 数据类型 指针、数组、切片类型\nfunc DataType() { num := 200 p := \u0026amp;num fmt.Printf(\u0026#34;%T\\n\u0026#34;, p) //\t*int 指针 arr := [3]int{1, 2, 3} fmt.Printf(\u0026#34;%T\\n\u0026#34;, arr) //[3]int 数组 arr1 := []int{1, 2, 3} fmt.Printf(\u0026#34;%T\\n\u0026#34;, arr1) //[]int 切片 } bool 类型 bool 类型：不能使用 0 和 非0 表示真假\n//\tBool b := 0 if b { //失败！ fmt.Println(b) } 数字类型 go 语言支持整型和浮点型数字，并且原生支持复数，其中位的运算采用补码。\n有基于架构的类型，例如：int、uint和uintptr。 这些类型的长度都是根据运行程序所在的操作系统类型所决定的：\nint和uint在32位操作系统上，它们均使用32位(4个字节)，在64位操作系统上，它们均使用64位(8个字节)。\nuintptr的长度被设定为足够存放一个指针即可。\ngo语言中没有float类型。(Go语言中只有float32和float64)\n没有 double 类型。\n与操作系统架构无关的类型都有固定的大小，并在类型的名称中就可以看出来。\n挺多的就不一一测了。\n//\t数字类型 var i8 int8 fmt.Printf(\u0026#34;%T %db %v~%v\\n\u0026#34;, i8, unsafe.Sizeof(i8), math.MinInt8, math.MaxInt8) //int8 1b -128~127 var i int fmt.Printf(\u0026#34;%T %db %v~%v\\n\u0026#34;, i, unsafe.Sizeof(i), math.MinInt, math.MaxInt) //int 8b -9223372036854775808~9223372036854775807 字符串 反引号可换行\n字符串连接 加号 使用 fmt.Sprintf() 使用 strings.Join() 使用 buffer.WriteString() //\tString str1 := \u0026#34;Hello,\u0026#34; str2 := \u0026#34;Tom\u0026#34; sprintf := fmt.Sprintf(\u0026#34;%s%s\u0026#34;, str1, str2) fmt.Println(sprintf) //\tstrings.Join join := strings.Join([]string{\u0026#34;Hello\u0026#34;, \u0026#34;Amy\u0026#34;}, \u0026#34;,\u0026#34;) fmt.Println(join)\t//\tbuffer.WriteString var buffer bytes.Buffer buffer.WriteString(\u0026#34;Hello\u0026#34;) buffer.WriteString(\u0026#34;,\u0026#34;) buffer.WriteString(\u0026#34;DaMing\u0026#34;) fmt.Printf(\u0026#34;%v\\n\u0026#34;, buffer.String()) 1、golang里面的字符串都是不可变的，每次运算都会产生一个新的字符串，所以会产生很多临时的无用的字符串，不仅没有用，还会给带来额外的负担，所以性能比较差。\n2、内部使用[]byte实现，不像直接运算符这种会产生很多临时的字符串，但是内部的逻辑比较复杂，有很多额外的判断，还用到了interface，所以性能也不是很好\n3、join会先根据字符串数组的内容，计算出一个拼接之后的长度，然后申请对应大小的内存，一个一个字符串填入，在已有一个数组的情况下，这种效率会很高，但是本来没有，去构造这个数据的代价也不小。\n4、这个比较理想，可以当成可变字符使用，对内存的增长也有优化，如果能预估字符串的长度，还可以用buffer.Grow()接口来设置capacity\n字符串切片操作 // 字符切片 str3 := \u0026#34;Hello world!\u0026#34; m, n := 3, 6 println(str3[m]) println(str3[:m]) // [0,3) println(str3[m:n]) println(str3[:n]) 字符串函数 格式化输出 https://pkg.go.dev/fmt?utm_source=godoc\nhttps://www.cnblogs.com/yinzhengjie/p/7680829.html\n通用：\n1 %v 值的默认格式表示。当输出结构体时，扩展标志（%+v）会添加字段名 2 %#v 值的Go语法表示 3 %T 值的类型的Go语法表示 4 %% 百分号 //\t格式化输出 user := User{ Name: \u0026#34;David\u0026#34;, Age: 20, Gender: \u0026#34;male\u0026#34;, } fmt.Printf(\u0026#34;%v\\n\u0026#34;, user) // {David 20 male} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, user) // Base.User{Name:\u0026#34;David\u0026#34;, Age:20, Gender:\u0026#34;male\u0026#34;} 布尔值：\n%t 单词true或false 整数：\n1 %b 表示为二进制 2 %c 该值对应的unicode码值[char] 3 %d 表示为十进制 4 %o 表示为八进制 5 %q 该值对应的单引号括起来的go语法字符字面值，必要时会采用安全的转义表示 6 %x 表示为十六进制，使用a-f 7 %X 表示为十六进制，使用A-F 8 %U 表示为Unicode格式：U+1234，等价于\u0026#34;U+%04X\u0026#34; 浮点数、复数的两个组分：\n1 %b 无小数部分、二进制指数的科学计数法，如-123456p-78；参见strconv.FormatFloat %e 科学计数法，如-1234.456e+78 %E 科学计数法，如-1234.456E+78 %f 有小数部分但无指数部分，如123.456 %F 等价于%f %g 根据实际情况采用%e或%f格式（以获得更简洁、准确的输出） 2 %G 根据实际情况采用%E或%F格式（以获得更简洁、准确的输出） 字符串和[]byte：\n%s 直接输出字符串或者[]byte %q 该值对应的双引号括起来的go语法字符串字面值，必要时会采用安全的转义表示 %x 每个字节用两字符十六进制数表示（使用a-f） %X 每个字节用两字符十六进制数表示（使用A-F） 指针：\n%p 表示为十六进制，并加上前导的0x 没有verb %u。整数如果是无符号类型自然输出也是无符号的。类似的，也没有必要指定操作数的尺寸（int8，int64）。\n宽度通过一个紧跟在百分号后面的十进制数指定，如果未指定宽度，则表示值时除必需之外不作填充。精度通过（可能有的）宽度后跟点号后跟的十进制数指定。如果未指定精度，会使用默认精度；如果点号后没有跟数字，表示精度为0。举例如下：\n%f: 默认宽度，默认精度 %9f 宽度9，默认精度 %.2f 默认宽度，精度2 %9.2f 宽度9，精度2 %9.f 宽度9，精度0 宽度和精度格式化控制的是Unicode码值的数量（不同于C的printf，它的这两个因数指的是字节的数量）。两者任一个或两个都可以使用\u0026rsquo;\u0026lsquo;号取代，此时它们的值将被对应的参数（按\u0026rsquo;\u0026lsquo;号和verb出现的顺序，即控制其值的参数会出现在要表示的值前面）控制，这个操作数必须是int类型。\n对于大多数类型的值，宽度是输出的最小字符数，如果必要是会用空格填充。对于字符串，宽度是输出字符数目的最低数量，如果必要会截断字符串。\n对于整数，宽度和精度都设置输出总长度。采用精度时表示右对齐并用0填充，而宽度默认表示用空格填充。\n对于浮点数，宽度设置输出总长度；精度设置小数部分长度（如果有的话），除了%g/%G，此时精度设置总的数字个数。例如，对数字123.45，格式%6.2f 输出123.45；格式%.4g输出123.5。%e和%f的默认精度是6，%g的默认精度是可以将该值区分出来需要的最小数字个数。\n对复数，宽度和精度会分别用于实部和虚部，结果用小括号包裹。因此%f用于1.2+3.4i输出(1.200000+3.400000i)。\n其它flag：\n1 + 总是输出数值的正负号；对%q（%+q）会生成全部是ASCII字符的输出（通过转义）； 2 - 在输出右边填充空白而不是默认的左边（即从默认的右对齐切换为左对齐）； 3 # 切换格式： 4 八进制数前加0（%#o），十六进制数前加0x（%#x）或0X（%#X），指针去掉前面的0x（%#p）； 5 对%q（%#q），如果strconv.CanBackquote返回真会输出反引号括起来的未转义字符串； 6 对%U（%#U），如果字符是可打印的，会在输出Unicode格式、空格、单引号括起来的go字面值； 7 \u0026#39; \u0026#39; 对数值，正数前加空格而负数前加负号； 8 对字符串采用%x或%X时（% x或% X）会给各打印的字节之间加空格； 9 0 使用0而不是空格填充，对于数值类型会把填充的0放在正负号后面； verb会忽略不支持的flag。例如，因为没有十进制切换模式，所以%#d和%d的输出是相同的。\n对每一个类似Printf的函数，都有对应的Print型函数，该函数不接受格式字符串，就效果上等价于对每一个参数都是用verb %v。另一个变体Println型函数会在各个操作数的输出之间加空格并在最后换行。\n不管verb如何，如果操作数是一个接口值，那么会使用接口内部保管的值，而不是接口，因此：\n1 /* 2 #!/usr/bin/env gorun 3 @author :yinzhengjie 4 Blog:http://www.cnblogs.com/yinzhengjie/tag/GO%E8%AF%AD%E8%A8%80%E7%9A%84%E8%BF%9B%E9%98%B6%E4%B9%8B%E8%B7%AF/ 5 EMAIL:y1053419035@qq.com 6 */ 7 8 package main 9 10 import \u0026#34;fmt\u0026#34; 11 12 func main() { 13 var name interface{} = \u0026#34;yinzhengjie\u0026#34; 14 fmt.Printf(\u0026#34;My name is %v !\\n\u0026#34;, name) 15 var age interface{} = 18 16 fmt.Printf(\u0026#34;I am [%d] years old。\u0026#34;,age) 17 } 18 19 20 21 #以上代码执行结果如下： 22 My name is yinzhengjie ! 23 I am [18] years old。 除了verb %T和%p之外；对实现了特定接口的操作数会考虑采用特殊的格式化技巧。按应用优先级如下：\n\\1. 如果操作数实现了Formatter接口，会调用该接口的方法。Formatter提供了格式化的控制。\n\\2. 如果verb %v配合flag #使用（%#v），且操作数实现了GoStringer接口，会调用该接口。\n如果操作数满足如下两条任一条，对于%s、%q、%v、%x、%X五个verb，将考虑：\n\\3. 如果操作数实现了error接口，Error方法会用来生成字符串，随后将按给出的flag（如果有）和verb格式化。\n\\4. 如果操作数具有String方法，这个方法将被用来生成字符串，然后将按给出的flag（如果有）和verb格式化。\n复合类型的操作数，如切片和结构体，格式化动verb递归地应用于其每一个成员，而不是作为整体一个操作数使用。因此%q会将[]string的每一个成员括起来，%6.2f会控制浮点数组的每一个元素的格式化。\n为了避免可能出现的无穷递归，如：\n1 type X string 2 func (x X) String() string { return Sprintf(\u0026#34;\u0026lt;%s\u0026gt;\u0026#34;, x) } 应在递归之前转换值的类型：\n1 func (x X) String() string { return Sprintf(\u0026#34;\u0026lt;%s\u0026gt;\u0026#34;, string(x)) } 显式指定参数索引：\n在Printf、Sprintf、Fprintf三个函数中，默认的行为是对每一个格式化verb依次对应调用时成功传递进来的参数。但是，紧跟在verb之前的[n]符号表示应格式化第n个参数（索引从1开始）。同样的在\u0026rsquo;*\u0026lsquo;之前的[n]符号表示采用第n个参数的值作为宽度或精度。在处理完方括号表达式[n]后，除非另有指示，会接着处理参数n+1，n+2……（就是说移动了当前处理位置）。例如：\n1 fmt.Sprintf(\u0026#34;%[2]d %[1]d\\n\u0026#34;, 11, 22) 会生成\u0026quot;22 11\u0026quot;，而：\n1 fmt.Sprintf(\u0026#34;%[3]*.[2]*[1]f\u0026#34;, 12.0, 2, 6), 等价于：\n1 fmt.Sprintf(\u0026#34;%6.2f\u0026#34;, 12.0), 会生成\u0026quot; 12.00\u0026quot;。因为显式的索引会影响随后的verb，这种符号可以通过重设索引用于多次打印同一个值：\n1 fmt.Sprintf(\u0026#34;%d %d %#[1]x %#x\u0026#34;, 16, 17) 会生成\u0026quot;16 17 0x10 0x11\u0026quot;\n格式化错误：\n如果给某个verb提供了非法的参数，如给%d提供了一个字符串，生成的字符串会包含该问题的描述，如下所例：\n1 错误的类型或未知的verb：%!verb(type=value) 2 Printf(\u0026#34;%d\u0026#34;, hi): %!d(string=hi) 3 太多参数（采用索引时会失效）：%!(EXTRA type=value) 4 Printf(\u0026#34;hi\u0026#34;, \u0026#34;guys\u0026#34;): hi%!(EXTRA string=guys) 5 太少参数: %!verb(MISSING) 6 Printf(\u0026#34;hi%d\u0026#34;): hi %!d(MISSING) 7 宽度/精度不是整数值：%!(BADWIDTH) or %!(BADPREC) 9 Printf(\u0026#34;%.*s\u0026#34;, 4.5, \u0026#34;hi\u0026#34;): %!(BADPREC)hi 10 没有索引指向的参数：%!(BADINDEX) 11 Printf(\u0026#34;%*[2]d\u0026#34;, 7): %!d(BADINDEX) 12 Printf(\u0026#34;%.[2]d\u0026#34;, 7): %!d(BADINDEX) 所有的错误都以字符串\u0026quot;%!\u0026ldquo;开始，有时会后跟单个字符（verb标识符），并以加小括弧的描述结束。\n如果被print系列函数调用时，Error或String方法触发了panic，fmt包会根据panic重建错误信息，用一个字符串说明该panic经过了fmt包。例如，一个String方法调用了panic(\u0026ldquo;bad\u0026rdquo;)，生成的格式化信息差不多是这样的：\n%!s(PANIC=bad) %!s指示表示错误（panic）出现时的使用的verb。\n运算符 自增 \u0026amp; 自减 不用于 表达式中。\n//num2:=num++ + 5 num3:=num + 5 fmt.Println(num3) 流程控制 if switch case ==可以多个、可以是表达式==\ncase 里面不需要 break ，若想继续下去 加 fallthrough\nfunc Control() { str := \u0026#34;b\u0026#34; checkGrade(str) } func checkGrade(grade string) { //\tswitch switch grade { case \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;: fmt.Printf(\u0026#34;Very Good\u0026#34;) case \u0026#34;c\u0026#34;: fmt.Printf(\u0026#34;Good\u0026#34;) default: fmt.Println(\u0026#34;normal\u0026#34;) } } 循环 for range 可以使用for range遍历数组、切片、字符串、map及通道(channel)。\n通过for range遍历的返回值有以下规律：\n1.数组、切片、字符串返回索引和值。 2.map返回键和值。 3.通道(channel)只返回通道内的值。\narr := [...]int{1, 2, 3} //[3]int //arr := []int{1, 2, 3} //[]int for i, v := range arr { fmt.Printf(\u0026#34;%v:%v\\n\u0026#34;, i, v) } fmt.Printf(\u0026#34;%T\\n\u0026#34;, arr) break：在循环中，跳出一层循环\ncontinue\ngoto\n数组 package Base import \u0026#34;fmt\u0026#34; func Array() { //\t数组列表初始化 var arr = [5]int{4, 5, 6, 7, 8} fmt.Println(arr) //\t使用 ... , 让他自行推断长度 var arr1 = [...]int{4, 5, 6, 7, 8, 9, 10} fmt.Println(arr1) //\t指定索引值的方式初始化 var arr2 = [...]int{0: 1, 2: 2, 3: 4} fmt.Println(arr2) } 切片 前面我们学习了数组，数组是固定长度，可以容纳相同数据类型的元素的集合。当长度固定时，使用还是带来一些限制，比如：我们申请的长度太大浪费内存，太小又不够用。\n鉴于上述原因，我们有了go语言的切片，可以把切片理解为，可变长度的数组，其实它底层就是使用数组实现的，增加了自动扩容功能。切片 (slice) 是一个拥有相同类型元素的可变长度的序列。\nfunc Slice() { //\t数组 var arr = [...]int{3, 4, 5, 6} fmt.Println(arr) //\t切片 var slice = []int{3, 4, 5, 6} fmt.Println(slice) // 通过 make var sliceByMake = make([]int, 5) fmt.Println(sliceByMake) println(\u0026#34;len\u0026#34;, len(sliceByMake)) println(\u0026#34;cap\u0026#34;, cap(sliceByMake)) } tips headNum := 6 // 这里创建了 6 个 0 var UidIntArr = make([]int, headNum) // right var UidIntArr = make([]int, 0, headNum) 添加、删除、Copy 删除：连续容器的元素删除无论在任何语言中，都要将删除点前后的元素移动到新的位置，随着元素的增加，这个过程将会变得极为耗时，因此，当业务需要大量、频繁地从一个切片中删除元素时，如果对性能要求较高的话，就需要考虑更换其他的容器了（如双链表等能快速从删除点删除元素）。\n//\tadd var slice1 = []int{1, 2, 3, 4, 5} fmt.Println(\u0026#34;before add\u0026#34;, slice1) slice1 = append(slice1, 6) slice1 = append(slice1, 6) slice1 = append(slice1, 6) fmt.Println(\u0026#34;after add\u0026#34;, slice1) //before add [1 2 3 4 5] //after add [1 2 3 4 5 6 6 6] //\tdelete fmt.Println(\u0026#34;before delete\u0026#34;, slice1) // 假设想删除 下标为 4 的元素 slice1 = append(slice1[:4], slice1[5:]...) //\u0026lt;======= fmt.Println(\u0026#34;after delete\u0026#34;, slice1) //\tcopy var slice3 = []int{1, 2, 3, 4, 5} var slice4 []int copy(slice4, slice3) fmt.Println(\u0026#34;slice4\u0026#34;, slice1) map map是一种key:value键值对的数据结构容器。map内部实现是哈希表(hash)。 map最重要的一点是通过key来快速检索数据，key类似于索引，指向数据的值。 map是引用类型的。\n初始化 func MapInit() { map1 := map[string]string{ \u0026#34;name\u0026#34;: \u0026#34;Tom\u0026#34;, \u0026#34;age\u0026#34;: \u0026#34;12\u0026#34;, \u0026#34;gender\u0026#34;: \u0026#34;male\u0026#34;, } fmt.Println(map1) //map[age:12 gender:male name:Tom] map2 := make(map[string]string, 5) map2[\u0026#34;name\u0026#34;] = \u0026#34;Amy\u0026#34; map2[\u0026#34;age\u0026#34;] = \u0026#34;13\u0026#34; map2[\u0026#34;gender\u0026#34;] = \u0026#34;female\u0026#34; fmt.Println(map2) //map[age:13 gender:female name:Amy] } 取值、遍历 //\t通过 key 取值 key := \u0026#34;name\u0026#34; value := map2[key] fmt.Println(\u0026#34;key = name , value = \u0026#34;, value) //key = name , value = Amy //\t判断一个map是否含有某个 key 值 value1, ok := map2[key] fmt.Printf(\u0026#34;key = name , isExist = %t , value = %v\\n\u0026#34;, ok, value1) //key = name , isExist = true , value = Amy //\t遍历 for k, v := range map2 { fmt.Printf(\u0026#34;%v:%v\\n\u0026#34;, k, v) } //name:Amy //age:13 //gender:female function go语言中函数特性\n1.go语言中有3种函数：普通函数、匿名函数（没有名称的函数）、方法（定义在struct上的函数）。\n2.go语言中不允许函数重载(overload),也就是说不允许函数同名。\n3.go语言中的函数不能嵌套函数，但可以嵌套匿名函数。\n4.函数是一个值，可以将函数赋值给变量，使得这个变量也成为函数。\n5.函数可以作为参数传递给另一个函数。\n6.函数的返回值可以是一个函数。\n7.函数调用的时候，如果有参数传递给函数，则先拷贝参数的副本，再将副本传递给函数。\n8.函数参数可以没有名称。\n返回值 1,return关键字中指定了参数时，返回值可以不用名称。如果return省略参数，则返回值部分必须带名称\n2.当返回值有名称时，必须使用括号包围，逗号分隔，即使只有一个返回值\n3.但即使返回值命名了，return中也可以强制指定其它返回值的名称，也就是说return的优先级更高\n4.命名的返回值是预先声明好的，在函数内部可以直接使用，无需再次声明。命名返回值的名称不能和函数参 数名称相同，否则报错提示变量重复定义\n5.return中可以有表达式，但不能出现赋值表达式，这和其它语言可能有所不同。例如return a+b是正确 的，但return c=a+b是错误的。\nfunc Function() { name, age := fun1() fmt.Printf(\u0026#34;name:%v,age:%v\\n\u0026#34;, name, age) } func fun1() (name string, age int) { name = \u0026#34;Amy\u0026#34; age = 19 return //\t等价于 ==\u0026gt; return name, age } 参数 值传递 【因为会创建函数副本】\n注意 ：map、slice、interface、channel这些数据类型本身就是指针类型的，所以就算是拷贝传值也是拷贝的指针，拷贝后的参数仍然指向底层数据结构，所以修改它们可能会影响外部数据结构的值。\nfunc Function() { a := []int{1, 2} fun2(a) fmt.Println(a[0]) // 100 } func fun2(a []int) { a[0] = 100 } 变长参数 func Function() { fun3(\u0026#34;Amy\u0026#34;, \u0026#34;Beijing\u0026#34;, \u0026#34;23\u0026#34;) } func fun3(args ...string) { for i, arg := range args { fmt.Printf(\u0026#34;%v:%v\\n\u0026#34;, i, arg) } } 0:Amy 1:Beijing 2:23 高阶函数 函数可以作为一个函数的参数、返回值。\n匿名函数 闭包 闭包可以理解成定义在一个函数内部的函数。在本质上，闭包是将函数内部和函数外部连接起来的桥梁。或者说是函数和其引用环境的组合体。 闭包指的是一个函数和与其相关的引用环境组合而成的实体。简单来说，==闭包=函数+引用环境==。\n变量f是一个函数并且它引用了其外部作用域中的x变量，此时f就是一个闭包。在f的生命周期内，变量x也一直有效。\nfunc Closure() { f := add() println(f(10)) println(f(20)) println(f(30)) // 10 // 30 // 60 //\t变量逃逸，从栈去到堆 } func add() func(int) int { var x int return func(y int) int { x += y return x } } 递归 函数内部调用函数自身的函数称为递归函数。 使用递归函数最重要的三点：\n1.递归就是自己调用自己。 2.必须先定义函数的退出条件，没有退出条件，递归将成为死循环。 3.go语言递归函数很可能会产生一大堆的goroutine,也很可能会出现栈空间内存谥出问题。\ndefer go语言中的defer语句会将其后面跟随的语句进行延迟处理。\n在defer归属的函数即将返回时，将延迟处理的语句按defer定义的逆序进行执行，\n也就是说，先被defer的语句最后被执行，最后被defer的语句，最先被执行。\ndefer\u0026rsquo;特性\n1.关键字defer用于注册延迟调用。 2.这些调用直到return前才被执。因此，可以用来做资源清理。 3.多个defer语句，按先进后出的方式执行。 4.defer语句中的变量，在defer声明时就决定了。\ndefer用途 1.关闭文件句柄 2.锁资源释放 3.数据库连接释放\ninit函数 golang有一个特殊的函数init函数，先于main函数执行，实现包级别的一些初始化操作。\ninit函数的主要特点 ·init函数先于main函数==自动执行==，不能被其他函数调用： ·init函数没有输入参数、返回值： ·每个包可以有多个init函数： ·包的每个源文件也可以有多个init函数，这点比较特殊： ·同一个包的init执行顺序，golang没有明确定义，编程时要注意程序不要依赖这个执行顺序。 ·不同包的it函数按照包，导入的依赖关系决定执行顺序。 golang初始化顺序 初始化顺序：变量初始化-\u0026gt;init()-\u0026gt;main()\n指针 G0语言中的函数传参都是值拷贝，当我们想要修改某个变量的时候，我们可以创建一个指向该变量地址的指针变 量。传递数据使用指针，而无须拷贝数据。\n类型指针不能进行偏移和运算。\nG0语言中的指针操作非常简单，只需要记住两个符号：\u0026amp;（取地址）和 *（根据地址取值）。\n指针地址和指针类型 每个变量在运行时都拥有一个地址，这个地址代表变量在内存中的位置。\nGo语言中使用\u0026amp;字符放在变量前面对变量进行取地址操作。\nGo语言中的值类型(int、float、bool、string、array、struct)都有对应的指针类型，如：*int、*int64、*string等。\n指针语法 一个指针变量指向了一个值的内存地址。\n(也就是我们声明了一个指针之后，可以像变量赋值一样，把一个值的内存地址放入到指针当中。)\n类似于变量和常量，在使用指针前你需要声明指针。指针声明格式如下：\nvar var_name *var-type var-type: 为指针类型 var-name: 为指针变量名 *：用于指定变量是作为一个指针 指针数组 表示数组里面的元素的类型是指针类型\n定义语法\nvar ptr [MAX]*int; 例子\nfunc Pointer() { var arr = [3]int{1, 2, 3} var pArr [3]*int for i := 0; i \u0026lt; len(arr); i++ { pArr[i] = \u0026amp;arr[i] } for i := 0; i \u0026lt; len(arr); i++ { println(pArr[i]) } //0xc000143f38 //0xc000143f40 //0xc000143f48 } 类型定义和类型别名 在介绍结构体之前，我们先来看看什么是类型定义和类型别名。\ngo语言类型定义 类型定义的语法\ntype NewType Type 实例\n//类型定义 type MyInt int //i为MyInt类型 var i MyInt i = 100 fmt.Printf(\u0026#34;i:%v i:%T\\n\u0026#34;, i, i) //\ti:100 i:Base.MyInt 类型别名 //类型别名 type MyInt1 = int var i1 MyInt1 i1 = 100 fmt.Printf(\u0026#34;i:%v i:%T\\n\u0026#34;, i1, i1) //\ti:100 i:int 结构体 go语言没有面向对象的概念了，但是可以使用结构体来实现面向对象编程的一些特性，例如：继承、组合等特 性。\n结构体的定义 结构体的定义和类型定义类似，只不过多了一个struct关键字：\ntype Person struct { id int name string age int email string } func Struct() { // 初始化 person1 := Person{ 2, \u0026#34;Amy\u0026#34;, 23, \u0026#34;hello@qq.com\u0026#34;, } person2 := Person{ id: 3, name: \u0026#34;Tom\u0026#34;, age: 20, email: \u0026#34;world@qq.com\u0026#34;, } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, person1) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, person2) } 结构体指针 var p1Point *Person p1Point = \u0026amp;person1 fmt.Printf(\u0026#34;%p\\n\u0026#34;, p1Point) // 通过 new var p2Point = new(Person) fmt.Printf(\u0026#34;%p\\n\u0026#34;, p2Point) 结构体作为函数参数 go结构体可以像普通变量一样，作为函数的参数，传递给函数，这里分为两种情况：\n直接传递结构体，这是是一个副本（拷贝），在函数内部不会改变外面结构体内容。 传递结构体指针，这时在函数内部，能够改变外部结构体内容。 直接传递结构体 这是值传递，将拷贝一份，不会改变原来的数据\n传递结构体指针 这就会修改原来的数据了\ntype Person struct { id int name string age int email string } func Struct() { // 初始化 person1 := Person{ 2, \u0026#34;Amy\u0026#34;, 23, \u0026#34;hello@qq.com\u0026#34;, } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, person1) showPerson(\u0026amp;person1) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, person1) //Base.Person{id:2, name:\u0026#34;Amy\u0026#34;, age:23, email:\u0026#34;hello@qq.com\u0026#34;} //Base.Person{id:2, name:\u0026#34;Amy\u0026#34;, age:1000, email:\u0026#34;hello@qq.com\u0026#34;} } func showPerson(person *Person) { person.age = 1000 } 嵌套结构体 go语言没有面向对象编程思想，也没有继承关系，但是可以通过结构体嵌套来实现这种效果。\n下面通过实例演示如何实现结构体嵌套，加入有一个人Person结构体，这个人还养了一个宠物Dog结构体。\ntype Dog struct { name string color string age int } type Person struct { dog Dog name string age int } 方法 gp语言没有面向对象的特性，也没有类对象的概念。\n但是，可以使用结构体来模拟这些特性，我们都知道面向对象里面有类方法等概念。\n我们也可以声明一些方法，属于某个结构体。\n方法的语法 Go中的方法，是一种特殊的函数，定义于struct之上（与struct关联、绑定），被称为struct的接受者(receiver))。\n通俗的讲，方法就是有接收者的函数。\n一个方法和一个函数非常相似，多了一个接受类型。\n语法格式如下： type mytype struct{} func (recv mytype)my_method(para)return_type {} func (recv *mytype)my_method(para)return_type {} mytype:定义一个结构体 recv:接受该方法的结构体(receiver) my-method:方法名称 para:参数列表 return-type:返回值类型 实例\ntype Person struct { name string age int } func (p Person) eat() { fmt.Printf(\u0026#34;%v is eating.\\n\u0026#34;, p.name) } func (p Person) sleep() { fmt.Printf(\u0026#34;%v is sleepy.\\n\u0026#34;, p.name) } func Struct() { person := Person{ name: \u0026#34;Tom\u0026#34;, age: 43, } person.eat() person.sleep() } 方法的注意事项 方法的receiver type并非一定要是struct类型，type定义的类型别名、slice、.map、channel、.func类型等都可 以。 struct结合它的方法就等价于面向对象中的类。只不过struct可以和它的方法分开，并非一定要属于同一个文 件，但必须属于同一个包。 方法有两种接收类型：(T Type)和(T*Type),它们之间有区别。 方法就是函数，所以Go中没有方法重载(overload)的说法，也就是说同一个类型中的所有方法名必须都唯一。 如果receiver是一个指针类型，则会自动解除引用。 方法和type是分开的，意味着实例的行为(behavior)和数据存储(field)是分开的，但是它们通过receiver建立起 关联关系。 方法接收者类型 结构体实例，有值类型和指针类型，那么方法的接收者是结构体，那么也有值类型和指针类型。\n区别就是接收者是否复制结构体副本。==值类型复制，指针类型不复制。==\npackage Base import \u0026#34;fmt\u0026#34; type Person struct { name string age int } func (p Person) modifyName() { p.name = \u0026#34;hello\u0026#34; } func (p *Person) modifyName1() { p.name = \u0026#34;hello\u0026#34; } func Struct() { person := Person{ name: \u0026#34;Tom\u0026#34;, age: 43, } fmt.Println(person) person.modifyName() fmt.Println(person) person.modifyName1() fmt.Println(person) //{Tom 43} //{Tom 43} //{hello 43} } 接口 接口像是一个公司里面的领导，他会定义一些通用规范，只设计规范，而不实现规范。\ngo语言的接口，是一种新的类型定义，它把所有的具有共性的方法定义在一起，任何其他类型只要实现了这些方 法就是实现了这个接口。\n语法格式和方法非常类似。\ndb_init package Dao import ( \u0026#34;log\u0026#34; \u0026#34;server/Model\u0026#34; \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/gorm/schema\u0026#34; ) type Manager interface { Register(userinfo Model.User) error GetUser(userId uint64) (Model.User, error) IsExist(username string) (Model.User, error) GetPostListByUserId(userId uint64) ([]Model.Post, error) UpdateProfileById(userId uint64, data *Model.User) error GetCommunityList() ([]Model.Community, error) StoreArticle(postInfo Model.Post) error GetList(latestTime int64) ([]Model.Post, error) GetPostById(postId int64) (Model.Post, error) GetUsernameById(AuthorId uint64) (author string, err error) GetCommunityNameById(CommunityId uint64) (CommunityName string, err error) DeletePostById(postId int64) error AddComment(comment *Model.Comment) } type manager struct { db *gorm.DB } var Mgr Manager func init() { dsn := \u0026#34;root:Admin666@tcp(127.0.0.1:3306)/blogserver?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{ NamingStrategy: schema.NamingStrategy{ SingularTable: true, }, }) if err != nil { log.Fatal(\u0026#34;Failed to init db:\u0026#34;, err) } Mgr = \u0026amp;manager{db: db} if err := db.AutoMigrate(\u0026amp;Model.Post{}); err != nil { log.Fatal(err) } } dao.user package Dao import ( \u0026#34;server/Model\u0026#34; ) func (mgr manager) Register(userinfo Model.User) error { result := mgr.db.Create(\u0026amp;userinfo) return result.Error } func (mgr manager) GetUser(userId uint64) (Model.User, error) { var user Model.User if err := mgr.db.Select(\u0026#34;user_id\u0026#34;, \u0026#34;username\u0026#34;, \u0026#34;company\u0026#34;, \u0026#34;user_page\u0026#34;, \u0026#34;user_introduce\u0026#34;, \u0026#34;position\u0026#34;, \u0026#34;created_at\u0026#34;). Where(\u0026#34;user_id=?\u0026#34;, userId).Find(\u0026amp;user).Error; err != nil { return user, err } return user, nil } func (mgr manager) IsExist(username string) (Model.User, error) { var userinfo Model.User result := mgr.db.Where(\u0026#34;username=?\u0026#34;, username).Find(\u0026amp;userinfo) return userinfo, result.Error } func (mgr manager) UpdateProfileById(userId uint64, data *Model.User) error { var userinfo Model.User var maps = make(map[string]interface{}) maps[\u0026#34;username\u0026#34;] = data.Username maps[\u0026#34;user_page\u0026#34;] = data.UserPage maps[\u0026#34;company\u0026#34;] = data.Company maps[\u0026#34;user_introduce\u0026#34;] = data.UserIntroduce maps[\u0026#34;position\u0026#34;] = data.Position err := mgr.db.Model(\u0026amp;userinfo).Where(\u0026#34;user_id = ? \u0026#34;, userId).Updates(maps).Error return err } 接口和类型的关系 1.一个类型可以实现多个接口 2.多个类型可以实现同一个接口（多态）\n一个类型实现多个接口\n例如：有一个Player接口可以播放音乐，有一个Video接口可以播放视频，\n一个手机Mobile实现这两个接口，既可以播放音乐，又可以播放视频。\n接口嵌套 package Base import \u0026#34;fmt\u0026#34; type Fly interface { FlyFunc() } type Swim interface { SwimFunc() } type FlyFish interface { Fly Swim } type Fish struct { } func (f Fish) FlyFunc() { fmt.Println(\u0026#34;Fish is flying.\u0026#34;) } func (f Fish) SwimFunc() { fmt.Println(\u0026#34;Fish is swimming.\u0026#34;) } func Interface() { var ff FlyFish // 此处如果不实现方法会报错 ff = Fish{} ff.SwimFunc() ff.FlyFunc() } 通过接口实现OCP设计原则 面向对象的可复用设计的第一块基石，便是所谓的”开-闭“原则(Open-Closed Principle,常缩写为OCP)。\n虽然，go不是面向对象语言，但是也可以模拟实现这个原则。\n实例 接口:\n特殊的数据类型\n方法定义的集合\n方法名(形参类型)返回值类型\n提高代码的复用率\n接口本身不能绑定方法\n保存的是：值+原始类型\n5.2.2 实现\n一个类型实现了接口的所有方法\n即实现了该接口\ngo中无需“implements”关键字\n5.2.3 类型选择\nswitch…case + interface.(type)\n.(type)不能在 switch…case 外使用\n5.2.4 类型断言\n还原为原始类型 interface.(Type)\n如果接口没有保存类型，则会报错\n可返回两个值\nvalue, ok := interface.(Type)\n5.2.5 空接口\ninterface{}\n空接口可保存任何类型\n5.2.6 nil问题\nnil 值：有类型没有值，接口本身并不是 nil，可以处理\nnil 接口：即没有保存值，也没有保存类型，使用时会报错\n//5.2 接口 type textMes struct { Type string Text string } func (tm *textMes) setText() { tm.Text = \u0026#34;hello\u0026#34; } type imgMes struct { Type string Img string } func (im *imgMes) setImg() { im.Img = \u0026#34;清明上河图\u0026#34; } type Mes interface { setType() } func (tm *textMes) setType() { tm.Type = \u0026#34;文字消息\u0026#34; } func (im *imgMes) setType() { im.Type = \u0026#34;图片消息\u0026#34; } func SendMes(m Mes) { m.setType() switch mptr := m.(type) { case *textMes: mptr.setText() case *imgMes: mptr.setImg() } fmt.Println(\u0026#34;m=\u0026#34;, m) } func Interface() { tm := textMes{} SendMes(\u0026amp;tm) im := imgMes{} SendMes(\u0026amp;im) var n1 int = 1 n1interface := interface{}(n1) n2, ok := n1interface.(int) if ok { fmt.Println(\u0026#34;n2=\u0026#34;, n2) } else { fmt.Println(\u0026#34;类型断言失败\u0026#34;) } } 继承 golang本质上没有ocp的概念，也没有继承的概念，但是可以通过结构体嵌套实现这个特性。\ngolang 中的继承是通过结构体中的==匿名字段==来实现\n例：定义一个 BaseNum 对象 (结构体)，作为父类，Add 和Sub 对象(结构体)中包含了BaseNum 匿名字段， 此时 Add 和Sub 就是BaseNum的子类\ntype BaseNum struct { num1 int num2 int } // BaseNum 即为父类型名称 type Add struct { BaseNum } //加法子类, 定义加法子类的主要目的, 是为了定义对应子类的方法 type Sub struct { BaseNum } //减法子类 构造函数 golang没有构造函数的概念，可以使用函数来模拟构造函数的的功能。\npackage Base import \u0026#34;fmt\u0026#34; type Person1 struct { name string age int } func NewPerson(name string, age int) (*Person1, error) { if name == \u0026#34;\u0026#34; { return nil, fmt.Errorf(\u0026#34;name不能为空\u0026#34;) } if age \u0026lt; 0 { return nil, fmt.Errorf(\u0026#34;age不能小于g\u0026#34;) } return \u0026amp;Person1{name: name, age: age}, nil } func Constructor() { person, err := NewPerson(\u0026#34;tom\u0026#34;, 20) if err != nil { fmt.Printf(\u0026#34;err:%v\\n\u0026#34;, err) } fmt.Printf(\u0026#34;person:%v\\n\u0026#34;, *person) } 包管理工具go module go modules是golang1.11新加的特性，用来管理模块中包的依赖关系。\ngo mod使用方法\n初始化模块\tgo mod init\u0026lt;项目模块名称\u0026gt;\n依赖关系处理，根据go.mod文件\tgo mod tidy\n将依赖包复制到项目下的vendor目录\tgo mod vendor\n如果包被屏蔽（墙），可以使用这个命令，随后使用go build-mod=vendor编译\n显示依赖关系\tgo list -m all\n显示详细依赖关系\tgo list -m -json all\n下载依赖\tgo mod download [path@version] [path@version]是非必写的\n并发编程-\u0026gt;协程 Golang中的并发是函数相互独立运行的能力。Goroutines是并发运行的函数。\nGolang提供了Goroutines作为并发处理操作的一种方式。\n创建一个协程非常简单，就是在一个任务函数前面添加一个go关键字：\ngo task() Q1 select …… case //5.3 协程 var ( c int lock sync.Mutex ) func PrimeNum(n int) { for i := 2; i \u0026lt; n; i++ { if n%i == 0 { return } } fmt.Printf(\u0026#34;%v\\t\u0026#34;, n) lock.Lock() c++ lock.Unlock() } func Goroutine() { for i := 2; i \u0026lt; 100001; i++ { go PrimeNum(i) } var key string fmt.Scanln(\u0026amp;key) fmt.Printf(\u0026#34;\\n共找到%v个素数\\n\u0026#34;, c) } //5.4 channel func pushNum(c chan int) { for i := 0; i \u0026lt; 100; i++ { c \u0026lt;- i } close(c) } func pushPrimeNum(n int, c chan int) { for i := 2; i \u0026lt; n; i++ { if n%i == 0 { return } } c \u0026lt;- n } func Channel() { var c1 chan int = make(chan int) go pushNum(c1) // for { // v, ok := \u0026lt;-c1 // if ok { // fmt.Printf(\u0026#34;%v\\t\u0026#34;, v) // } else { // break // } // } for v := range c1 { fmt.Printf(\u0026#34;%v\\t\u0026#34;, v) } var c2 chan int = make(chan int, 100) for i := 2; i \u0026lt; 100001; i++ { go pushPrimeNum(i, c2) } Print: for { select { case v := \u0026lt;-c2: fmt.Printf(\u0026#34;%v\\t\u0026#34;, v) default: fmt.Println(\u0026#34;所有素数已经找到\u0026#34;) break Print } } } 在 Go 编程语言中，select 语句用于在多个通道操作中进行选择。它可以在多个通道上等待数据到达或操作完成，并根据情况执行相应的操作。select 的结构如下：\nselect { case \u0026lt;-channel1: // 执行 channel1 数据到达时的操作 case data := \u0026lt;-channel2: // 执行 channel2 数据到达时的操作，并将数据存储在 data 变量中 case channel3 \u0026lt;- data: // 执行将 data 发送到 channel3 的操作 default: // 当没有任何通道操作准备就绪时执行的操作 } 在您提供的代码中，您使用了 select 来从通道 c2 中接收数据，同时还设置了一个 default 分支。让我对您的代码进行解释：\n首先，您创建了一个缓冲通道 c2，并启动了一系列 goroutine，每个 goroutine 负责将素数推送到 c2 通道。 然后，使用一个无限循环，不断地执行 select 语句。 在 select 语句中，您使用了一个 case 分支，该分支尝试从 c2 通道接收一个整数。如果 c2 通道中有数据，它会执行相应的操作，将接收到的整数打印出来。 您还使用了一个 default 分支，这是当没有通道操作准备就绪时执行的分支。在这种情况下，它会输出 \u0026ldquo;所有素数已经找到\u0026rdquo;，并通过 break Print 语句跳出 for 循环。 总结来说，您的代码通过多个并发的 goroutine 计算素数并推送到通道中，然后使用 select 语句从通道中接收数据并进行处理。select 的作用在于允许您同时等待多个通道的数据到达，哪个通道有数据，就执行相应的操作。\n那这段代码没有 select case 可以吗？\n当您使用 select 时，是因为您希望能够同时监视多个通道，并在其中任何一个通道就绪时执行相应的操作。在您的代码示例中，您使用 select 来从通道 c2 接收数据，并在没有数据可接收时输出提示。\n如果您不需要同时监视多个通道，而只是希望从单个通道中接收数据并执行相应的操作，那么是可以省略 select 的。您可以直接使用通道的阻塞接收操作，例如：\nfor { v, ok := \u0026lt;-c2 if !ok { fmt.Println(\u0026#34;所有素数已经找到\u0026#34;) break } fmt.Printf(\u0026#34;%v\\t\u0026#34;, v) } 在这个循环中，v, ok := \u0026lt;-c2 将从通道 c2 接收数据，并将数据存储在变量 v 中。同时，ok 表示通道是否关闭，如果通道关闭了，就不再有数据可以接收了。\n然后，您可以检查 ok 的值，如果为 false，就输出提示信息并跳出循环。否则，继续执行打印操作。\n所以，您可以根据自己的需求，选择使用带有 select 的并发操作，或者直接使用通道的阻塞接收操作。\n并发编程-\u0026gt;通道channel Go提供了一种称为通道的机制，用于在==goroutine之间==共享数据。\n当您作为goroutine执行并发活动时，需要在goroutine之间共享资源或数据，通道充当goroutine之间的管道（管道）并提供一种机制来保证同步交换。需要在声明通道时指定数据类型。我们可以共享内置、命名、结构和引用类型的值和指针。数据在通道上传递：在 任何给定时间只有一个goroutine可以访问数据项：因此按照设计不会发生数据竞争。\n根据数据交换的行为，有两种类型的通道：无缓冲通道和缓冲通道。\n无缓冲通道用于执行goroutine之间的同步通信，而缓冲通道用于执行异步通信。\n无缓冲通道保证在发送和接收发生的瞬间执行两个goroutine之间的交换。缓冲通道没有这样的保证。\n无缓冲通道（Unbuffered Channel）和缓冲通道（Buffered Channel）是 Go 语言中的两种通道类型，它们在使用方式和适用场景上有一些区别。\n无缓冲通道：\n无缓冲通道是指在发送数据到通道时，发送方会被阻塞直到接收方接收数据。同样，在接收数据时，接收方会被阻塞直到发送方发送数据。这种通道保证了数据的同步传输，发送和接收是紧密耦合的。无缓冲通道的声明方式为 make(chan T)。\n适用场景：\n在并发编程中，用于协调两个 goroutine 之间的同步操作。 当确保发送方和接收方同步工作很重要时，可以使用无缓冲通道。 缓冲通道：\n缓冲通道允许在通道中存储一定数量的数据，当通道中的数据数量达到缓冲区大小时，发送方才会被阻塞。只有在通道满了时，发送方才会被阻塞。同样，当通道中没有数据时，接收方才会被阻塞。缓冲通道的声明方式为 make(chan T, capacity)。\n适用场景：\n在解耦发送方和接收方的情况下，允许发送方发送数据到通道，然后继续执行其他操作，而不必等待接收方。 在生产者-消费者模式中，可以使用缓冲通道来平衡生产者和消费者之间的速度差异 通道由make函数创建，该函数指定chan关键字和通道的元素类型。\n这是创建无缓冲和缓冲通道的代码块：\n语法\nUnbuffered:=make(chan int)\t//整型无缓冲通道 buffered:=make(chan int,10)\t//整型有缓冲通道 使用内置函数make创建无缓冲和缓冲通道。\nmake的第一个参数需要关键字chan,然后是通道允许交换的数据类型。\npackage Base import ( \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) var channel = make(chan int) func send() { rand.Seed(time.Now().UnixNano()) random := rand.Intn(10) println(\u0026#34;随机值：\u0026#34;, random) time.Sleep(2 * time.Second) channel \u0026lt;- random } func GoRoutine() { defer close(channel) go send() println(\u0026#34;wait...\u0026#34;) receive := \u0026lt;-channel println(\u0026#34;接收值：\u0026#34;, receive) println(\u0026#34;end...\u0026#34;) } channel 遍历 package Base func Channel() { c := make(chan int) go func() { for i := 0; i \u0026lt; 5; i++ { c \u0026lt;- i } close(c) }() for v := range c { println(v) } } 并发编程-\u0026gt;WaitGroup实现同步 查看添加WaitGroup和不添加WaitGroup的区别\npackage Base import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var wg sync.WaitGroup func showMsg(i int) { defer wg.Done() fmt.Println(i) } func GoRoutine() { for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go showMsg(i) } wg.Wait() } // StuData 请求参数验证结构 type StuData struct { File *multipart.FileHeader `form:\u0026#34;file\u0026#34; binding:\u0026#34;required\u0026#34;` } func dealStuData(row []string, buff chan map[string]string, wg *sync.WaitGroup, userList chan map[string]string, errData chan []string) { errMsg := make(map[string]string, 0) // 不能提交空数据 for _, val := range row { if val == \u0026#34;\u0026#34; { errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = \u0026#34;数据不能为空\u0026#34; errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } if row[common.EStuGender] != \u0026#34;男\u0026#34; \u0026amp;\u0026amp; row[common.EStuGender] != \u0026#34;女\u0026#34; { errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = \u0026#34;性别格式错误\u0026#34; errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // 比对学院代码是否正确 org := common.Organization{} err := org.GetOrgByCode(row[common.EStuCollegeCode]) if err != nil { msg := fmt.Sprintf(\u0026#34;查询目标学院代码错误:%v\u0026#34;, err) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } if errors.Is(err, sql.ErrNoRows) || org.Name != row[common.EStuCollege] { var msg string if org.Code != \u0026#34;\u0026#34; { msg = fmt.Sprintf(\u0026#34;同一个学院出现不同的学院代码：正确：【%v,%v】，错误：【%v,%v】\u0026#34;, org.Code, org.Name, row[common.EStuCollegeCode], row[common.EStuCollege]) } else { msg = fmt.Sprintf(\u0026#34;不存在代码为：%v的学院\u0026#34;, row[common.EStuCollegeCode]) } logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } ab := common.AddrBook{} // 通过同步系统数据库查看企业微信中是否有对应的学院部门 collegeDep, err := ab.GetDepByDbID(row[common.EStuCollegeCode], row[common.EStuLevel]) if err != nil \u0026amp;\u0026amp; !errors.Is(err, sql.ErrNoRows) { msg := fmt.Sprintf(\u0026#34;查询同步系统库失败:%s\u0026#34;, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // 如果对应学院部门不存在 if errors.Is(err, sql.ErrNoRows) { parentDepid, _ := strconv.Atoi(pid[row[common.EStuLevel]]) depid, err := ab.GetAndUpdateConf() if err != nil { // TODO 数据库异常概率小，故直接返回500 logger.Error(err.Error()) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // TODO 在企业微信中新建学院部门 err = Wxapi.CreateDept(row[common.EStuCollege], int64(parentDepid), depid, depid) if err != nil { logger.Error(fmt.Sprintf(\u0026#34;新建学院部门失败: %s,错误数据为:[%s],\u0026#34;, err.Error(), strings.Join(row, \u0026#34;,\u0026#34;))) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } collegeDep.WxName = row[common.EStuCollege] collegeDep.WxParentID = pid[row[common.EStuLevel]] collegeDep.WxCollegeID = \u0026#34;None\u0026#34; collegeDep.DbID = row[common.EStuCollegeCode] collegeDep.Grade = \u0026#34;None\u0026#34; collegeDep.WxGrade = \u0026#34;None\u0026#34; collegeDep.Level = 3 // TODO 将部门信息写入数据库 err = ab.NewDep(\u0026amp;collegeDep, row[common.EStuLevel], depid) if err != nil { msg := fmt.Sprintf(\u0026#34;将部门信息写入数据库失败: %s,\u0026#34;, err.Error()) logger.Error(msg) // TODO 删除创建的部门 err := Wxapi.DelDept(depid) if err != nil { logger.Error(fmt.Sprintf(\u0026#34;删除部门失败：%s\u0026#34;, err.Error())) } errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } // 通过同步系统数据库查看企业微信中是否有对应的年级部门 gradeDep, err := ab.GetDepByParentIdAndName(collegeDep.WxID, row[common.EStuGrade], row[common.EStuLevel]) if err != nil \u0026amp;\u0026amp; !errors.Is(err, sql.ErrNoRows) { msg := fmt.Sprintf(\u0026#34;查询同步数据库失败: %s\u0026#34;, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // 如果年级部门不存在 if errors.Is(err, sql.ErrNoRows) { parentId, _ := strconv.Atoi(collegeDep.WxID) depid, err := ab.GetAndUpdateConf() if err != nil { // TODO 数据库异常概率小，故直接返回500 logger.Error(fmt.Sprintf(\u0026#34;查询同步数据库失败:%s\u0026#34;, err.Error())) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // TODO 在企业微信中新建年级部门 err = Wxapi.CreateDept(row[common.EStuGrade], int64(parentId), depid, depid) if err != nil { logger.Error(fmt.Sprintf(\u0026#34;新建年级部门失败: %s\u0026#34;, err.Error())) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } gradeDep.WxName = row[common.EStuGrade] gradeDep.WxParentID = collegeDep.WxID gradeDep.WxCollegeID = collegeDep.WxID gradeDep.DbID = \u0026#34;None\u0026#34; gradeDep.Grade = \u0026#34;None\u0026#34; gradeDep.WxGrade = \u0026#34;None\u0026#34; gradeDep.Level = collegeDep.Level + 1 // TODO 将部门信息写入数据库 err = ab.NewDep(\u0026amp;gradeDep, row[common.EStuLevel], depid) if err != nil { msg := fmt.Sprintf(\u0026#34;将部门信息写入数据库失败: %s,\u0026#34;, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } // 先查询是否有该新生数据 bts := common.TStudent{} err1 := bts.QueryStudentByIdCard(row[common.EStuIdCard]) if err1 != nil \u0026amp;\u0026amp; !errors.Is(err1, gorm.ErrRecordNotFound) { msg := fmt.Sprintf(\u0026#34;查询学生信息错误:%s\u0026#34;, err) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // 录入新生数据 ts := common.TStudent{ Name: row[common.EStuName], IdCard: row[common.EStuIdCard], StuId: row[common.EStuStuId], Gender: WxGender[row[common.EStuGender]], Birthday: row[common.EStuBirth], College: row[common.EStuCollege], CollegeCode: row[common.EStuCollegeCode], Grade: row[common.EStuGrade], Level: row[common.EStuLevel], } curUser := make(map[string]string, 0) curUser[\u0026#34;name\u0026#34;] = row[common.EStuName] curUser[\u0026#34;idcard\u0026#34;] = row[common.EStuIdCard] curUser[\u0026#34;stu_id\u0026#34;] = row[common.EStuStuId] curUser[\u0026#34;gender\u0026#34;] = WxGender[row[common.EStuGender]] curUser[\u0026#34;birth\u0026#34;] = row[common.EStuBirth] curUser[\u0026#34;college\u0026#34;] = row[common.EStuCollege] curUser[\u0026#34;college_code\u0026#34;] = row[common.EStuCollegeCode] curUser[\u0026#34;grade\u0026#34;] = row[common.EStuGrade] curUser[\u0026#34;level\u0026#34;] = row[common.EStuLevel] exist := false // 如果已有信息 if err1 == nil { if bts.Status == \u0026#34;已核验\u0026#34; { errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = \u0026#34;success\u0026#34; buff \u0026lt;- errMsg wg.Done() return } err := ts.UpdateStudentByIdCard(ts.IdCard) if err != nil { msg := fmt.Sprintf(\u0026#34;修改学生信息失败:%s,错误数据:[%s]\u0026#34;, err, strings.Join(row, \u0026#34;,\u0026#34;)) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } exist = true } //TODO 判断中间库中是否有该研究生的信息（要从中间库中本科生，研究生，教职工表中查询） if row[common.EStuLevel] != \u0026#34;本科生\u0026#34; { pgStu := common.PGStudent{} originPosition, err2 := pgStu.GetStudentByIdCard(row[common.EStuIdCard]) if err2 != nil \u0026amp;\u0026amp; !errors.Is(err2, sql.ErrNoRows) { logger.Error(fmt.Sprintf(\u0026#34;中间库操作错误：%s\u0026#34;, err2)) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err2.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // TODO 如果该研究生信息在中间库中存在 if err2 == nil { user, err3 := Wxapi.GetUser(pgStu.StuID) if err3 != nil { msg := fmt.Sprintf(\u0026#34;在企业微信中获取研究生:%s 的信息失败,ERROR:%s\u0026#34;, pgStu.Name, err3.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } var depid []int64 d, _ := strconv.Atoi(gradeDep.WxID) for _, val := range user.Departments { if val.DeptID != int64(d) { depid = append(depid, val.DeptID) } } // TODO 给企业微信中存在数据的研究生添加新部门 depid = append(depid, int64(d)) extattr := user.Extattr err4 := Wxapi.UpdateUser(pgStu.StuID, pgStu.Name, depid, WxGender[row[common.EStuGender]], extattr) if err4 != nil { msg := fmt.Sprintf(\u0026#34;更新已有研究生部门失败:%s\u0026#34;, err4.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } ts.Status = \u0026#34;已核验\u0026#34; ts.InMidDb = \u0026#34;y\u0026#34; //记录该成员信息在中间库中存在 ts.OriginalPosition = originPosition curUser[\u0026#34;status\u0026#34;] = \u0026#34;已核验\u0026#34; curUser[\u0026#34;in_middb\u0026#34;] = \u0026#34;y\u0026#34; curUser[\u0026#34;originPosition\u0026#34;] = originPosition } } // 获取标签列表 taglist, err := Wxapi.GetTagList() if err != nil { logger.Error(fmt.Sprintf(\u0026#34;获取企业微信标签列表失败:%s\u0026#34;, err.Error())) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } flag := false // 判断标签是否存在 tmp := strings.Replace(row[common.EStuGrade], \u0026#34;级\u0026#34;, \u0026#34;\u0026#34;, -1) tmp = fmt.Sprintf(\u0026#34;%s/所有学院%s级部门\u0026#34;, row[common.EStuLevel], tmp) for _, values := range taglist.TagList { if values.TagName == tmp { flag = true break } } tagId := int64(-1) // 标签不存在 if !flag { var err error tagId, err = Wxapi.CreateTag(tmp) if err != nil { msg := fmt.Sprintf(\u0026#34;创建标签失败：%s,ERR: %s\u0026#34;, tmp, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } // 将对应年级部门加入到标签 if tagId != -1 { curDepid, _ := strconv.Atoi(gradeDep.WxID) err := Wxapi.AddTagUserOrDep(tagId, []string{}, []int64{int64(curDepid)}) if err != nil { msg := fmt.Sprintf(\u0026#34;为部门%v添加标签：[%v]失败，ERR: %s\u0026#34;, gradeDep.WxID, tmp, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = \u0026#34;success\u0026#34; if !exist { userList \u0026lt;- curUser } buff \u0026lt;- errMsg wg.Done() } func (st *StuHandle) ImportStuData(context *gin.Context) { var resp = gin.H{ \u0026#34;status\u0026#34;: 200, \u0026#34;msg\u0026#34;: \u0026#34;操作成功\u0026#34;, \u0026#34;err_data_url\u0026#34;: \u0026#34;\u0026#34;, } var form StuData if err := context.ShouldBind(\u0026amp;form); err != nil { logger.Error(err.Error()) Response(context, http.StatusBadRequest, \u0026#34;请求不合法\u0026#34;, resp) return } tmpFile := `./fileTmp/test.xlsx` if _, err := os.Stat(tmpFile); os.IsNotExist(err) { logger.Info(\u0026#34;文件不存在\u0026#34;) } else { logger.Info(\u0026#34;文件存在\u0026#34;) err := os.Remove(tmpFile) if err != nil { msg := fmt.Sprintf(\u0026#34;删除文件失败: %s\u0026#34;, err) logger.Error(msg) Response(context, http.StatusInternalServerError, \u0026#34;操作失败，请稍后再试\u0026#34;, resp) return } } // 接收并处理上传的excel表格 err := context.SaveUploadedFile(form.File, tmpFile) if err != nil { msg := fmt.Sprintf(\u0026#34;保存上传文件失败: %s\u0026#34;, err) logger.Error(msg) Response(context, http.StatusInternalServerError, \u0026#34;操作失败，请稍后再试\u0026#34;, resp) return } f, err := excelize.OpenFile(tmpFile) if err != nil { msg := fmt.Sprintf(\u0026#34;打开文件失败:%s\u0026#34;, err) logger.Error(msg) Response(context, http.StatusInternalServerError, \u0026#34;操作失败，请稍后再试\u0026#34;, resp) return } // 关闭文件 defer func() { if err := f.Close(); err != nil { msg := fmt.Sprintf(\u0026#34;关闭文件失败:%s\u0026#34;, err) logger.Error(msg) } }() rows, err := f.GetRows(\u0026#34;Sheet1\u0026#34;) if err != nil { msg := fmt.Sprintf(\u0026#34;读取Excel文件失败: %s\u0026#34;, err.Error()) logger.Error(msg) Response(context, http.StatusAccepted, \u0026#34;解析Excel数据错误，请确保提交正确的Excel数据\u0026#34;, resp) return } if len(rows) == 0 { logger.Error(\u0026#34;不能提交空文件\u0026#34;) Response(context, http.StatusAccepted, \u0026#34;不能提交空文件\u0026#34;, resp) return } row := rows[0] if len(row) != 9 || row[common.EStuName] != \u0026#34;姓名\u0026#34; || row[common.EStuIdCard] != \u0026#34;身份证号\u0026#34; || row[common.EStuStuId] != \u0026#34;学号\u0026#34; || row[common.EStuGender] != \u0026#34;性别\u0026#34; || row[common.EStuBirth] != \u0026#34;出生日期\u0026#34; || row[common.EStuCollege] != \u0026#34;学院名称\u0026#34; || row[common.EStuCollegeCode] != \u0026#34;学院代码\u0026#34; || row[common.EStuGrade] != \u0026#34;年级\u0026#34; || row[common.EStuLevel] != \u0026#34;层次\u0026#34; { logger.Error(\u0026#34;Excel格式不符合模板要求\u0026#34;) Response(context, http.StatusBadRequest, \u0026#34;Excel格式不符合模板要求\u0026#34;, resp) return } var wg sync.WaitGroup wg.Add(len(rows) - 1) buff := make(chan map[string]string, len(rows)-1) //建立缓冲区，记录不能导入的数据对应的姓名 _failInfo := make([]map[string]string, 0) userBuff := make(chan map[string]string, len(rows)-1) errBuff := make(chan []string, len(rows)-1) // 多进程处理，为每条数据分配一个goroutine for _, data := range rows[1:] { if len(data) != 9 { msg := fmt.Sprintf(\u0026#34;数据不符合要求：【%v】\u0026#34;, data) logger.Error(msg) tmp := make(map[string]string, 0) tmp[\u0026#34;name\u0026#34;] = row[common.EStuName] tmp[\u0026#34;reason\u0026#34;] = msg errBuff \u0026lt;- data buff \u0026lt;- tmp } // 多线程处理，为每条数据开一个线程 go dealStuData(data, buff, \u0026amp;wg, userBuff, errBuff) } wg.Wait() close(buff) close(userBuff) close(errBuff) for val := range buff { _failInfo = append(_failInfo, val) } ts := common.TStudent{} userList := make([]common.TStudent, 0) for val := range userBuff { t := common.TStudent{ Name: val[\u0026#34;name\u0026#34;], IdCard: val[\u0026#34;idcard\u0026#34;], StuId: val[\u0026#34;stu_id\u0026#34;], Gender: val[\u0026#34;gender\u0026#34;], Birthday: val[\u0026#34;birth\u0026#34;], College: val[\u0026#34;college\u0026#34;], CollegeCode: val[\u0026#34;college_code\u0026#34;], Grade: val[\u0026#34;grade\u0026#34;], Level: val[\u0026#34;level\u0026#34;], } t.Status = val[\u0026#34;status\u0026#34;] t.InMidDb = val[\u0026#34;in_middb\u0026#34;] t.OriginalPosition = val[\u0026#34;originPosition\u0026#34;] userList = append(userList, t) } failData := make([][]string, 0) for val := range errBuff { failData = append(failData, val) } err = ts.CreateStudent(userList) if err != nil { logger.Error(err.Error()) Response(context, http.StatusInternalServerError, err.Error(), resp) return } success := 0 fail := 0 var failInfo []string for _, val := range _failInfo { if val[\u0026#34;reason\u0026#34;] != \u0026#34;success\u0026#34; { fail++ failInfo = append(failInfo, val[\u0026#34;reason\u0026#34;]) continue } success++ } if len(failData) == 0 { resp[\u0026#34;err_data_url\u0026#34;] = \u0026#34;\u0026#34; } else { fileName, _ := golib.NewErrDataFile(failData, failInfo) fileName = strings.Replace(fileName, \u0026#34;.xlsx\u0026#34;, \u0026#34;\u0026#34;, -1) resp[\u0026#34;err_data_url\u0026#34;] = fmt.Sprintf(\u0026#34;%v/student/err?name=%v\u0026#34;, config.HostName, fileName) } msg := fmt.Sprintf(\u0026#34;成功导入条数:%d 导入失败条数:%d 总计条数:%d\u0026#34;, success, len(failData), len(rows)-1) status := http.StatusOK if fail != 0 { status = http.StatusAccepted } Response(context, status, msg, resp) return } // 下载不能导入的信息 type reqErrFile struct { FileName int `form:\u0026#34;name\u0026#34; binding:\u0026#34;required\u0026#34;` } func (st *StuHandle) StuErrFile(ctx *gin.Context) { resp := gin.H{ \u0026#34;status\u0026#34;: 200, \u0026#34;msg\u0026#34;: \u0026#34;操作成功\u0026#34;, } err := golib.DelOldFile() if err != nil { logger.Error(fmt.Sprintf(\u0026#34;删除旧文件失败：%v\u0026#34;, err)) Response(ctx, http.StatusInternalServerError, \u0026#34;操作失败\u0026#34;, resp) return } var form reqErrFile if err := ctx.ShouldBind(\u0026amp;form); err != nil { logger.Error(fmt.Sprintf(\u0026#34;参数错误：%v\u0026#34;, err)) Response(ctx, http.StatusBadRequest, \u0026#34;操作不合法\u0026#34;, resp) return } file, err := ioutil.ReadFile(fmt.Sprintf(\u0026#34;./fileTmp/%v.xlsx\u0026#34;, form.FileName)) if err != nil { logger.Error(fmt.Sprintf(\u0026#34;读取文件失败:%v\u0026#34;, err)) Response(ctx, http.StatusNotFound, \u0026#34;找不到资源\u0026#34;, resp) return } ctx.Header(\u0026#34;content-disposition\u0026#34;, `attachment; filename=`+fmt.Sprintf(\u0026#34;%v.xlsx\u0026#34;, form.FileName)) ctx.Data(200, \u0026#34;application/octet-stream\u0026#34;, file) } d := make(map[string]int,6) d[\u0026#34;name\u0026#34;] = 0 d[\u0026#34;content\u0026#34;] = 1 d[\u0026#34;org\u0026#34;] = 2 d[\u0026#34;year\u0026#34;] = 3 d[\u0026#34;user_id\u0026#34;] = 4 d[\u0026#34;username\u0026#34;] = 5 data 并发编程-\u0026gt;runtime runtime包里面定义了一些协程管理相关的api\nruntime.Gosched() 让出CPU时间片，重新等待安排任务\nfunc showMsg1(s string) { for i := 0; i \u0026lt; 2; i++ { fmt.Println(s) } } func RunTime() { go showMsg1(\u0026#34;java\u0026#34;) for i := 0; i \u0026lt; 2; i++ { runtime.Gosched() fmt.Println(\u0026#34;golang\u0026#34;) } fmt.Println(\u0026#34;end...\u0026#34;) } java java golang golang end... 如果没有第11行，可能main协程直接结束啦 golang golang end... runtime.Goexit() 退出协程\nruntime.Goexit() runtime.GOMAXPROCS() func showA() { for i := 0; i \u0026lt; 15; i++ { fmt.Printf(\u0026#34;A:%v\\n\u0026#34;, i) } } func showB() { for i := 0; i \u0026lt; 15; i++ { fmt.Printf(\u0026#34;B:%v\\n\u0026#34;, i) } } func RunTime() { cpuNum := runtime.NumCPU() // 我这是 8 核 println(cpuNum) runtime.GOMAXPROCS(1) // 如果设置为 1 ，则不会交替执行。除非有睡眠在。 go showA() go showB() time.Sleep(time.Second) } 并发编程-\u0026gt;Mutex互斥锁实现同步 除了使用 channel 实现同步之外，还可以使用Mutex互斥锁的方式实现同步。\nGo语言提供了sync包和channel机制来解决并发机制中不同goroutine之间的同步和通信\n没加锁 package Base import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func addOne(i int) { i++ } func subOne(i int) { i-- } func Mutex() { var i = 1 for ; i \u0026lt;= 1000; i++ { go addOne(i) go subOne(i) } time.Sleep(time.Second * 1) fmt.Println(\u0026#34;Sum:\u0026#34;, i) } Sum: 1001 加了锁 package Base import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var mutex sync.Mutex func addOne(i int) { mutex.Lock() i++ mutex.Unlock() } func subOne(i int) { mutex.Lock() i-- mutex.Unlock() } func Mutex() { i := 0 for ; i \u0026lt; 1000; i++ { go addOne(i) go subOne(i) } time.Sleep(time.Second * 1) fmt.Println(\u0026#34;Sum:\u0026#34;, i) } Sum: 1000 锁 Locker Go语言使用go语句开启新的goroutine，由于goroutine非常轻量除了对其分配栈空间外，所占的空间也是微乎其微的。但当多个goroutine同时处理时会遇到比如同时抢占一个资源，某个goroutine会等待等一个goroutine处理完毕某才能继续执行的问题。对于这种情况，官方并不希望依靠共享内存的方式来实现进程的协同操作，而是希望通过channel信道的方式来处理。但在某些特殊情况下，依然需要使用到锁，为此sync包提供了锁。\n当在并发情况下，多个goroutine同时修改某一个变量时，就会出现资源抢占，因此会导致数据不一致的问题。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { var num = 0 for i := 0; i \u0026lt; 100000; i++ { go func(i int) { num++ fmt.Printf(\u0026#34;goroutine %d: num = %d\\n\u0026#34;, i, num) }(i) } time.Sleep(time.Second)//主goroutine等待1秒以确保所有工作goroutine执行完毕 } ... goroutine 10018: num = 98635 goroutine 12646: num = 98635 goroutine 12844: num = 98635 goroutine 12950: num = 98635 ... 上例中goroutine一依次从寄存器中读取num的值后做加法运算，然后将其结果回写到寄存器中。运行中会发现存在一个goroutine取出num的值时做加法运算时，另一个goroutine也取出了num的值。因为上一个goroutine运行结果还没有回写到寄存器，最终导致多个goroutine产生的相同的结果。\n并发编程中同步原语-锁，为了保证多个线程或goroutine在访问同一块内存时不出现混乱，Go语言的sync包提供了常见的并发编程同步原语的控制锁。\nsync包围绕着Locker锁接口展开，Locker接口中提供了两个方法Lock()和Unlock()。\ntype Locker interface { Lock() Unlock() } Go语言标准库sync中提供了两种锁分别是互斥锁sync.Mutex和读写互斥锁sync.RWMutex\n互斥锁sync.Mutex sync.Mutex是一个互斥锁，可以由不同的goroutine加锁和解锁。\nsync.Mutex是Golang标准库提供的一个互斥锁，当一个goroutine获得互斥锁权限后，其他请求锁的goroutine会阻塞在Lock()方法的调用上，直到调用Unlock()方法被释放。\n例如：10个并发的goroutine打印同一个数字100，为避免重复打印，实现printOnce(num int)函数，使用集合set记录已打印过的数字。若数字已经打印过，则不再打印。\n$ vim mutex_test.go package test import ( \u0026#34;fmt\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) var set = make(map[int]bool, 0) func printOnce(index int, num int) { if _, ok := set[num]; !ok { fmt.Println(index, num) } set[num] = true } func TestPrint(t *testing.T) { for i := 0; i \u0026lt; 10; i++ { go printOnce(i, 100) } time.Sleep(time.Second) } $ go test -v mutex_test.go === RUN TestPrint 9 100 3 100 --- PASS: TestPrint (1.00s) PASS ok command-line-arguments 1.304s 程序多次运行后会发现打印次数多次，因为对同一个数据结构set的访问发生了冲突。\n并发访问中比如多个goroutine并发更新同一个资源，比如计时器、账户余额、秒杀系统、向同一个缓存中并发写入数据等等。如果没有互斥控制，很容易会出现异常，比如计时器计数不准确、用户账户可能出现透支、秒杀系统出现超卖、缓存出现数据缓存等等，后果会很严重。\n互斥锁是并发控制的一种基本手段，是为了避免竞争而建立的一种并发控制机制。学习前首先需要弄清楚一个概念-临界区。在并发编程中，如果程序中的一部分会被并发访问或修改，为了避免并发访问导致的意想不到的结果，这部分程序需要被保护起来，这部分被保护起来的程序就叫做临界区。\n临界区是一个被共享的资源，或者说是一个整体的共享资源，比如对数据库的访问，对某个共享数据结构的操作。对一个I/O设备的使用，对一个连接池中的连接的调用等等。\n如果很多线程同步访问临界区就会造成访问或操作错误，这并不是我们希望看到的结果。所以，使用互斥锁，限定临界区只能同时由一个线程持有。当临界区由一个线程持有的时候，其他线程如果想进入临界区就会返回失败，或者是等待。直到持有的线程退出临界区，这些等待线程中的某一个才有机会接着持有这个临界区。\n互斥锁\n互斥锁可以很好的解决资源竞争的问题，因此也有人称之为排它锁。Golang标准库中使用Mutex来实现互斥锁。根据2019年分析Go并发Bug的论文Understanding Real-World Concurrency Bugs in Go中，Mutex是使用最为广泛的同步原语（Synchronization primitives， 并发原语或同步原语）。关于同步原语并没有一个严格的定义，可将其看作是解决并发问题的一个基础的数据结构。\ntype Mutex struct { state int32 //状态标识 sema uint32 //信号量 } Go标准库提供了sync.Mutex互斥锁类型以及两个方法分别是Lock加锁和Unlock释放锁。可以通过在代码前调用Lock方法，在代码后调用Unlock方法来保证一段代码的互斥执行，也可以使用defer语句来保证互斥锁一定会被解锁。当一个goroutine调用Lock方法获得锁后，其它请求的goroutine都会阻塞在Lock方法直到锁被释放。\n一个互斥锁只能同时被一个goroutine锁定，其它goroutine将阻塞直到互斥锁被解锁，也就是重新争抢对互斥锁的锁定。需要注意的是，对一个未锁定的互斥锁解锁时将会产生运行时错误。\nsync.Mutex不区分读写锁，只有Lock()和Lock()之间才会导致阻塞的情况。若在一个地方Lock()，在另一个地方不Lock()而是直接修改或访问共享数据，对于sync.Mutext类型是允许的，因为mutex不会和goroutine进行关联。若要区分读锁和写锁，可使用sync.RWMutex类型。\n在Lock()和Unlock()之间的代码段成为资源临界区（critical section），在这一区间内的代码是严格被Lock()保护的，是线程安全的，任何一个时间点都只能有一个goroutine执行这段区间的代码。\n例如：使用互斥锁的Lock()和Unlock()方法将冲突包裹\npackage test import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) var m sync.Mutex var set = make(map[int]bool, 0) func printOnce(index int, num int) { m.Lock() defer m.Unlock() if _, ok := set[num]; !ok { fmt.Println(index, num) } set[num] = true } func TestPrint(t *testing.T) { for i := 0; i \u0026lt; 10; i++ { go printOnce(i, 100) } time.Sleep(time.Second) } 相同的数字只会比打印一次，当一个goroutine调用了Lock()方法时，其他goroutine被阻塞了，直到Unlock()调用将锁释放。因此被包裹部分的代码就能避免冲突，实现互斥。\n互斥即不能同时运行，使用互斥锁的两个代码片段相互排斥，只有其中一个代码片段执行完毕后，另一个才能执行。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var num = 0 var locker sync.Mutex for i := 0; i \u0026lt; 100000; i++ { go func(i int) { locker.Lock() defer locker.Unlock() num++ fmt.Printf(\u0026#34;goroutine %d: num = %d\\n\u0026#34;, i, num) }(i) } time.Sleep(time.Second) } 从上例中可以发现，添加互斥锁后，不仅没有出现抢占资源导致的重复输出，而且输出结果顺序递增。\nGo语言中的Mutex类型的互斥锁Lock()锁定与其它语言不同的是，Lock()锁定的是互斥锁而非一段代码。其他语言比如Java中使用同步锁锁定的是一段代码，以确保多线程并发誓只有一个线程可以控制运行此代码块直到释放同步锁。Go语言是在goroutine中锁定互斥锁，其它goroutine执行到有锁的位置时，由于获取不到互斥锁的锁定，因此会发生阻塞而等待，从而达到控制同步的目的。\nrace detector Golang提供了一个检测并发访问共享资源是否存在问题的工具 - race detector，它可以帮助自动发现城中有没有data race的问题。\nGolang的race detector是基于Google的C/C++ sanitizers技术实现的，编译器通过探测所有的内存访问，加入代码能监视对这些内存地址的访问（读或是写）。代码运行时race detector能监控对共享变量的非同步访问，出现race时就会打印出警告信息。\nhttps://blog.golang.org/race-detector\n读写锁sync.RWMutex 在银行存取钱时，对账户余额的修改是需要加锁的，因此此时可能有人汇款到你的账户，如果对金额的修改不加锁，很可能导致最后的金额发生错误。读取账户余额也需要等待修改操作结束，才能读取到正确的余额。大部分情况下，读取余额的操作会更加频繁，如果能保证读取余额的操作能并发执行，程序的效率会很大地提升。\n保证读操作的安全，只需要保证并发读时没有写操作在进行就行。在这种场景下就需要一种特殊类型的锁，即允许多个只读操作并行执行，但写操作会完全互斥。这种锁称之为多读单写锁（multiple readers, single writer lock），简称读写锁。读写锁分为读锁和写锁，读锁允许同时执行，但写锁是互斥的。\nsync.RWMutex读写锁是基于sync.Mutex实现的，读写锁的特点是针对读写操作的互斥锁，读写锁与互斥锁最大不同之处在于分别对读、写进行了锁定。一般用在大量读操作少量写操作中。\n同时只能具有一个goroutine能够获得写锁定 同时可以具有任意多个goroutine获得读锁定 同时只能存在写锁定或读锁定，即读和写互斥。 换句话说\n当只有一个goroutine获得写锁定时，其它无论是读锁定还是写锁定都将会阻塞直到写解锁。 当只有一个goroutine获得读锁定时，其它读锁定仍然可以继续执行。 当有一个或多个读锁定时，写锁定将等待所有读锁定解锁之后才能进行写锁定。 这里所谓的读锁定（RLock）目的是为了告诉写锁定（Lock），此时有很多人正在读取数据，写锁定需要排队等待。\n一般来说，读写锁会分为几种情况：\n读锁之间不互斥，在没有写锁的情况下，读锁是无堵塞的，多个goroutine可以同时获得读锁。 写锁之间是互斥的，当存在写锁时，其它写锁会阻塞。 写锁与读锁互斥，若存在读锁则写锁阻塞，若存在写锁则读锁阻塞。 Go标准库sync.RWMutex读写互斥锁提供了四个方法\n读写互斥锁 描述 Lock 添加写锁 Unlock 释放写锁 RLock 添加读锁 RUnlock 释放读锁 并发编程-\u0026gt;select switch 1.select是Go中的一个控制结构，类似于switch语句，用于处理异步IO操作。select会监听case语句中channel的读写操作，当case中channel读写操作为非阻塞状态（即能读写）时，将会触发相应的动作。\nselect中的case语句必须是一个channel操作. select中的default子句总是可运行的。\n2.如果有多个case都可以运行，select会随机公平地选出一个执行，其他不会执行。\n3.如果没有可运行的case语句，且有default语句，那么就会执行default的动作。\n4.如果没有可运行的case语句，且没有default语句，select将阻塞，直到某个case通信可以运行.\n实例\npackage Base import \u0026#34;time\u0026#34; var chanInt = make(chan int) var chanStr = make(chan string) func Channel() { go func() { chanInt \u0026lt;- 100 chanStr \u0026lt;- \u0026#34;Hello\u0026#34; defer close(chanInt) defer close(chanStr) }() for { select { case r := \u0026lt;-chanInt: println(\u0026#34;chanInt\u0026#34;, r) case r := \u0026lt;-chanStr: println(\u0026#34;chanStr\u0026#34;, r) default: println(\u0026#34;default\u0026#34;) } time.Sleep(time.Second) } } default chanInt 100 chanStr Hello chanStr chanStr chanInt 0 chanInt 0 \u0026hellip;\u0026hellip;\n并发编程-\u0026gt;Timer Timer顾名思义，就是定时器的意思，可以实现一些定时操作，内部也是通过channel来实现的。\npackage Base import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func Timer() { // 第一种创建方式 timer := time.NewTimer(time.Second * 2) fmt.Println(time.Now()) c := \u0026lt;-timer.C fmt.Println(c) // 相差两秒 //2022-09-13 11:28:25.6609052 +0800 +08 m=+0.004536701 //2022-09-13 11:28:27.6616643 +0800 +08 m=+2.005295801 } 并发编程-\u0026gt;Ticker Timer只执行一次，TickerT可以周期的执行。\n实例\nfunc Ticker() { ticker := time.NewTicker(time.Second) count := 0 for range ticker.C { fmt.Println(\u0026#34;ticker...\u0026#34;) count++ if count \u0026gt;= 5 { ticker.Stop() break } } } 并发编程-\u0026gt;原子变量 package Base import ( \u0026#34;fmt\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) var num int64 = 1 func Add(i int64) { atomic.AddInt64(\u0026amp;i, 1) } func Sub(i int64) { atomic.AddInt64(\u0026amp;i, -1) } func Atomic() { for ; num \u0026lt; 1000; num++ { go Add(num) go Sub(num) } time.Sleep(time.Second * 1) fmt.Println(\u0026#34;Sum:\u0026#34;, num) } Advanced level fmt https://www.bilibili.com/read/cv14519061/?from=readlist\n文件常见操作/读写 (os, io, bufio包) https://www.bilibili.com/read/cv14586068/?from=readlist\n错误/日志/单元测试 错误处理\nfunc Errors() { defer func() { err := recover() fmt.Println(\u0026#34;捕捉到了错误:\u0026#34;, err) }() err1 := errors.New(\u0026#34;可爱的错误\u0026#34;) fmt.Println(\u0026#34;err1=\u0026#34;, err1) err2 := fmt.Errorf(\u0026#34;%s的错误\u0026#34;, \u0026#34;温柔\u0026#34;) fmt.Println(\u0026#34;err2=\u0026#34;, err2) panic(err1) } 单元测试 6.10.1 命名规范\n文件名: xxx_test.go (通常xxx为被测试文件名)\n6.10.2 测试函数\n测试函数: func TestXxx(*testing.T) (通常Xxx为被测试函数名)\n性能测试函数: func BenchmarkXxx(*testing.B) (通常Xxx为被测试函数名)\n6.10.3 testing.T与testing.B\ntesting.T与testing.B是testing包定义的结构体，下面简称t与b\n6.10.4 测试命令(go mod下)\n项目名可以简写为\u0026rdquo;.\u0026quot;，下面同一为\u0026quot;.\u0026quot;\n测试指定包: go test ./文件夹路径\n将自动调用所有_test.go文件中的所有TestXxx函数\n测试指定文件: go test ./文件夹路径/xxx_test.go ./go/文件夹路径/xxx.go\n将自动调用xxx_test.go中的所有TestXxx函数\nflag\nflag可以写在 ./\u0026hellip; 前也可以写在 ./\u0026hellip; 之后\n也运行BenchmarkXxx函数: go test -bench ./…\n详细输出(verbose): go test -v ./…\n即使运行成功也输出日志\n规定测试时间: go test -benchtime XhXmXs ./…\n规定测试次数: go test -benchtime Nx ./…\n指定测试cpu数量: go test -cpu N ./…\n指定测试函数: go test -run TestXxx ./…\n只测试TestXxx函数\n超时限制: go test -timeout XhXmXs ./…\n默认限制为10min\n打印测试的内存使用统计: go test -benchmem ./…\n作者：FangChannel https://www.bilibili.com/read/cv14614760/?from=readlist 出处：bilibili\nfor range package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) type Detail struct{ Rid int TeamName string Member string } type TeamMember struct{ Rid int Member string } func main() { d1:=Detail{ Rid: 10, TeamName: \u0026#34;ddd10\u0026#34;, Member: \u0026#34;\u0026#34;, } d2:=Detail{ Rid: 11, TeamName: \u0026#34;ddd11\u0026#34;, Member: \u0026#34;\u0026#34;, } d3:=Detail{ Rid: 12, TeamName: \u0026#34;ddd12\u0026#34;, Member: \u0026#34;\u0026#34;, } t1:=TeamMember{ Rid: 10, Member: \u0026#34;10的Member\u0026#34;, } var ds []Detail ds = append(ds,d1,d2,d3) var ts []TeamMember ts = append(ts, t1) fmt.Println(ts) fmt.Println(ds) for i := 0; i \u0026lt; len(ds); i++ { for j := 0; j \u0026lt; len(ts); j++ { if ds[i].Rid == ts[j].Rid { ds[i].Member = ts[j].Member break } } } // ==== ?? ==== for _, v := range ds { for _, v2 := range ts { if v.Rid == v2.Rid { v.member = v2.menber } } } fmt.Println(ts) fmt.Println(ds) } ","permalink":"https://Bin-lin-rgb.github.io/posts/go/base/","summary":"Base go 常用命令 build: 编译包和依赖 clean: 移除对象文件 doc: 显示包或者符号的文档 env: 打印go的环境信息 bug: 启动错误报告 fix: 运行go tool fix fmt: 运行gofmt进行格式化 generate: 从processing source生成go文件 get: 下载并安装包和依赖 install: 编译并安装包和依赖 list: 列出包 run: 编译并运行go程序 test: 运行测试 tool: 运行go提供的工","title":"Golang 基础语法"},{"content":"Go 方法与函数的区别？ 在 Go 语言中，有方法（method）和函数（function）两个概念，它们之间有一些重要的区别，主要体现在以下几个方面：\n定义方式：\n函数：函数是一段独立的代码块，它可以在任何地方定义和调用。函数的定义是全局的，可以在不同包中调用。\n方法：方法是与类型（结构体或接口）关联的函数。方法的定义是与类型绑定的，它们通常用于对类型进行操作和处理。通过实例来调用这些方法。\n方法的接收者：\n方法：方法通常有一个接收者（receiver），它指定了方法可以作用于哪种类型。接收者可以是值接收者（value receiver）或指针接收者（pointer receiver）。\n函数：函数没有接收者，它们是独立的代码块，不与特定类型关联。\n下面是一个简单的示例，演示了方法和函数之间的区别：\npackage main import ( \u0026#34;fmt\u0026#34; ) type Rectangle struct { Width float64 Height float64 } // 方法，使用值接收者 func (r Rectangle) Area() float64 { return r.Width * r.Height } // 函数，计算两个数的和 func Add(a, b int) int { return a + b } func main() { r := Rectangle{Width: 5, Height: 3} // 调用方法 area := r.Area() fmt.Println(\u0026#34;面积:\u0026#34;, area) // 调用函数 sum := Add(2, 3) fmt.Println(\u0026#34;和:\u0026#34;, sum) } Go 方法值接收者和指针接收者的区别? 如果方法的接收者是指针类型，无论调用者是对象还是对象指针，修改的都是对象本身，会影响调用者；\n如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者；\npackage main import \u0026#34;fmt\u0026#34; type Person struct { age int } // 如果实现了接收者是指针类型的方法，会隐含地也实现了接收者是值类型的IncrAge1方法。 // 会修改age的值 func (p *Person) IncrAge1() { p.age += 1 } // 如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的IncrAge2方法。 // 不会修改age的值 func (p Person) IncrAge2() { p.age += 1 } // 如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的GetAge方法。 func (p Person) GetAge() int { return p.age } func main() { // p1 是值类型 p := Person{age: 10} // 值类型 调用接收者是指针类型的方法 p.IncrAge1() fmt.Println(p.GetAge()) // 值类型 调用接收者是值类型的方法 p.IncrAge2() fmt.Println(p.GetAge()) // ---------------------- // p2 是指针类型 p2 := \u0026amp;Person{age: 20} // 指针类型 调用接收者是指针类型的方法 p2.IncrAge1() fmt.Println(p2.GetAge()) // 指针类型 调用接收者是值类型的方法 p2.IncrAge2() fmt.Println(p2.GetAge()) } 上述代码中：\n实现了接收者是指针类型的 IncrAge1 函数，不管调用者是值类型还是指针类型，都可以调用IncrAge1方法，并且它的 age 值都改变了。 实现了接收者是指针类型的 IncrAge2 函数，不管调用者是值类型还是指针类型，都可以调用IncrAge2方法，并且它的 age 值都没有被改变。\n通常我们使用指针类型作为方法的接收者的理由：\n使用指针类型能够修改调用者的值。 使用指针类型可以避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做会更加高效。 总结：\n值接收者用于不需要修改原始数据的情况，适用于只读操作。 指针接收者用于需要修改原始数据的情况，适用于读写操作。 选择接收者类型取决于方法的需求，需要考虑是否要修改原始数据以及性能等因素。 Go 函数返回局部变量的指针是否安全? 一般来说，局部变量会在函数返回后被销毁，因此被返回的引用就成为了\u0026quot;无所指\u0026quot;的引用，程序会进入未知状态。\n但这在 Go 中是安全的，Go 编译器将会对每个局部变量进行逃逸分析。如果发现局部变量的作用域超出该函数，则不会将内存分配在栈上，而是分配在堆上，因为他们不在栈区，即使释放函数，其内容也不会受影响。\npackage main import \u0026#34;fmt\u0026#34; func add(x, y int) *int { res := 0 res = x + y return \u0026amp;res } func main() { fmt.Println(add(1, 2)) } 这个例子中，函数 add 局部变量 res 发生了逃逸。res作为返回值，在 main 函数中继续使用，因此 res 指向的内存不能够分配在栈上，随着函数结束而回收，只能分配在堆上。\n编译时可以借助选项 -gcflags=-m，查看变量逃逸的情况\n~/GoTest$ go build -gcflags=-m main.go # command-line-arguments ./main.go:5:6: can inline add ./main.go:12:16: inlining call to add ./main.go:12:12: inlining call to fmt.Println ./main.go:6:1: moved to heap: res ./main.go:12:16: moved to heap: res ./main.go:12:12: []interface {}{...} does not escape \u0026lt;autogenerated\u0026gt;:1: leaking param content: .this res escapes to heap 即表示 res 逃逸到堆上了。\nGo 函数参数传递到底是值传递还是引用传递？ 结论：\nGo语言中所有的传参都是值传递（传值），都是一个副本，一个拷贝。\n参数如果是非引用类型（int、string、struct），这样就在函数中就无法修改原内容数据；如果是引用类型（指针、map、slice、chan），这样就可以修改原内容数据。\n是否可以修改原内容数据，和传值、传引用没有必然的关系。在C++中，传引用肯定是可以修改原内容数据的，在Go语言里,需要看参数是值类型还是引用类型。\n值类型 值类型：值类型的实例在分配给变量、作为函数参数传递或复制时会创建副本。这意味着每个值类型的实例都是独立的，对其进行修改不会影响其他实例。以下是一些常见的值类型：\n基本数据类型：包括整数、浮点数、布尔值和字符串。\n数组（Array）：数组的大小在声明时是固定的，数组是值类型。\n结构体（Struct）：结构体由一组字段组成，是值类型。\n引用类型 引用类型：引用类型的实例在分配给变量、作为函数参数传递或复制时，不会创建副本，而是会共享同一个底层数据。这意味着对引用类型的修改可能会影响其他引用该数据的实例。以下是一些常见的引用类型：\n切片（Slice）：切片是对数组的引用，它可以动态调整大小，并且多个切片可以引用相同的底层数组。\n映射（Map）：映射是一种键值对集合，多个映射可以引用不同数据，但它们可以共享相同的底层数据结构。\n通道（Channel）：通道用于在不同的 Go 协程之间进行通信，多个通道可以引用不同的数据，但它们可以共享相同的通道。\n接口（Interface）：接口类型包含一个具体类型和该类型的值。多个接口可以引用不同类型的数据，但它们可以引用相同类型的值。\n函数（Function）：函数是一种引用类型，可以将函数作为参数传递给其他函数。\n引用类型和引用传递 什么是值传递？\n将实参的值传递给形参，形参是实参的一份拷贝，实参和形参的内存地址不同。函数内对形参值内容的修改，是否会影响实参的值内容，取决于参数是否是引用类型\n什么是引用传递？\n将实参的地址传递给形参，函数内对形参值内容的修改，将会影响实参的值内容。Go语言是没有引用传递的，在C++中，函数参数的传递方式有引用传递。\ndefer 关键字 defer定义的延迟函数参数在defer语句出时就已经确定下来了 defer定义顺序与实际执行顺序相反 return不是原子操作，执行过程是: 保存返回值(若有)\u0026ndash;\u0026gt;执行defer（若有）\u0026ndash;\u0026gt;执行ret跳转 申请资源后立即使用defer关闭资源是好习惯 示例题目 1、\nfunc deferFuncParameter() { var aInt = 1 defer fmt.Println(aInt) aInt = 2 return } 参考答案： 输出1。延迟函数fmt.Println(aInt)的参数在defer语句出现时就已经确定了，所以无论后面如何修改aInt变量都不会影响延迟函数。\n2、\n下面函数输出什么？\nfunc deferFuncReturn() (result int) { i := 1 defer func() { result++ }() return i } 参考答案： 函数输出2。函数的return语句并不是原子的，实际执行分为设置返回值\u0026ndash;\u0026gt;ret，defer语句实际执行在返回前， 即拥有defer的函数返回过程是：设置返回值\u0026ndash;\u0026gt;执行defer\u0026ndash;\u0026gt;ret。 所以return语句先把result设置为i的值，即1，defer语句中又把result递增1，所以最终返回2。\nGo 内置函数make和new的区别？ 首先纠正下make和new是内置函数，不是关键字\n变量初始化，一般包括2步，变量声明 + 变量内存分配，var关键字就是用来声明变量的，new和make函数主要是用来分配内存的\nvar声明值类型的变量时，系统会默认为他分配内存空间，并赋该类型的零值\n比如布尔、数字、字符串、结构体\n如果指针类型或者引用类型的变量，系统不会为它分配内存，默认就是nil。此时如果你想直接使用，那么系统会抛异常，必须进行内存分配后，才能使用。\nnew 和 make 两个内置函数，主要用来分配内存空间，有了内存，变量就能使用了，主要有以下2点区别：\n使用场景区别：\nmake 只能用来分配及初始化类型为 slice、map、chan 的数据。\nnew 可以分配任意类型的数据，并且置零。\n返回值区别：\nmake函数原型如下，返回的是slice、map、chan类型本身 这3种类型是引用类型，就没有必要返回他们的指针\nfunc make(t Type, size ...IntegerType) Type new函数原型如下，返回一个指向该类型内存地址的指针\nfunc new(Type) *Type ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go%E5%9F%BA%E7%A1%80%E7%AF%87/","summary":"Go 方法与函数的区别？ 在 Go 语言中，有方法（method）和函数（function）两个概念，它们之间有一些重要的区别，主要体现在以下几个方面： 定义方式： 函数：函数是一段独立的代码块，它可以在任何地方定义和调用。函数的定义是全局的，可以在不同包中调用。 方法：方法是与类型（结构体或接口","title":"Go 基础篇"},{"content":"Slice实现原理 Slice依托数组实现，底层数组对用户屏蔽，在底层数组容量不足时可以实现自动重分配并生成新的Slice。 接下来按照实际使用场景分别介绍其实现机制。\n3.1 Slice数据结构 源码包中src/runtime/slice.go:slice定义了Slice的数据结构：\ntype slice struct { array unsafe.Pointer len int cap int } 从数据结构看Slice很清晰, array指针指向底层数组，len表示切片长度，cap表示底层数组容量。\n3.2 创建Slice // 初始化方式1：直接声明 var slice1 []int // 初始化方式2：使用字面量 slice2 := []int{1, 2, 3, 4} // 初始化方式3：使用make创建slice slice3 := make([]int, 3, 5) // 初始化方式4: 从切片或数组“截取” slcie4 := arr[1:3] 3.3 Slice 扩容 使用append向Slice追加元素时，如果Slice空间不足，将会触发Slice扩容，扩容实际上是重新配一块更大的内存，将原Slice数据拷贝进新Slice，然后返回新Slice，扩容后再将数据追加进去。\n扩容容量的选择遵循以下规则：\n如果原Slice容量小于1024，则新Slice容量将扩大为原来的2倍； 如果原Slice容量大于等于1024，则新Slice容量将扩大为原来的1.25倍；\n使用append()向Slice添加一个元素的实现步骤如下：\n假如Slice容量够用，则将新元素追加进去，Slice.len++，返回原Slice 原Slice容量不够，则将Slice先扩容，扩容后得到新Slice。将新元素追加进新Slice，Slice.len++，返回新的Slice。 3.5 Slice Copy 使用copy()内置函数拷贝两个切片时，会将源切片的数据逐个拷贝到目的切片指向的数组中，拷贝数量取两个切片长度的最小值。\n例如长度为10的切片拷贝到长度为5的切片时，将会拷贝5个元素。\n也就是说，copy过程中不会发生扩容。\n3.6 特殊切片 跟据数组或切片生成新的切片一般使用slice := array[start:end]方式，这种新生成的切片并没有指定切片的容量，实际上新切片的容量是从start开始直至array的结束。\n比如下面两个切片，长度和容量都是一致的，使用共同的内存地址：\nsliceA := make([]int, 5, 10) sliceB := sliceA[0:5]\n根据数组或切片生成切片还有另一种写法，即切片同时也指定容量，即slice[start:end:cap], 其中cap即为新切片的容量，当然容量不能超过原切片实际值，如下所示：\nsliceA := make([]int, 5, 10) //length = 5; capacity = 10\rsliceB := sliceA[0:5] //length = 5; capacity = 10\rsliceC := sliceA[0:5:5] //length = 5; capacity = 5\r这切片方法不常见，在Golang源码里能够见到，不过非常利于切片的理解。\n编程Tips 创建切片时可跟据实际需要预分配容量，尽量避免追加过程中扩容操作，有利于提升性能； 切片拷贝时需要判断实际拷贝的元素个数 谨慎使用多个切片操作同一个数组，以防读写冲突 Slice总结 每个切片都指向一个底层数组 每个切片都保存了当前切片的长度、底层数组可用容量 使用len()计算切片长度时间复杂度为O(1)，不需要遍历切片 使用cap()计算切片容量时间复杂度为O(1)，不需要遍历切片 通过函数传递切片时，不会拷贝整个切片，因为切片本身只是个结构体而矣 使用append()向切片追加元素时有可能触发扩容，扩容后将会生成新的切片 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-slice%E7%AF%87/","summary":"Slice实现原理 Slice依托数组实现，底层数组对用户屏蔽，在底层数组容量不足时可以实现自动重分配并生成新的Slice。 接下来按照实际使用场景分别介绍其实现机制。 3.1 Slice数据结构 源码包中src/runtime/slice.go:slice定义了Slice的数据结构： type slice struct {","title":"Go Slice篇"},{"content":"Go 互斥锁的实现原理？ 互斥锁是并发程序中对共享资源进行访问控制的主要手段，对此Go语言提供了非常简单易用的Mutex，Mutex为一结构体类型，对外暴露两个方法Lock()和Unlock()分别用于加锁和解锁。\nMutex使用起来非常方便，但其内部实现却复杂得多，这包括Mutex的几种状态。另外，我们也想探究一下Mutex重复解锁引起panic的原因。\nMutex数据结构 源码包src/sync/mutex.go:Mutex定义了互斥锁的数据结构：\ntype Mutex struct { state int32 sema uint32 } Mutex.state表示互斥锁的状态，比如是否被锁定等。\nMutex.sema表示信号量，协程阻塞等待该信号量，解锁的协程释放信号量从而唤醒等待信号量的协程。\n我们看到Mutex.state是32位的整型变量，内部实现时把该变量分成四份，用于记录Mutex的四种状态。\n下图展示Mutex的内存布局：\nLocked: 表示该Mutex是否已被锁定，0：没有锁定 1：已被锁定。 Woken: 表示是否有协程已被唤醒，0：没有协程唤醒 1：已有协程唤醒，正在加锁过程中。 Starving：表示该Mutex是否处理饥饿状态， 0：没有饥饿 1：饥饿状态，说明有协程阻塞了超过1ms。 Waiter: 表示阻塞等待锁的协程个数，协程解锁时根据此值来判断是否需要释放信号量。 协程之间抢锁实际上是抢给Locked赋值的权利，能给Locked域置1，就说明抢锁成功。抢不到的话就阻塞等待Mutex.sema信号量，一旦持有锁的协程解锁，等待的协程会依次被唤醒。\nWoken和Starving主要用于控制协程间的抢锁过程，后面再进行了解。\nMutex方法 Mutext对外提供两个方法，实际上也只有这两个方法：\nLock() : 加锁方法 Unlock(): 解锁方法 下面我们分析一下加锁和解锁的过程，加锁分成功和失败两种情况，成功的话直接获取锁，失败后当前协程被阻塞，同样，解锁时跟据是否有阻塞协程也有两种处理。\n加解锁过程 3.1 简单加锁 假定当前只有一个协程在加锁，没有其他协程干扰\n加锁过程会去判断Locked标志位是否为0，如果是0则把Locked位置1，代表加锁成功。从上图可见，加锁成功后，只是Locked位置1，其他状态位没发生变化。\n3.2 加锁被阻塞\n假定加锁时，锁已被其他协程占用了，此时加锁过程如下图所示：\n从上图可看到，当协程B对一个已被占用的锁再次加锁时，Waiter计数器增加了1，此时协程B将被阻塞，直到Locked值变为0后才会被唤醒。\n3.3 简单解锁\n假定解锁时，没有其他协程阻塞, 由于没有其他协程阻塞等待加锁，所以此时解锁时只需要把Locked位置为0即可，不需要释放信号量。\n3.4 解锁并唤醒协程\n假定解锁时，有1个或多个协程阻塞。\n协程A解锁过程分为两个步骤，一是把Locked位置0，二是查看到Waiter\u0026gt;0，所以释放一个信号量，唤醒一个阻塞的协程，被唤醒的协程B把Locked位置1，于是协程B获得锁。\n自旋过程 加锁时，如果当前Locked位为1，说明该锁当前由其他协程持有，尝试加锁的协程并不是马上转入阻塞，而是会持续的探测Locked位是否变为0，这个过程即为自旋过程。\n自旋时间很短，但如果在自旋过程中发现锁已被释放，那么协程可以立即获取锁。此时即便有协程被唤醒也无法获取锁，只能再次阻塞。\n自旋的好处是，当加锁失败时不必立即转入阻塞，有一定机会获取到锁，这样可以避免协程的切换。\n4.1 什么是自旋\n自旋对应于CPU的\u0026quot;PAUSE\u0026quot;指令，CPU对该指令什么都不做，相当于CPU空转，对程序而言相当于sleep了一小段时间，时间非常短，当前实现是30个时钟周期。\n自旋过程中会持续探测Locked是否变为0，连续两次探测间隔就是执行这些PAUSE指令，它不同于sleep，不需要将协程转为睡眠状态。\n4.1 自旋条件\n加锁时程序会自动判断是否可以自旋，无限制的自旋将会给CPU带来巨大压力，所以判断是否可以自旋就很重要了。\n自旋必须满足以下所有条件：\n自旋次数要足够小，通常为4，即自旋最多4次 CPU核数要大于1，否则自旋没有意义，因为此时不可能有其他协程释放锁 协程调度机制中的Process数量要大于1，比如使用GOMAXPROCS()将处理器设置为1就不能启用自旋 协程调度机制中的可运行队列必须为空，否则会延迟协程调度 可见，自旋的条件是很苛刻的，总而言之就是不忙的时候才会启用自旋。\n4.2 自旋的优势\n自旋的优势是更充分的利用CPU，尽量避免协程切换。因为当前申请加锁的协程拥有CPU，如果经过短时间的自旋可以获得锁，当前协程可以继续运行，不必进入阻塞状态。\n4.3 自旋的问题\n如果自旋过程中获得锁，那么之前被阻塞的协程将无法获得锁，如果加锁的协程特别多，每次都通过自旋获得锁，那么之前被阻塞的进程将很难获得锁，从而进入饥饿状态。\n为了避免协程长时间无法获取锁，自1.8版本以来增加了一个状态，**即Mutex的Starving状态。这个状态下不会自旋，**一旦有协程释放锁，那么一定会唤醒一个协程并成功加锁。\nMutex模式 前面分析加锁和解锁过程中只关注了Waiter和Locked位的变化，现在我们看一下Starving位的作用。\n每个Mutex都有两个模式，称为Normal和Starving。下面分别说明这两个模式。\n4.1 normal模式\n默认情况下，Mutex的模式为normal。\n该模式下，协程如果加锁不成功不会立即转入阻塞排队，而是判断是否满足自旋的条件，如果满足则会启动自旋过程，尝试抢锁。\n4.2 starvation模式\n自旋过程中能抢到锁，一定意味着同一时刻有协程释放了锁，我们知道释放锁时如果发现有阻塞等待的协程，还会释放一个信号量来唤醒一个等待协程，被唤醒的协程得到CPU后开始运行，此时发现锁已被抢占了，自己只好再次阻塞，不过阻塞前会判断自上次阻塞到本次阻塞经过了多长时间，如果超过1ms的话，会将Mutex标记为\u0026quot;饥饿\u0026quot;模式，然后再阻塞。\n处于饥饿模式下，不会启动自旋过程，也即一旦有协程释放了锁，那么一定会唤醒协程，被唤醒的协程将会成功获取锁，同时也会把等待计数减1。\nWoken状态 Woken状态用于加锁和解锁过程的通信，举个例子，同一时刻，两个协程一个在加锁，一个在解锁，在加锁的协程可能在自旋过程中，此时把Woken标记为1，用于通知解锁协程不必释放信号量了，好比在说：你只管解锁好了，不必释放信号量，我马上就拿到锁了。\n为什么重复解锁要panic 可能你会想，为什么Go不能实现得更健壮些，多次执行Unlock()也不要panic？\n仔细想想Unlock的逻辑就可以理解，这实际上很难做到。Unlock过程分为将Locked置为0，然后判断Waiter值，如果值\u0026gt;0，则释放信号量。\n如果多次Unlock()，那么可能每次都释放一个信号量，这样会唤醒多个协程，多个协程唤醒后会继续在Lock()的逻辑里抢锁，势必会增加Lock()实现的复杂度，也会引起不必要的协程切换。\n编程Tips 7.1 使用defer避免死锁：加锁后立即使用defer对其解锁，可以有效的避免死锁。 7.2 加锁和解锁应该成对出现：加锁和解锁最好出现在同一个层次的代码块中，比如同一个函数。\n重复解锁会引起panic，应避免这种操作的可能性。\nGo 读写锁的实现原理 读写锁数据结构 读写锁RWMutex，完整的表述应该是读写互斥锁，可以说是Mutex的一个改进版，在某些场景下可以发挥更加灵活的控制能力，比如：读取数据频率远远大于写数据频率的场景。\n例如，程序中写操作少而读操作多，简单的说，如果执行过程是1次写然后N次读的话，使用Mutex，这个过程将是串行的，因为即便N次读操作互相之间并不影响，但也都需要持有Mutex后才可以操作。如果使用读写锁，多个读操作可以同时持有锁，并发能力将大大提升。\n实现读写锁需要解决如下几个问题：\n写锁需要阻塞写锁：一个协程拥有写锁时，其他协程写锁定需要阻塞 写锁需要阻塞读锁：一个协程拥有写锁时，其他协程读锁定需要阻塞 读锁需要阻塞写锁：一个协程拥有读锁时，其他协程写锁定需要阻塞 读锁不能阻塞读锁：一个协程拥有读锁时，其他协程也可以拥有读锁 下面我们将按照这个思路，即读写锁如何解决这些问题的，来分析读写锁的实现。\n读写锁基于Mutex实现，实现源码非常简单和简洁，又有一定的技巧在里面。\n2.1 类型定义 源码包src/sync/rwmutex.go:RWMutex定义了读写锁数据结构：\ntype RWMutex struct { w Mutex //用于控制多个写锁，获得写锁首先要获取该锁，如果有一个写锁在进行，那么再到来的写锁将会阻塞于此 writerSem uint32 //写阻塞等待的信号量，最后一个读者释放锁时会释放信号量 readerSem uint32 //读阻塞的协程等待的信号量，持有写锁的协程释放锁后会释放信号量 readerCount int32 //记录读者个数 readerWait int32 //记录写阻塞时读者个数 } 由以上数据结构可见，读写锁内部仍有一个互斥锁，用于将两个写操作隔离开来，其他的几个都用于隔离读操作和写操作。\n下面我们简单看下RWMutex提供的4个接口，后面再跟据使用场景具体分析这几个成员是如何配合工作的。\n2.2 接口定义 RWMutex提供4个简单的接口来提供服务：\nRLock()：读锁定 RUnlock()：解除读锁定 Lock(): 写锁定，与Mutex完全一致 Unlock()：解除写锁定，与Mutex完全一致 2.2.1 Lock()实现逻辑 写锁定操作需要做两件事：\n获取互斥锁 阻塞等待所有读操作结束（如果有的话） 所以func (rw *RWMutex) Lock()接口实现\nconst rwmutexMaxReaders = 1 \u0026lt;\u0026lt; 30 func (rw *RWMutex) Lock() { // First, resolve competition with other writers. rw.w.Lock() // Announce to readers there is a pending writer. r := atomic.AddInt32(\u0026amp;rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders // Wait for active readers. if r != 0 \u0026amp;\u0026amp; atomic.AddInt32(\u0026amp;rw.readerWait, r) != 0 { runtime_Semacquire(\u0026amp;rw.writerSem) } } 首先调用互斥锁的 lock，获取到互斥锁之后，如果计算之后当前仍然有其他 goroutine 持有读锁，那么就调用 runtime_SemacquireMutex 休眠当前的 goroutine 等待所有的读操作完成\n2.2.2 Unlock()实现逻辑 解除写锁定要做两件事：\n唤醒因读锁定而被阻塞的协程（如果有的话） 解除互斥锁 所以func (rw *RWMutex) Unlock()接口实现\nfunc (rw *RWMutex) Unlock() { // Announce to readers there is no active writer. r := atomic.AddInt32(\u0026amp;rw.readerCount, rwmutexMaxReaders) // Unblock blocked readers, if any. for i := 0; i \u0026lt; int(r); i++ { runtime_Semrelease(\u0026amp;rw.readerSem, false) } // Allow other writers to proceed. rw.w.Unlock() } 2.2.3 RLock()实现逻辑 读锁定需要做两件事：\n增加读操作计数，即readerCount++ 阻塞等待写操作结束(如果有的话) 所以func (rw *RWMutex) RLock()接口实现\nfunc (rw *RWMutex) RLock() { // 为什么readerCount会小于0呢？往下看发现writer的Lock()会对readerCount做减法操作（原子操作） if atomic.AddInt32(\u0026amp;rw.readerCount, 1) \u0026lt; 0 { // A writer is pending, wait for it. runtime_Semacquire(\u0026amp;rw.readerSem) } } atomic.AddInt32(\u0026amp;rw.readerCount, 1) 调用这个原子方法，对当前在读的数量加1，如果返回负数，那么说明当前有其他写锁，这时候就调用 runtime_SemacquireMutex 休眠当前goroutine 等待被唤醒\n2.2.4 RUnlock()实现逻辑 解除读锁定需要做两件事：\n减少读操作计数，即readerCount-- 唤醒等待写操作的协程（如果有的话） 所以func (rw *RWMutex) RUnlock()接口实现\n解锁的时候对正在读的操作减1，如果返回值小于 0 那么说明当前有在写的操作，这个时候调用 rUnlockSlow 进入慢速通道\nfunc (rw *RWMutex) RUnlock() { if r := atomic.AddInt32(\u0026amp;rw.readerCount, -1); r \u0026lt; 0 { rw.rUnlockSlow(r) } } 被阻塞的准备读的 goroutine 的数量减1，readerWait 为 0，就表示当前没有正在准备读的 goroutine 这时候调用 runtime_Semrelease 唤醒写操作\nfunc (rw *RWMutex) rUnlockSlow(r int32) { // A writer is pending. if atomic.AddInt32(\u0026amp;rw.readerWait, -1) == 0 { // The last reader unblocks the writer. runtime_Semrelease(\u0026amp;rw.writerSem, false, 1) } } 注意：即便有协程阻塞等待写操作，并不是所有的解除读锁定操作都会唤醒该协程，而是最后一个解除读锁定的协程才会释放信号量将该协程唤醒，因为只有当所有读操作的协程释放锁后才可以唤醒协程。\n场景分析 上面我们简单看了下4个接口实现原理，接下来我们看一下是如何解决前面提到的几个问题的。\n3.1 写操作是如何阻止写操作的 读写锁包含一个互斥锁(Mutex)，写锁定必须要先获取该互斥锁，如果互斥锁已被协程A获取（或者协程A在阻塞等待读结束），意味着协程A获取了互斥锁，那么协程B只能阻塞等待该互斥锁。\n所以，写操作依赖互斥锁阻止其他的写操作。\n3.2 写操作是如何阻止读操作的 这个是读写锁实现中最精华的技巧。\n我们知道RWMutex.readerCount是个整型值，用于表示读者数量，不考虑写操作的情况下，每次读锁定将该值+1，每次解除读锁定将该值-1，所以readerCount取值为[0, N]，N为读者个数，实际上最大可支持2^30个并发读者。\n当写锁定进行时，会先将readerCount减去2^30，从而readerCount变成了负值，此时再有读锁定到来时检测到readerCount为负值，便知道有写操作在进行，只好阻塞等待。而真实的读操作个数并不会丢失，只需要将readerCount加上2^30即可获得。\n所以，写操作将readerCount变成负值来阻止读操作的。\n3.3 读操作是如何阻止写操作的 读锁定会先将RWMutext.readerCount加1，此时写操作到来时发现读者数量不为0，会阻塞等待所有读操作结束。\n所以，读操作通过readerCount来将来阻止写操作的。\n3.4 为什么写锁定不会被饿死 我们知道，写操作要等待读操作结束后才可以获得锁，写操作等待期间可能还有新的读操作持续到来，如果写操作等待所有读操作结束，很可能被饿死。然而，通过RWMutex.readerWait可完美解决这个问题。\n写操作到来时，会把RWMutex.readerCount值拷贝到RWMutex.readerWait中，用于标记排在写操作前面的读者个数。\n前面的读操作结束后，除了会递减RWMutex.readerCount，还会递减RWMutex.readerWait值，当RWMutex.readerWait值变为0时唤醒写操作。\n所以，写操作就相当于把一段连续的读操作划分成两部分，前面的读操作结束后唤醒写操作，写操作结束后唤醒后面的读操作。如下图所示：\nGo 原子操作 Go atomic包是最轻量级的锁（也称无锁结构），可以在不形成临界区和创建互斥量的情况下完成并发安全的值替换操作，不过这个包只支持int32/int64/uint32/uint64/uintptr这几种数据类型的一些基础操作（增减、交换、载入、存储等）\n概念 原子操作仅会由一个独立的CPU指令代表和完成。原子操作是无锁的，常常直接通过CPU指令直接实现。 事实上，其它同步技术的实现常常依赖于原子操作。\n使用场景 当我们想要对某个变量并发安全的修改，除了使用官方提供的 mutex，还可以使用 sync/atomic 包的原子操作，它能够保证对变量的读取或修改期间不被其他的协程所影响。\natomic 包提供的原子操作能够确保任一时刻只有一个goroutine对变量进行操作，善用 atomic 能够避免程序中出现大量的锁操作。\n常见操作\n增减Add 载入Load 比较并交换CompareAndSwap 交换Swap 存储Store atomic 操作的对象是一个地址，你需要把可寻址的变量的地址作为参数传递给方法，而不是把变量的值传递给方法\n","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-mutex%E7%AF%87/","summary":"Go 互斥锁的实现原理？ 互斥锁是并发程序中对共享资源进行访问控制的主要手段，对此Go语言提供了非常简单易用的Mutex，Mutex为一结构体类型，对外暴露两个方法Lock()和Unlock()分别用于加锁和解锁。 Mutex使用起来非常方便，但其内部实现却复杂得多，这包括Mutex的几","title":"Go Mutex篇"},{"content":"1. map数据结构 Golang的map使用哈希表作为底层实现，一个哈希表里可以有多个哈希表节点，也即bucket，而每个bucket就保存了map中的一个或一组键值对。\nmap数据结构由runtime/map.go/hmap定义:\n// A header for a Go map. type hmap struct { count int // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。 flags uint8 // 状态标志（是否处于正在写入的状态等） B uint8 // buckets（桶）的对数 // 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶 buckets unsafe.Pointer // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。 oldbuckets unsafe.Pointer // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。 nevacuate uintptr // 表示扩容进度，小于此地址的buckets代表已搬迁完成。 extra *mapextra // 存储溢出桶，这个字段是为了优化GC扫描而设计的 } 2. bucket数据结构 bucket数据结构由runtime/map.go/bmap定义：\ntype bmap struct { tophash [8]uint8 //存储哈希值的高8位 data byte[1] //key value数据:key/key/key/.../value/value/value... overflow *bmap //溢出bucket的地址 } 每个bucket可以存储8个键值对。\ntophash是个长度为8的数组，哈希值相同的键（准确的说是哈希值低位相同的键）存入当前bucket时会将哈希值的高位存储在该数组中，以方便后续匹配。 data区存放的是key-value数据，存放顺序是key/key/key/\u0026hellip;value/value/value，如此存放是为了节省字节对齐带来的空间浪费。 overflow 指针指向的是下一个bucket，据此将所有冲突的键连接起来。 注意：上述中data和overflow并不是在结构体中显示定义的，而是直接通过指针运算进行访问的。 3. 哈希冲突 当有两个或以上数量的键被哈希到了同一个bucket时，我们称这些键发生了冲突。Go使用链地址法来解决键冲突。 由于每个bucket可以存放8个键值对，所以同一个bucket存放超过8个键值对时就会再创建一个键值对，用类似链表的方式将bucket连接起来。\n4. 负载因子 负载因子用于衡量一个哈希表冲突情况，公式为：\n负载因子 = 键数量/bucket数量\n例如，对于一个bucket数量为4，包含4个键值对的哈希表来说，这个哈希表的负载因子为1.\n哈希表需要将负载因子控制在合适的大小，超过其阀值需要进行rehash，也即键值对重新组织：\n哈希因子过小，说明空间利用率低 哈希因子过大，说明冲突严重，存取效率低 每个哈希表的实现对负载因子容忍程度不同，比如Redis实现中负载因子大于1时就会触发rehash，而Go则在在负载因子达到6.5时才会触发rehash，因为Redis的每个bucket只能存1个键值对，而Go的bucket可能存8个键值对，所以Go可以容忍更高的负载因子。\n5. 渐进式扩容 5.1 扩容的前提条件 为了保证访问效率，当新元素将要添加进map时，都会检查是否需要扩容，扩容实际上是以空间换时间的手段。 触发扩容的条件有二个：\n负载因子 \u0026gt; 6.5时，也即平均每个bucket存储的键值对达到6.5个。 overflow数量 \u0026gt; 2^15时，也即overflow数量超过32768时。\n5.2 增量扩容 当负载因子过大时，就新建一个bucket，新的bucket长度是原来的2倍，然后旧bucket数据搬迁到新的bucket。\n考虑到如果map存储了数以亿计的key-value，一次性搬迁将会造成比较大的延时\nGo采用逐步搬迁策略，即每次访问map时都会触发一次搬迁，每次搬迁2个键值对。\n5.3 等量扩容 所谓等量扩容，实际上并不是扩大容量，buckets数量不变，重新做一遍类似增量扩容的搬迁动作，把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。 在极端场景下，比如不断的增删，而键值对正好集中在一小部分的bucket，这样会造成overflow的bucket数量增多，但负载因子又不高，从而无法执行增量搬迁的情况\n6. 查找过程 查找过程如下：\n跟据key值算出哈希值 取哈希值低位与hmpa.B取模确定bucket位置 取哈希值高位在tophash数组中查询 如果tophash[i]中存储值也哈希值相等，则去找到该bucket中的key值进行比较 当前bucket没有找到，则继续从下个overflow的bucket中查找。 如果当前处于搬迁过程，则优先从oldbuckets查找 注：如果查找不到，也不会返回空值，而是返回相应类型的0值。\n7. 插入过程 新员素插入过程如下：\n跟据key值算出哈希值 取哈希值低位与hmap.B取模确定bucket位置 查找该key是否已经存在，如果存在则直接更新值 如果没找到将key，将key插入 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-map%E7%AF%87/","summary":"1. map数据结构 Golang的map使用哈希表作为底层实现，一个哈希表里可以有多个哈希表节点，也即bucket，而每个bucket就保存了map中的一个或一组键值对。 map数据结构由runtime/map.go/hmap定义: // A header for a Go map. type hmap struct { count int // 代表哈希表中的元素个数，调","title":"Go Map篇"},{"content":"Go goroutine 的底层实现原理 概念 Goroutine 可以理解为一种 Go 语言的协程（轻量级线程），是 Go 支持高并发的基础，属于用户态的线程，由 Go runtime 管理而不是操作系统。\n底层数据结构 type g struct { goid int64 // 唯一的goroutine的ID sched gobuf // goroutine切换时，用于保存g的上下文 stack stack // 栈 gopc // pc of go statement that created this goroutine startpc uintptr // pc of goroutine function ... } type gobuf struct { sp uintptr // 栈指针位置 pc uintptr // 运行到的程序位置 g guintptr // 指向 goroutine ret uintptr // 保存系统调用的返回值 ... } type stack struct { lo uintptr // 栈的下界内存地址 hi uintptr // 栈的上界内存地址 } 最终有一个 runtime.g 对象放入调度队列\n状态流转 状态 含义 空闲中_Gidle G 刚刚新建, 仍未初始化 待运行_Grunnable 就绪状态，G 在运行队列中, 等待 M 取出并运行 运行中_Grunning M 正在运行这个 G, 这时候 M 会拥有一个 P 系统调用中_Gsyscall M 正在运行这个 G 发起的系统调用, 这时候 M 并不拥有 P 等待中_Gwaiting G 在等待某些条件完成, 这时候 G 不在运行也不在运行队列中(可能在 channel 的等待队列中) 已中止_Gdead G 未被使用, 可能已执行完毕 栈复制中_Gcopystack G 正在获取一个新的栈空间并把原来的内容复制过去(用于防止 GC 扫描) 创建 通过 go 关键字调用底层函数 runtime.newproc()创建一个 goroutine\n当调用该函数之后，goroutine 会被设置成 runnable 状态\nfunc main() { go func() { fmt.Println(\u0026#34;func routine\u0026#34;) }() fmt.Println(\u0026#34;main goroutine\u0026#34;) } 创建好的这个 goroutine 会新建一个自己的栈空间，同时在 G 的 sched 中维护栈地址与程序计数器这些信息。\n每个 G 在被创建之后，都会被优先放入到本地队列中，如果本地队列已经满了，就会被放入到全局队列中。\n运行 goroutine 本身只是一个数据结构，真正让 goroutine 运行起来的是调度器。Go 实现了一个用户态的调度器（GMP 模型），这个调度器充分利用现代计算机的多核特性，同时让多个 goroutine 运行，同时 goroutine 设计的很轻量级，调度和上下文切换的代价都比较小。\n调度时机：\n新起一个协程和协程执行完毕 会阻塞的系统调用，比如文件 io、网络 io channel、mutex 等阻塞操作 time.sleep 垃圾回收之后 主动调用 runtime.Gosched() 运行过久或系统调用过久等等 每个 M 开始执行 P 的本地队列中的 G 时，goroutine 会被设置成 running 状态 如果某个 M 把本地队列中的 G 都执行完成之后，然后就会去全局队列中拿 G，这里需要注意，每次去全局队列拿 G 的时候，都需要上锁，避免同样的任务被多次拿。\n如果全局队列都被拿完了，而当前 M 也没有更多的 G 可以执行的时候，它就会去其他 P 的本地队列中拿任务，这个机制被称之为 work stealing 机制，每次会拿走一半的任务，向下取整，比如另一个 P 中有 3 个任务，那一半就是一个任务。\n当全局队列为空，M 也没办法从其他的 P 中拿任务的时候，就会让自身进入自选状态，等待有新的 G 进来。最多只会有 GOMAXPROCS 个 M 在自旋状态，过多 M 的自旋会浪费 CPU 资源。\n阻塞 channel 的读写操作、等待锁、等待网络数据、系统调用等都有可能发生阻塞，会调用底层函数 runtime.gopark()，会让出 CPU 时间片，让调度器安排其它等待的任务运行，并在下次某个时候从该位置恢复执行。\n当调用该函数之后，goroutine 会被设置成 waiting 状态\n唤醒 处于 waiting 状态的 goroutine，在调用 runtime.goready()函数之后会被唤醒，唤醒的 goroutine 会被重新放到 M 对应的上下文 P 对应的 runqueue 中，等待被调度。\n当调用该函数之后，goroutine 会被设置成 runnable 状态\n退出 当 goroutine 执行完成后，会调用底层函数 runtime.Goexit()\n当调用该函数之后，goroutine 会被设置成 dead 状态\nGo goroutine和线程的区别 goroutine 线程 内存占用 创建一个 goroutine 的栈内存消耗为 2 KB，实际运行过程中，如果栈空间不够用，会自动进行扩容 创建一个 线程 的栈内存消耗为 1 MB 创建和销毀 goroutine 因为是由 Go runtime 负责管理的，创建和销毁的消耗非常小，是用户级。 线程 创建和销毀都会有巨大的消耗，因为要和操作系统打交道，是内核级的，通常解决的办法就是线程池 切换 goroutines 切换只需保存三个寄存器：PC、SP、BP goroutine 的切换约为 200 ns，相当于 2400-3600 条指令。 当线程切换时，需要保存各种寄存器，以便恢复现场。 线程切换会消耗 1000-1500 ns，相当于 12000-18000 条指令。 Go goroutine泄露的场景? 泄露原因 Goroutine 内进行channel/mutex 等读写操作被一直阻塞。 Goroutine 内的业务逻辑进入死循环，资源一直无法释放。 Goroutine 内的业务逻辑进入长时间等待，有不断新增的 Goroutine 进入等待 泄露场景 如果输出的 goroutines 数量是在不断增加的，就说明存在泄漏\nnil channel\nchannel 如果忘记初始化，那么无论你是读，还是写操作，都会造成阻塞。\nfunc main() { fmt.Println(\u0026#34;before goroutines: \u0026#34;, runtime.NumGoroutine()) block1() time.Sleep(time.Second * 1) fmt.Println(\u0026#34;after goroutines: \u0026#34;, runtime.NumGoroutine()) } func block1() { var ch chan int for i := 0; i \u0026lt; 10; i++ { go func() { \u0026lt;-ch }() } } 输出结果：\nbefore goroutines: 1 after goroutines: 11 发送不接收\nchannel 发送数量 超过 channel接收数量，就会造成阻塞\nfunc block2() { ch := make(chan int) for i := 0; i \u0026lt; 10; i++ { go func() { ch \u0026lt;- 1 }() } } 接收不发送\nchannel 接收数量 超过 channel发送数量，也会造成阻塞\nfunc block3() { ch := make(chan int) for i := 0; i \u0026lt; 10; i++ { go func() { \u0026lt;-ch }() } } http request body未关闭\nresp.Body.Close() 未被调用时，goroutine不会退出\nfunc requestWithNoClose() { _, err := http.Get(\u0026#34;https://www.baidu.com\u0026#34;) if err != nil { fmt.Println(\u0026#34;error occurred while fetching page, error: %s\u0026#34;, err.Error()) } } func requestWithClose() { resp, err := http.Get(\u0026#34;https://www.baidu.com\u0026#34;) if err != nil { fmt.Println(\u0026#34;error occurred while fetching page, error: %s\u0026#34;, err.Error()) return } defer resp.Body.Close() } func block4() { for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { defer wg.Done() requestWithNoClose() }() } } var wg = sync.WaitGroup{} func main() { block4() wg.Wait() } 一般发起http请求时，需要确保关闭body\ndefer resp.Body.Close() 互斥锁忘记解锁\n第一个协程获取 sync.Mutex 加锁了，但是他可能在处理业务逻辑，又或是忘记 Unlock 了。\n因此导致后面的协程想加锁，却因锁未释放被阻塞了\nfunc block5() { var mutex sync.Mutex for i := 0; i \u0026lt; 10; i++ { go func() { mutex.Lock() }() } } sync.WaitGroup使用不当\n由于 wg.Add 的数量与 wg.Done 数量并不匹配，因此在调用 wg.Wait 方法后一直阻塞等待\nfunc block6() { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { go func() { wg.Add(2) wg.Done() wg.Wait() }() } } 如何排查 单个函数：调用 runtime.NumGoroutine 方法来打印 执行代码前后Goroutine 的运行数量，进行前后比较，就能知道有没有泄露了。\n生产/测试环境：使用PProf实时监测Goroutine的数量\n在程序中引入pprof package：\nimport _ \u0026#34;net/http/pprof\u0026#34; 程序中开启HTTP监听服务：\npackage main import ( \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) func main() { for i := 0; i \u0026lt; 100; i++ { go func() { select {} }() } go func() { http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil) }() select {} } 分析goroutine文件\n在命令行下执行：\ngo tool pprof -http=:1248 http://127.0.0.1:6060/debug/pprof/goroutine Go 如何控制并发的goroutine数量 为什么要控制goroutine并发的数量？\n在开发过程中，如果不对goroutine加以控制而进行滥用的话，可能会导致服务整体崩溃。比如耗尽系统资源导致程序崩溃，或者CPU使用率过高导致系统忙不过来。\n用什么方法控制goroutine并发的数量？\n有缓冲channel 利用缓冲满时发送阻塞的特性\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; ) var wg = sync.WaitGroup{} func main() { // 模拟用户请求数量 requestCount := 10 fmt.Println(\u0026#34;goroutine_num\u0026#34;, runtime.NumGoroutine()) // 管道长度即最大并发数 ch := make(chan bool, 3) for i := 0; i \u0026lt; requestCount; i++ { wg.Add(1) ch \u0026lt;- true go Read(ch, i) } wg.Wait() } func Read(ch chan bool, i int) { fmt.Printf(\u0026#34;goroutine_num: %d, go func: %d\\n\u0026#34;, runtime.NumGoroutine(), i) \u0026lt;-ch wg.Done() } 输出结果：默认最多不超过3（4-1）个goroutine并发执行\ngoroutine_num 1 goroutine_num: 4, go func: 1 goroutine_num: 4, go func: 3 goroutine_num: 4, go func: 2 goroutine_num: 4, go func: 0 goroutine_num: 4, go func: 4 goroutine_num: 4, go func: 5 goroutine_num: 4, go func: 6 goroutine_num: 4, go func: 8 goroutine_num: 4, go func: 9 goroutine_num: 4, go func: 7 无缓冲channel 任务发送和执行分离，指定消费者并发协程数\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;sync\u0026#34; ) var wg = sync.WaitGroup{} func main() { // 模拟用户请求数量 requestCount := 10 fmt.Println(\u0026#34;goroutine_num\u0026#34;, runtime.NumGoroutine()) ch := make(chan bool) for i := 0; i \u0026lt; 3; i++ { go Read(ch, i) } for i := 0; i \u0026lt; requestCount; i++ { wg.Add(1) ch \u0026lt;- true } wg.Wait() } func Read(ch chan bool, i int) { for _ = range ch { fmt.Printf(\u0026#34;goroutine_num: %d, go func: %d\\n\u0026#34;, runtime.NumGoroutine(), i) wg.Done() } } ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-goroutine%E7%AF%87/","summary":"Go goroutine 的底层实现原理 概念 Goroutine 可以理解为一种 Go 语言的协程（轻量级线程），是 Go 支持高并发的基础，属于用户态的线程，由 Go runtime 管理而不是操作系统。 底层数据结构 type g struct { goid int64 // 唯一的goroutine的ID sched gobuf // goroutine切换时，用于保存g的上下文 stack stack // 栈 gopc // pc of go statement that created this goroutine startpc uintptr // pc of goroutine function","title":"Go Goroutine篇"},{"content":"Go channel 的底层实现原理 概念：\nGo 中的 channel 是一个队列，遵循先进先出的原则，负责协程之间的通信（Go 语言提倡不要通过共享内存来通信，而要通过通信来实现内存共享，CSP(Communicating Sequential Process)并发模型，就是通过 goroutine 和 channel 来实现的）\n使用场景：\n停止信号监听\n定时任务\n生产方和消费方解耦\n控制并发数\n底层数据结构：\n通过 var 声明或者 make 函数创建的 channel 变量是一个存储在函数栈帧上的指针，占用 8 个字节，指向堆上的 hchan 结构体\n源码包中 src/runtime/chan.go 定义了 hchan 的数据结构：\nhchan hchan 结构体：\ntype hchan struct { closed uint32 // channel是否关闭的标志 elemtype *_type // channel中的元素类型 // channel分为无缓冲和有缓冲两种。 // 对于有缓冲的channel存储数据，使用了 ring buffer（环形缓冲区) 来缓存写入的数据，本质是循环数组 // 为啥是循环数组？普通数组不行吗，普通数组容量固定更适合指定的空间，弹出元素时，普通数组需要全部都前移 // 当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置 buf unsafe.Pointer // 指向底层循环数组的指针（环形缓冲区） qcount uint // 循环数组中的元素数量 dataqsiz uint // 循环数组的长度 elemsize uint16 // 元素的大小 sendx uint // 下一次写下标的位置 recvx uint // 下一次读下标的位置 // 尝试读取channel或向channel写入数据而被阻塞的goroutine recvq waitq // 读等待队列 sendq waitq // 写等待队列 lock mutex //互斥锁，保证读写channel时不存在并发竞争问题 } 等待队列：\n双向链表，包含一个头结点和一个尾结点\n每个节点是一个 sudog 结构体变量，记录哪个协程在等待，等待的是哪个 channel，等待发送/接收的数据在哪里\ntype waitq struct { first *sudog last *sudog } type sudog struct { g *g next *sudog prev *sudog elem unsafe.Pointer c *hchan ... } 操作：\n创建 使用 make(chan T, cap) 来创建 channel，make 语法会在编译时，转换为 makechan64 和 makechan\nfunc makechan64(t *chantype, size int64) *hchan { if int64(int(size)) != size { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } return makechan(t, int(size)) } 创建 channel 有两种，一种是带缓冲的 channel，一种是不带缓冲的 channel\n// 带缓冲\nch := make(chan int, 3)\n// 不带缓冲\nch := make(chan int)\n创建时会做一些检查:\n元素大小不能超过 64K 元素的对齐大小不能超过 maxAlign 也就是 8 字节 计算出来的内存是否超过限制 创建时的策略:\n如果是无缓冲的 channel，会直接给 hchan 分配内存 如果是有缓冲的 channel，并且元素不包含指针，那么会为 hchan 和底层数组分配一段连续的地址 如果是有缓冲的 channel，并且元素包含指针，那么会为 hchan 和底层数组分别分配地址 发送 发送操作，编译时转换为 runtime.chansend 函数\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool\n阻塞式：\n调用 chansend 函数，并且 block=true\nch \u0026lt;- 10\n非阻塞式：\n调用 chansend 函数，并且 block=false\nselect { case ch \u0026lt;- 10: ... default } 向 channel 中发送数据时大概分为两大块：检查和数据发送，数据发送流程如下：\n如果 channel 的读等待队列存在接收者 goroutine\n将数据直接发送给第一个等待的 goroutine， 唤醒接收的 goroutine 如果 channel 的读等待队列不存在接收者 goroutine\n如果循环数组 buf 未满，那么将会把数据发送到循环数组 buf 的队尾 如果循环数组 buf 已满，这个时候就会走阻塞发送的流程，将当前 goroutine 加入写等待队列，并挂起等待唤醒 接收 接受操作，编译时转换为 runtime.chanrecv 函数\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool)\n阻塞式：\n调用 chanrecv 函数，并且 block=true\n\u0026lt;-ch v := \u0026lt;ch v, ok := \u0026lt;ch // 当 channel 关闭时，for 循环会自动退出，无需主动监测 channel 是否关闭，可以防止读取已经关闭的 channel,造成读到数据为通道所存储的数据类型的零值 for i := range ch { fmt.Println(i) } 非阻塞式：\n调用 chanrecv 函数，并且 block=false\nselect { case \u0026lt;-ch: ... default } 向 channel 中接收数据时大概分为两大块，检查和数据发送，而数据接收流程如下：\n如果 channel 的写等待队列存在发送者 goroutine\n如果是无缓冲 channel，直接从第一个发送者 goroutine 那里把数据拷贝给接收变量，唤醒发送的 goroutine 如果是有缓冲 channel（已满），将循环数组 buf 的队首元素拷贝给接收变量，将第一个发送者 goroutine 的数据拷贝到 buf 循环数组队尾，唤醒发送的 goroutine 如果 channel 的写等待队列不存在发送者 goroutine\n如果循环数组 buf 非空，将循环数组 buf 的队首元素拷贝给接收变量 如果循环数组 buf 为空，这个时候就会走阻塞接收的流程，将当前 goroutine 加入读等待队列，并挂起等待唤醒 关闭 关闭操作，调用 close 函数，编译时转换为 runtime.closechan 函数\nclose(ch)\nfunc closechan(c *hchan)\n案例分析：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { // ch 是长度为 4 的带缓冲的 channel // 初始 hchan 结构体重的 buf 为空，sendx 和 recvx 均为 0 ch := make(chan string, 4) fmt.Println(ch, unsafe.Sizeof(ch)) go sendTask(ch) go receiveTask(ch) time.Sleep(1 \\* time.Second) } // G1 是发送者 // 当 G1 向 ch 里发送数据时，首先会对 buf 加锁，然后将 task 存储的数据 copy 到 buf 中，然后 sendx++，然后释放对 buf 的锁 func sendTask(ch chan string) { taskList := []string{\u0026#34;this\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;demo\u0026#34;} for \\_, task := range taskList { ch \u0026lt;- task //发送任务到 channel } } // G2 是接收者 // 当 G2 消费 ch 的时候，会首先对 buf 加锁，然后将 buf 中的数据 copy 到 task 变量对应的内存里，然后 recvx++,并释放锁 func receiveTask(ch chan string) { for { task := \u0026lt;-ch //接收任务 fmt.Println(\u0026#34;received\u0026#34;, task) //处理任务 } } 总结 hchan 结构体的主要组成部分有四个：\n用来保存 goroutine 之间传递数据的循环数组：buf 用来记录此循环数组当前发送或接收数据的下标值：sendx 和 recvx 用于保存向该 chan 发送和从该 chan 接收数据被阻塞的 goroutine 队列： sendq 和 recvq 保证 channel 写入和读取数据时线程安全的锁：lock Go channel有无缓冲的区别 无缓冲：一个送信人去你家送信，你不在家他不走，你一定要接下信，他才会走。\n有缓冲：一个送信人去你家送信，扔到你家的信箱转身就走，除非你的信箱满了，他必须等信箱有多余空间才会走。\n无缓冲 有缓冲 创建方式 make(chan TYPE) make(chan TYPE, SIZE) 发送阻塞 数据接收前发送阻塞 缓冲满时发送阻塞 接收阻塞 数据发送前接收阻塞 缓冲空时接收阻塞 非缓冲 channel\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func loop(ch chan int) { for { select { case i := \u0026lt;-ch: fmt.Println(\u0026#34;this value of unbuffer channel\u0026#34;, i) } } } func main() { ch := make(chan int) ch \u0026lt;- 1 go loop(ch) time.Sleep(1 * time.Millisecond) } 这里会报错 fatal error: all goroutines are asleep - deadlock! 就是因为 ch\u0026lt;-1 发送了，但是同时没有接收者，所以就发生了阻塞\n但如果我们把 ch \u0026lt;- 1 放到 go loop(ch) 下面，程序就会正常运行\n缓冲 channel\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func loop(ch chan int) { for { select { case i := \u0026lt;-ch: fmt.Println(\u0026#34;this value of unbuffer channel\u0026#34;, i) } } } func main() { ch := make(chan int,3) ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 ch \u0026lt;- 4 go loop(ch) time.Sleep(1 * time.Millisecond) } 这里也会报 fatal error: all goroutines are asleep - deadlock! ，这是因为 channel 的大小为 3 ，而我们要往里面塞 4 个数据，所以就会阻塞住，解决的办法有两个:\n把 channel 长度调大一点 把 channel 的信息发送者 ch \u0026lt;- 1 这些代码移动到 go loop(ch) 下面 ，让 channel 实时消费就不会导致阻塞了 Go channel为什么是线程安全的？ 为什么设计成线程安全？\n不同协程通过channel进行通信，本身的使用场景就是多线程，为了保证数据的一致性，必须实现线程安全\n如何实现线程安全的？\nchannel的底层实现中，hchan结构体中采用Mutex锁来保证数据读写安全。在对循环数组buf中的数据进行入队和出队操作时，必须先获取互斥锁，才能操作channel数据\nGo channel如何控制goroutine并发执行顺序？ 多个goroutine并发执行时，每一个goroutine抢到处理器的时间点不一致，gorouine的执行本身不能保证顺序。即代码中先写的gorouine并不能保证先执行\n思路：使用channel进行通信通知，用channel去传递信息，从而控制并发执行顺序\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var wg sync.WaitGroup func main() { ch1 := make(chan struct{}, 1) ch2 := make(chan struct{}, 1) ch3 := make(chan struct{}, 1) ch1 \u0026lt;- struct{}{} wg.Add(3) start := time.Now().Unix() go print(\u0026#34;gorouine1\u0026#34;, ch1, ch2) go print(\u0026#34;gorouine2\u0026#34;, ch2, ch3) go print(\u0026#34;gorouine3\u0026#34;, ch3, ch1) wg.Wait() end := time.Now().Unix() fmt.Printf(\u0026#34;duration:%d\\n\u0026#34;, end-start) } func print(gorouine string, inputchan chan struct{}, outchan chan struct{}) { // 模拟内部操作耗时 time.Sleep(1 * time.Second) select { case \u0026lt;-inputchan: fmt.Printf(\u0026#34;%s\\n\u0026#34;, gorouine) outchan \u0026lt;- struct{}{} } wg.Done() } 输出：\ngorouine1\ngorouine2\ngorouine3\nduration:1\nGo channel共享内存有什么优劣势？ “不要通过共享内存来通信，我们应该使用通信来共享内存” 这句话想必大家已经非常熟悉了，在官方的博客，初学时的教程，甚至是在 Go 的源码中都能看到\n无论是通过共享内存来通信还是通过通信来共享内存，最终我们应用程序都是读取的内存当中的数据，只是前者是直接读取内存的数据，而后者是通过发送消息的方式来进行同步。而通过发送消息来同步的这种方式常见的就是 Go 采用的 CSP(Communication Sequential Process) 模型以及 Erlang 采用的 Actor 模型，这两种方式都是通过通信来共享内存。\n大部分的语言采用的都是第一种方式直接去操作内存，然后通过互斥锁，CAS 等操作来保证并发安全。Go 引入了 Channel 和 Goroutine 实现 CSP 模型将生产者和消费者进行了解耦，Channel 其实和消息队列很相似。而 Actor 模型和 CSP 模型都是通过发送消息来共享内存，但是它们之间最大的区别就是 Actor 模型当中并没有一个独立的 Channel 组件，而是 Actor 与 Actor 之间直接进行消息的发送与接收，每个 Actor 都有一个本地的“信箱”消息都会先发送到这个“信箱当中”。\n优点\n使用 channel 可以帮助我们解耦生产者和消费者，可以降低并发当中的耦合 缺点\n容易出现死锁的情况 Go channel发送和接收什么情况下会死锁？ 死锁：\n单个协程永久阻塞 两个或两个以上的协程的执行过程中，由于竞争资源或由于彼此通信而造成的一种阻塞的现象。 channel死锁场景：\n非缓存channel只写不读或者读在写后面 缓存channel写入超过缓冲区数量 空读 多个协程互相等待 1. 非缓存channel只写不读 func deadlock1() { ch := make(chan int) ch \u0026lt;- 3 // 这里会发生一直阻塞的情况，执行不到下面一句 } 2. 非缓存channel读在写后面 func deadlock2() { ch := make(chan int) ch \u0026lt;- 3 // 这里会发生一直阻塞的情况，执行不到下面一句 num := \u0026lt;-ch fmt.Println(\u0026#34;num=\u0026#34;, num) } func deadlock2() { ch := make(chan int) ch \u0026lt;- 100 // 这里会发生一直阻塞的情况，执行不到下面一句 go func() { num := \u0026lt;-ch fmt.Println(\u0026#34;num=\u0026#34;, num) }() time.Sleep(time.Second) } 3. 缓存channel写入超过缓冲区数量 func deadlock3() { ch := make(chan int, 3) ch \u0026lt;- 3 ch \u0026lt;- 4 ch \u0026lt;- 5 ch \u0026lt;- 6 // 这里会发生一直阻塞的情况 } 4. 空读 func deadlock4() { ch := make(chan int) // ch := make(chan int, 1) fmt.Println(\u0026lt;-ch) // 这里会发生一直阻塞的情况 } 5. 多个协程互相等待 func deadlock5() { ch1 := make(chan int) ch2 := make(chan int) // 互相等对方造成死锁 go func() { for { select { case num := \u0026lt;-ch1: fmt.Println(\u0026#34;num=\u0026#34;, num) ch2 \u0026lt;- 100 } } }() for { select { case num := \u0026lt;-ch2: fmt.Println(\u0026#34;num=\u0026#34;, num) ch1 \u0026lt;- 300 } } } ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-channel%E7%AF%87/","summary":"Go channel 的底层实现原理 概念： Go 中的 channel 是一个队列，遵循先进先出的原则，负责协程之间的通信（Go 语言提倡不要通过共享内存来通信，而要通过通信来实现内存共享，CSP(Communicating Sequential Process)并发模型，就是通过 goroutine 和 channel 来实现的） 使用场景： 停止信号监听 定时任务 生产方和消费方解","title":"Go Channel篇"},{"content":"Go 内存分配机制 Go语言内置运行时（就是runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。\n设计思想 内存分配算法采用Google的TCMalloc算法，每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向加锁向全局内存池申请，减少系统调用并且避免不同线程对全局内存池的锁竞争 把内存切分的非常的细小，分为多级管理，以降低锁的粒度 回收对象内存时，并没有将其真正释放掉，只是放回预先分配的大块内存中，以便复用。只有内存闲置过多的时候，才会尝试归还部分内存给操作系统，降低整体开销 分配组件 Go的内存管理组件主要有：mspan、mcache、mcentral和mheap\n内存管理单元：mspan mspan是 内存管理的基本单元，该结构体中包含 next 和 prev 两个字段，它们分别指向了前一个和后一个mspan，每个mspan 都管理 npages 个大小为 8KB 的页，一个span 是由多个page组成的，这里的页不是操作系统中的内存页，它们是操作系统内存页的整数倍。\npage是内存存储的基本单元，“对象”放到page中\ntype mspan struct { next *mspan // 后指针 prev *mspan // 前指针 startAddr uintptr // 管理页的起始地址，指向page npages uintptr // 页数 spanclass spanClass // 规格 ... } type spanClass uint8 Go有68种不同大小的spanClass，用于小对象的分配\nconst _NumSizeClasses = 68 var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536,1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} 如果按照序号为1的spanClass（对象规格为8B）分配，每个span占用堆的字节数：8k，mspan可以保存1024个对象\n如果按照序号为2的spanClass（对象规格为16B）分配，每个span占用堆的字节数：8k，mspan可以保存512个对象\n\u0026hellip;\n如果按照序号为67的spanClass（对象规格为32K）分配，每个span占用堆的字节数：32k，mspan可以保存1个对象\n字段含义：\nclass： class ID，每个span结构中都有一个class ID, 表示该span可处理的对象类型 bytes/obj：该class代表对象的字节数 bytes/span：每个span占用堆的字节数，也即页数*页大小 objects: 每个span可分配的对象个数，也即（bytes/spans）/（bytes/obj） waste bytes: 每个span产生的内存碎片，也即（bytes/spans）%（bytes/obj） 大于32k的对象出现时，会直接从heap分配一个特殊的span，这个特殊的span的类型(class)是0, 只包含了一个大对象\n线程缓存：mcache mcache管理线程在本地缓存的mspan，每个goroutine绑定的P都有一个mcache字段\ntype mcache struct { alloc [numSpanClasses]*mspan } _NumSizeClasses = 68 numSpanClasses = _NumSizeClasses \u0026lt;\u0026lt; 1 mcache用Span Classes作为索引管理多个用于分配的mspan，它包含所有规格的mspan。它是_NumSizeClasses的2倍，也就是68*2=136，其中*2是将spanClass分成了有指针和没有指针两种,方便与垃圾回收。对于每种规格，有2个mspan，一个mspan不包含指针，另一个mspan则包含指针。对于无指针对象的mspan在进行垃圾回收的时候无需进一步扫描它是否引用了其他活跃的对象。\nmcache在初始化的时候是没有任何mspan资源的，在使用过程中会动态地从mcentral申请，之后会缓存下来。当对象小于等于32KB大小时，使用mcache的相应规格的mspan进行分配。\n中心缓存：mcentral mcentral管理全局的mspan供所有线程使用，全局mheap变量包含central字段，每个 mcentral 结构都维护在mheap结构内\ntype mcentral struct { spanclass spanClass // 指当前规格大小 partial [2]spanSet // 有空闲object的mspan列表 full [2]spanSet // 没有空闲object的mspan列表 } 每个mcentral管理一种spanClass的mspan，并将有空闲空间和没有空闲空间的mspan分开管理。partial和 full的数据类型为spanSet，表示 mspans集，可以通过pop、push来获得mspans\ntype spanSet struct { spineLock mutex spine unsafe.Pointer // 指向[]span的指针 spineLen uintptr // Spine array length, accessed atomically spineCap uintptr // Spine array cap, accessed under lock index headTailIndex // 前32位是头指针，后32位是尾指针 } 简单说下mcache从mcentral获取和归还mspan的流程：\n获取； 加锁，从partial链表找到一个可用的mspan；并将其从partial链表删除；将取出的mspan加入到full链表；将mspan返回给工作线程，解锁。 归还； 加锁，将mspan从full链表删除；将mspan加入到partial链表，解锁。 页堆：mheap mheap管理Go的所有动态分配内存，可以认为是Go程序持有的整个堆空间，全局唯一\nvar mheap_ mheap type mheap struct { lock mutex // 全局锁 pages pageAlloc // 页面分配的数据结构 allspans []*mspan // 所有通过 mheap_ 申请的mspans // 堆 arenas [1 \u0026lt;\u0026lt; arenaL1Bits]*[1 \u0026lt;\u0026lt; arenaL2Bits]*heapArena // 所有中心缓存mcentral central [numSpanClasses]struct { mcentral mcentral pad [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte } ... } 所有mcentral的集合则是存放于mheap中的。mheap里的arena 区域是堆内存的抽象，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象。运行时使用二维的 runtime.heapArena 数组管理所有的内存，每个 runtime.heapArena 都会管理 64MB 的内存。\n当申请内存时，依次经过 mcache 和 mcentral 都没有可用合适规格的大小内存，这时候会向 mheap 申请一块内存。然后按指定规格划分为一些列表，并将其添加到相同规格大小的 mcentral 的 非空闲列表 后面\n分配对象 微对象 (0, 16B)：先使用线程缓存上的微型分配器，再依次尝试线程缓存、中心缓存、堆 分配内存； 小对象 [16B, 32KB]：依次尝试线程缓存、中心缓存、堆 分配内存； 大对象 (32KB, +∞)：直接尝试堆分配内存； 分配流程 首先通过计算使用的大小规格 然后使用mcache中对应大小规格的块分配。 如果mcentral中没有可用的块，则向mheap申请，并根据算法找到最合适的mspan。 如果申请到的mspan 超出申请大小，将会根据需求进行切分，以返回用户所需的页数。剩余的页构成一个新的 mspan 放回 mheap 的空闲列表。 如果 mheap 中没有可用 span，则向操作系统申请一系列新的页（最小 1MB） 2.Go 内存逃逸机制 概念 在一段程序中，每一个函数都会有自己的内存区域存放自己的局部变量、返回地址等，这些内存会由编译器在栈中进行分配，每一个函数都会分配一个栈桢，在函数运行结束后进行销毁，但是有些变量我们想在函数运行结束后仍然使用它，那么就需要把这个变量在堆上分配，这种从\u0026quot;栈\u0026quot;上逃逸到\u0026quot;堆\u0026quot;上的现象就成为内存逃逸。\n在栈上分配的地址，一般由系统申请和释放，不会有额外性能的开销，比如函数的入参、局部变量、返回值等。在堆上分配的内存，如果要回收掉，需要进行 GC，那么GC 一定会带来额外的性能开销。编程语言不断优化GC算法，主要目的都是为了减少 GC带来的额外性能开销，变量一旦逃逸会导致性能开销变大。\n逃逸机制 编译器会根据变量是否被外部引用来决定是否逃逸：\n如果函数外部没有引用，则优先放到栈中； 如果函数外部存在引用，则必定放到堆中; 如果栈上放不下，则必定放到堆上; 逃逸分析也就是由编译器决定哪些变量放在栈，哪些放在堆中，通过编译参数-gcflag=-m可以查看编译过程中的逃逸分析，发生逃逸的几种场景如下：\n指针逃逸 package main func escape1() *int { var a int = 1 return \u0026amp;a } func main() { escape1() } 通过go build -gcflags=-m main.go查看逃逸情况：\n./main.go:4:6: moved to heap: a 函数返回值为局部变量的指针，函数虽然退出了，但是因为指针的存在，指向的内存不能随着函数结束而回收，因此只能分配在堆上。\n栈空间不足 package main func escape2() { s := make([]int, 0, 10000) for index, _ := range s { s[index] = index } } func main() { escape2() } 通过go build -gcflags=-m main.go查看逃逸情况：\n./main.go:4:11: make([]int, 10000, 10000) escapes to heap 当栈空间足够时，不会发生逃逸，但是当变量过大时，已经完全超过栈空间的大小时，将会发生逃逸到堆上分配内存。局部变量s占用内存过大，编译器会将其分配到堆上\n变量大小不确定 package main func escape3() { number := 10 s := make([]int, number) // 编译期间无法确定slice的长度 for i := 0; i \u0026lt; len(s); i++ { s[i] = i } } func main() { escape3() } 编译期间无法确定slice的长度，这种情况为了保证内存的安全，编译器也会触发逃逸，在堆上进行分配内存。直接s := make([]int, 10)不会发生逃逸\n动态类型 动态类型就是编译期间不确定参数的类型、参数的长度也不确定的情况下就会发生逃逸\n空接口 interface{} 可以表示任意的类型，如果函数参数为 interface{}，编译期间很难确定其参数的具体类型，也会发生逃逸。\npackage main import \u0026#34;fmt\u0026#34; func escape4() { fmt.Println(1111) } func main() { escape4() } 通过go build -gcflags=-m main.go查看逃逸情况：\n./main.go:6:14: 1111 escapes to heap fmt.Println(a \u0026hellip;interface{})函数参数为interface，编译器不确定参数的类型，会将变量分配到堆上\n闭包引用对象 package main func escape5() func() int { var i int = 1 return func() int { i++ return i } } func main() { escape5() } 通过go build -gcflags=-m main.go查看逃逸情况：\n./main.go:4:6: moved to heap: i 闭包函数中局部变量i在后续函数是继续使用的，编译器将其分配到堆上\n总结 栈上分配内存比在堆中分配内存效率更高 栈上分配的内存不需要 GC 处理，而堆需要 逃逸分析目的是决定内分配地址是栈还是堆 逃逸分析在编译阶段完成 因为无论变量的大小，只要是指针变量都会在堆上分配，所以对于小变量我们还是使用传值效率（而不是传指针）更高一点。\nGo 内存对齐机制？ 参考文章\n什么是内存对齐 为了能让CPU可以更快的存取到各个字段，Go编译器会帮你把struct结构体做数据的对齐。所谓的数据对齐，是指内存地址是所存储数据大小（按字节为单位）的整数倍，以便CPU可以一次将该数据从内存中读取出来。 编译器通过在结构体的各个字段之间填充一些空白已达到对齐的目的。\n对齐系数 不同硬件平台占用的大小和对齐值都可能是不一样的，每个特定平台上的编译器都有自己的默认\u0026quot;对齐系数\u0026quot;，32位系统对齐系数是4，64位系统对齐系数是8\n不同类型的对齐系数也可能不一样，使用Go语言中的unsafe.Alignof函数可以返回相应类型的对齐系数，对齐系数都符合2^n这个规律，最大也不会超过8\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { fmt.Printf(\u0026#34;bool alignof is %d\\n\u0026#34;, unsafe.Alignof(bool(true))) fmt.Printf(\u0026#34;string alignof is %d\\n\u0026#34;, unsafe.Alignof(string(\u0026#34;a\u0026#34;))) fmt.Printf(\u0026#34;int alignof is %d\\n\u0026#34;, unsafe.Alignof(int(0))) fmt.Printf(\u0026#34;float alignof is %d\\n\u0026#34;, unsafe.Alignof(float64(0))) fmt.Printf(\u0026#34;int32 alignof is %d\\n\u0026#34;, unsafe.Alignof(int32(0))) fmt.Printf(\u0026#34;float32 alignof is %d\\n\u0026#34;, unsafe.Alignof(float32(0))) } 可以查看到各种类型在Mac 64位上的对齐系数如下：\nbool alignof is 1 string alignof is 8 int alignof is 8 int32 alignof is 4 float32 alignof is 4 float alignof is 8 优点 提高可移植性，有些CPU可以访问任意地址上的任意数据，而有些CPU只能在特定地址访问数据，因此不同硬件平台具有差异性，这样的代码就不具有移植性，如果在编译时，将分配的内存进行对齐，这就具有平台可以移植性了 提高内存的访问效率，32位CPU下一次可以从内存中读取32位（4个字节）的数据，64位CPU下一次可以从内存中读取64位（8个字节）的数据，这个长度也称为CPU的字长。CPU一次可以读取1个字长的数据到内存中，如果所需要读取的数据正好跨了1个字长，那就得花两个CPU周期的时间去读取了。因此在内存中存放数据时进行对齐，可以提高内存访问效率。 缺点 存在内存空间的浪费，实际上是空间换时间 结构体对齐 对齐原则：\n结构体变量中成员的偏移量必须是成员大小的整数倍 整个结构体的地址必须是最大字节的整数倍（结构体的内存占用是1/4/8/16byte\u0026hellip;) package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;unsafe\u0026#34; ) type T1 struct { i16 int16 // 2 byte bool bool // 1 byte } type T2 struct { i8 int8 // 1 byte i64 int64 // 8 byte i32 int32 // 4 byte } type T3 struct { i8 int8 // 1 byte i32 int32 // 4 byte i64 int64 // 8 byte } func main() { fmt.Println(runtime.GOARCH) // amd64 t1 := T1{} fmt.Println(unsafe.Sizeof(t1)) // 4 bytes t2 := T2{} fmt.Println(unsafe.Sizeof(t2)) // 24 bytes t3 := T3{} fmt.Println(unsafe.Sizeof(t3)) // 16 bytes } 以T1结构体为例，实际存储数据的只有3字节，但实际用了4字节，浪费了1个字节：\ni16并没有直接放在bool的后面，而是在bool中填充了一个空白后，放到了偏移量为2的位置上。如果i16从偏移量为1的位置开始占用2个字节，根据对齐原则2：构体变量中成员的偏移量必须是成员大小的整数倍，套用公式 1 % 2 = 1，就不满足对齐的要求，所以i16从偏移量为2的位置开始\n以T2结构体为例，实际存储数据的只有13字节，但实际用了24字节，浪费了11个字节：\n以T3结构体为例，实际存储数据的只有13字节，但实际用了16字节，浪费了3个字节：\nGo GC实现原理 什么是GC？ 垃圾回收也称为GC（Garbage Collection），是一种自动内存管理机制\n现代高级编程语言管理内存的方式分为两种：自动和手动，像C、C++ 等编程语言使用手动管理内存的方式，工程师编写代码过程中需要主动申请或者释放内存；而 PHP、Java 和 Go 等语言使用自动的内存管理系统，有内存分配器和垃圾收集器来代为分配和回收内存，其中垃圾收集器就是我们常说的GC。\n在应用程序中会使用到两种内存，分别为堆（Heap）和栈（Stack），GC负责回收堆内存，而不负责回收栈中的内存：\n栈是线程的专用内存，专门为了函数执行而准备的，存储着函数中的局部变量以及调用栈，函数执行完后，编译器可以将栈上分配的内存可以直接释放，不需要通过GC来回收。\n堆是程序共享的内存，需要GC进行回收在堆上分配的内存。\n垃圾回收器的执行过程被划分为两个半独立的组件：\n赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户态的代码仅仅只是在修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上进行操作。 回收器（Collector）：负责执行垃圾回收的代码。 主流GC算法 目前比较常见的垃圾回收算法有三种：\n引用计数：为每个对象维护一个引用计数，当引用该对象的对象销毁时，引用计数 -1，当对象引用计数为 0 时回收该对象。 代表语言：Python、PHP、Swift 优点：对象回收快，不会出现内存耗尽或达到某个阈值时才回收。 缺点：不能很好的处理循环引用，而实时维护引用计数也是有损耗的。 分代收集：按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，短的放入新生代，不同代有不同的回收算法和回收频率。 代表语言：Java 优点：回收性能好 缺点：算法复杂 标记-清除：从根变量开始遍历所有引用的对象，标记引用的对象，没有被标记的进行回收。 代表语言：Golang（三色标记法） 优点：解决了引用计数的缺点。 缺点：需要 STW，暂时停掉程序运行。 Go GC算法 三色标记法 此算法是在Go 1.5版本开始使用，Go 语言采用的是标记清除算法，并在此基础上使用了三色标记法和混合写屏障技术，GC过程和其他用户goroutine可并发运行，但需要一定时间的STW\n三色标记法只是为了叙述方便而抽象出来的一种说法，实际上的对象是没有三色之分的。这里的三色，对应了垃圾回收过程中对象的三种状态：\n灰色：对象还在标记队列中等待 黑色：对象已被标记，gcmarkBits 对应位为 1 （该对象不会在本次 GC 中被回收） 白色：对象未被标记，gcmarkBits 对应位为 0 （该对象将会在本次 GC 中被清理） step 1: 创建：白、灰、黑 三个集合\nstep 2: 将所有对象放入白色集合中\nstep 3: 遍历所有root对象，把遍历到的对象从白色集合放入灰色集合 (这里放入灰色集合的都是根节点的对象)\nstep 4: 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，自身标记为黑色\nstep 5: 重复步骤4，直到灰色中无任何对象，其中用到2个机制：\n写屏障（Write Barrier）：上面说到的 STW 的目的是防止 GC 扫描时内存变化引起的混乱，而写屏障就是让 goroutine 与 GC 同时运行的手段，虽然不能完全消除 STW，但是可以大大减少 STW 的时间。写屏障在 GC 的特定时间开启，开启后指针传递时会把指针标记，即本轮不回收，下次 GC 时再确定。 辅助 GC（Mutator Assist）：为了防止内存分配过快，在 GC 执行过程中，GC 过程中 mutator 线程会并发运行，而 mutator assist 机制会协助 GC 做一部分的工作。 step 6: 收集所有白色对象（垃圾）\nroot对象 根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：\n全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。 执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上指向堆内存的指针。 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。\n插入写屏障 对象被引用时触发的机制（只在堆内存中生效）：赋值器这一行为通知给并发执行的回收器，被引用的对象标记为灰色\n缺点：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活\n删除写屏障 对象被删除时触发的机制（只在堆内存中生效）：赋值器将这一行为通知给并发执行的回收器，被删除的对象，如果自身为灰色或者白色，那么标记为灰色\n缺点：一个对象的引用被删除后，即使没有其他存活的对象引用它，它仍然会活到下一轮，会产生很大冗余扫描成本，且降低了回收精度\n混合写屏障 GC没有混合写屏障前，一直是插入写屏障；混合写屏障是插入写屏障 + 删除写屏障，写屏障只应用在堆上应用，栈上不启用（栈上启用成本很高）\nGC开始将栈上的对象全部扫描并标记为黑色。 GC期间，任何在栈上创建的新对象，均为黑色。 被删除的对象标记为灰色。 被添加的对象标记为灰色。 GC流程 一次完整的垃圾回收会分为四个阶段，分别是标记准备、标记开始、标记终止、清理：\n标记准备（Mark Setup）：打开写屏障（Write Barrier），需 STW（stop the world) 标记开始（Marking）：使用三色标记法并发标记 ，与用户程序并发执行 标记终止（Mark Termination）：对触发写屏障的对象进行重新扫描标记，关闭写屏障（Write Barrier），需 STW（stop the world) 清理（Sweeping）：将需要回收的内存归还到堆中，将过多的内存归还给操作系统，与用户程序并发执行 GC触发时机 主动触发：\n调用 runtime.GC() 方法，触发 GC 被动触发：\n定时触发，该触发条件由 runtime.forcegcperiod 变量控制，默认为 2 分 钟。当超过两分钟没有产生任何 GC 时，触发 GC 根据内存分配阈值触发，该触发条件由环境变量GOGC控制，默认值为100（100%），当前堆内存占用是上次GC结束后占用内存的2倍时，触发GC GC算法演进 Go 1：mark and sweep操作都需要STW Go 1.3：分离了mark和sweep操作，mark过程需要 STW，mark完成后让sweep任务和普通协程任务一样并行，停顿时间在约几百ms Go 1.5：引入三色并发标记法、插入写屏障，不需要每次都扫描整个内存空间，可以减少stop the world的时间，停顿时间在100ms以内 Go 1.6：使用 bitmap 来记录回收内存的位置，大幅优化垃圾回收器自身消耗的内存，停顿时间在10ms以内 Go 1.7：停顿时间控制在2ms以内 Go 1.8：混合写屏障（插入写屏障和删除写屏障），停顿时间在0.5ms左右 Go 1.9：彻底移除了栈的重扫描过程 Go 1.12：整合了两个阶段的 Mark Termination Go 1.13：着手解决向操作系统归还内存的，提出了新的 Scavenger Go 1.14：替代了仅存活了一个版本的 scavenger，全新的页分配器，优化分配内存过程的速率与现有的扩展性问题，并引入了异步抢占，解决了由于密集循环导致的 STW 时间过长的问题. 5.Go GC如何调优 控制内存分配的速度，限制 Goroutine 的数量，提高赋值器 mutator 的 CPU 利用率（降低GC的CPU利用率） 少量使用+连接string slice提前分配足够的内存来降低扩容带来的拷贝 避免map key对象过多，导致扫描时间增加 变量复用，减少对象分配，例如使用 sync.Pool 来复用需要频繁创建临时对象、使用全局变量等 增大 GOGC 的值，降低 GC 的运行频率 Go 如何查看GC信息？ 1. GODEBUG=\u0026lsquo;gctrace=1\u0026rsquo; package main func main() { for n := 1; n \u0026lt; 100000; n++ { _ = make([]byte, 1\u0026lt;\u0026lt;20) } } $ GODEBUG=\u0026#39;gctrace=1\u0026#39; go run main.go gc 1 @0.003s 4%: 0.013+1.7+0.008 ms clock, 0.10+0.67/1.2/0.018+0.064 ms cpu, 4-\u0026gt;6-\u0026gt;2 MB, 5 MB goal, 8 P gc 2 @0.006s 2%: 0.006+4.5+0.058 ms clock, 0.048+0.070/0.027/3.6+0.47 ms cpu, 4-\u0026gt;5-\u0026gt;1 MB, 5 MB goal, 8 P gc 3 @0.011s 3%: 0.021+1.3+0.009 ms clock, 0.17+0.041/0.41/0.046+0.072 ms cpu, 4-\u0026gt;6-\u0026gt;2 MB, 5 MB goal, 8 P gc 4 @0.013s 5%: 0.025+0.38+0.26 ms clock, 0.20+0.054/0.15/0.009+2.1 ms cpu, 4-\u0026gt;6-\u0026gt;2 MB, 5 MB goal, 8 P gc 5 @0.014s 5%: 0.021+0.16+0.002 ms clock, 0.17+0.098/0.028/0.001+0.016 ms cpu, 4-\u0026gt;5-\u0026gt;1 MB, 5 MB goal, 8 P gc 6 @0.014s 7%: 0.025+1.6+0.003 ms clock, 0.20+0.061/2.9/1.5+0.025 ms cpu, 4-\u0026gt;6-\u0026gt;2 MB, 5 MB goal, 8 P gc 7 @0.016s 7%: 0.019+1.0+0.002 ms clock, 0.15+0.053/1.0/0.018+0.017 ms cpu, 4-\u0026gt;6-\u0026gt;2 MB, 5 MB goal, 8 P gc 8 @0.017s 7%: 0.029+0.17+0.002 ms clock, 0.23+0.037/0.10/0.063+0.022 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 8 P gc 9 @0.018s 7%: 0.019+0.23+0.002 ms clock, 0.15+0.040/0.16/0.023+0.018 ms cpu, 4-\u0026gt;5-\u0026gt;1 MB, 5 MB goal, 8 P gc 10 @0.018s 7%: 0.022+0.23+0.003 ms clock, 0.17+0.061/0.13/0.006+0.024 ms cpu, 4-\u0026gt;6-\u0026gt;2 MB, 5 MB goal, 8 P gc 11 @0.018s 7%: 0.019+0.11+0.001 ms clock, 0.15+0.033/0.051/0.013+0.015 ms cpu, 4-\u0026gt;5-\u0026gt;1 MB, 5 MB goal, 8 P gc 12 @0.019s 7%: 0.018+0.19+0.001 ms clock, 0.14+0.035/0.10/0.018+0.014 ms cpu, 4-\u0026gt;5-\u0026gt;1 MB, 5 MB goal, 8 P gc 13 @0.019s 7%: 0.018+0.35+0.002 ms clock, 0.15+0.21/0.054/0.013+0.016 ms cpu, 4-\u0026gt;5-\u0026gt;1 MB, 5 MB goal, 8 P gc 14 @0.019s 8%: 0.024+0.27+0.002 ms clock, 0.19+0.022/0.13/0.014+0.017 ms cpu, 4-\u0026gt;5-\u0026gt;1 MB, 5 MB goal, 8 P gc 15 @0.020s 8%: 0.019+0.42+0.038 ms clock, 0.15+0.060/0.28/0.007+0.31 ms cpu, 4-\u0026gt;17-\u0026gt;13 MB, 5 MB goal, 8 P gc 16 @0.021s 8%: 0.018+0.53+0.060 ms clock, 0.14+0.045/0.39/0.005+0.48 ms cpu, 21-\u0026gt;28-\u0026gt;7 MB, 26 MB goal, 8 P gc 17 @0.021s 10%: 0.020+0.91+0.64 ms clock, 0.16+0.050/0.36/0.027+5.1 ms cpu, 12-\u0026gt;16-\u0026gt;4 MB, 14 MB goal, 8 P gc 18 @0.023s 10%: 0.020+0.55+0.002 ms clock, 0.16+0.053/0.50/0.081+0.023 ms cpu, 7-\u0026gt;9-\u0026gt;2 MB, 8 MB goal, 8 P 字段含义由下表所示：\n字段 含义 gc 2 第二个 GC 周期 0.006 程序开始后的 0.006 秒 2% 该 GC 周期中 CPU 的使用率 0.006 标记开始时， STW 所花费的时间（wall clock） 4.5 标记过程中，并发标记所花费的时间（wall clock） 0.058 标记终止时， STW 所花费的时间（wall clock） 0.048 标记开始时， STW 所花费的时间（cpu time） 0.070 标记过程中，标记辅助所花费的时间（cpu time） 0.027 标记过程中，并发标记所花费的时间（cpu time） 3.6 标记过程中，GC 空闲的时间（cpu time） 0.47 标记终止时， STW 所花费的时间（cpu time） 4 标记开始时，堆的大小的实际值 5 标记结束时，堆的大小的实际值 1 标记结束时，标记为存活的对象大小 5 标记结束时，堆的大小的预测值 8 P 的数量 2. go tool trace package main import ( \u0026#34;os\u0026#34; \u0026#34;runtime/trace\u0026#34; ) func main() { f, _ := os.Create(\u0026#34;trace.out\u0026#34;) defer f.Close() trace.Start(f) defer trace.Stop() for n := 1; n \u0026lt; 100000; n++ { _ = make([]byte, 1\u0026lt;\u0026lt;20) } } $ go run main.go $ go tool trace trace.out 打开浏览器后，可以看到如下统计：\n点击View trace，可以查看当时的trace情况\n点击 Minimum mutator utilization，可以查看到赋值器 mutator （用户程序）对 CPU 的利用率 74.1%，接近100%则代表没有针对GC的优化空间了\n3. debug.ReadGCStats package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime/debug\u0026#34; \u0026#34;time\u0026#34; ) func printGCStats() { t := time.NewTicker(time.Second) s := debug.GCStats{} for { select { case \u0026lt;-t.C: debug.ReadGCStats(\u0026amp;s) fmt.Printf(\u0026#34;gc %d last@%v, PauseTotal %v\\n\u0026#34;, s.NumGC, s.LastGC, s.PauseTotal) } } } func main() { go printGCStats() for n := 1; n \u0026lt; 100000; n++ { _ = make([]byte, 1\u0026lt;\u0026lt;20) } } $ go run main.go gc 3392 last@2022-05-04 19:22:52.877293 +0800 CST, PauseTotal 117.524907ms gc 6591 last@2022-05-04 19:22:53.876837 +0800 CST, PauseTotal 253.254996ms gc 10028 last@2022-05-04 19:22:54.87674 +0800 CST, PauseTotal 376.981595ms gc 13447 last@2022-05-04 19:22:55.87689 +0800 CST, PauseTotal 511.420111ms gc 16938 last@2022-05-04 19:22:56.876955 +0800 CST, PauseTotal 649.293449ms gc 20350 last@2022-05-04 19:22:57.876756 +0800 CST, PauseTotal 788.003014ms 字段含义由下表所示：\n字段 含义 NumGC GC总次数 LastGC 上次GC时间 PauseTotal STW总耗时 4. runtime.ReadMemStats package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; ) func printMemStats() { t := time.NewTicker(time.Second) s := runtime.MemStats{} for { select { case \u0026lt;-t.C: runtime.ReadMemStats(\u0026amp;s) fmt.Printf(\u0026#34;gc %d last@%v, heap_object_num: %v, heap_alloc: %vMB, next_heap_size: %vMB\\n\u0026#34;, s.NumGC, time.Unix(int64(time.Duration(s.LastGC).Seconds()), 0), s.HeapObjects, s.HeapAlloc/(1\u0026lt;\u0026lt;20), s.NextGC/(1\u0026lt;\u0026lt;20)) } } } func main() { go printMemStats() fmt.Println(1 \u0026lt;\u0026lt; 20) for n := 1; n \u0026lt; 100000; n++ { _ = make([]byte, 1\u0026lt;\u0026lt;20) } } $ go run main.go gc 2978 last@2022-05-04 19:38:04 +0800 CST, heap_object_num: 391, heap_alloc: 20MB, next_heap_size: 28MB gc 5817 last@2022-05-04 19:38:05 +0800 CST, heap_object_num: 370, heap_alloc: 4MB, next_heap_size: 4MB gc 9415 last@2022-05-04 19:38:06 +0800 CST, heap_object_num: 392, heap_alloc: 7MB, next_heap_size: 8MB gc 11429 last@2022-05-04 19:38:07 +0800 CST, heap_object_num: 339, heap_alloc: 4MB, next_heap_size: 5MB gc 14706 last@2022-05-04 19:38:08 +0800 CST, heap_object_num: 436, heap_alloc: 6MB, next_heap_size: 8MB gc 18253 last@2022-05-04 19:38:09 +0800 CST, heap_object_num: 375, heap_alloc: 4MB, next_heap_size: 6M 字段含义由下表所示：\n字段 含义 NumGC GC总次数 LastGC 上次GC时间 HeapObjects 堆中已经分配的对象总数，GC内存回收后HeapObjects取值相应减小 HeapAlloc 堆中已经分配给对象的字节数，GC内存回收后HeapAlloc取值相应减小 NextGC 下次GC目标堆的大小 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%AF%87/","summary":"Go 内存分配机制 Go语言内置运行时（就是runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。 设计思想 内存分配算法采用Google的TCMalloc算法，每个线程都会自行维护","title":"Go 内存管理篇"},{"content":"Go 线程实现模型 Go实现的是两级线程模型（M：N)，准确的说是GMP模型，是对两级线程模型的改进实现，使它能够更加灵活地进行线程之间的调度。\n背景 含义 缺点 单进程时代 每个程序就是一个进程，直到一个程序运行完，才能进行下一个进程 1. 无法并发，只能串行 2. 进程阻塞所带来的 CPU 时间浪费 多进程/线程时代 一个线程阻塞， cpu 可以立刻切换到其他线程中去执行 1. 进程/线程占用内存高 2. 进程/线程上下文切换成本高 协程时代 协程（用户态线程）绑定线程（内核态线程），cpu调度线程执行 1. 实现起来较复杂，协程和线程的绑定依赖调度器算法 线程 -\u0026gt; CPU 由 操作系统 调度，协程 -\u0026gt; 线程 由Go调度器来调度，协程与线程的映射关系有三种线程模型\n三种线程模型 线程实现模型主要分为：内核级线程模型、用户级线程模型、两级线程模型，他们的区别在于用户线程与内核线程之间的对应关系。\n内核级线程模型（1：1）\n1个用户线程对应1个内核线程，这种最容易实现，协程的调度都由 CPU 完成了\n优点：\n实现起来最简单 能够利用多核 如果进程中的一个线程被阻塞，不会阻塞其他线程，是能够切换同一进程内的其他线程继续执行 缺点：\n上下文切换成本高，创建、删除和切换都由 CPU 完成 用户级线程模型（N：1）\n1个进程中的所有线程对应1个内核线程\n优点：\n上下文切换成本低，在用户态即可完成协程切换 缺点：\n无法利用多核 一旦协程阻塞，造成线程阻塞，本线程的其它协程无法执行 两级线程模型（M：N)\nM个线程对应N个内核线程\n优点：\n能够利用多核 上下文切换成本低 如果进程中的一个线程被阻塞，不会阻塞其他线程，是能够切换同一进程内的其他线程继续执行 缺点：\n实现起来最复杂 Go GMP和GM模型？ 什么才是一个好的调度器？\n能在适当的时机将合适的协程分配到合适的位置，保证公平和效率。\nGo采用了GMP模型（对两级线程模型的改进实现），使它能够更加灵活地进行线程之间的调度。\nGMP模型 GMP是Go运行时调度层面的实现，包含4个重要结构，分别是G、M、P、Sched\nG（Goroutine）：代表Go 协程Goroutine，存储了 Goroutine 的执行栈信息、Goroutine 状态以及 Goroutine 的任务函数等。G的数量无限制，理论上只受内存的影响，创建一个 G 的初始栈大小为2-4K，配置一般的机器也能简简单单开启数十万个 Goroutine ，而且Go语言在 G 退出的时候还会把 G 清理之后放到 P 本地或者全局的闲置列表 gFree 中以便复用。\nM（Machine）： Go 对操作系统线程（OS thread）的封装，可以看作操作系统内核线程，想要在 CPU 上执行代码必须有线程，通过系统调用 clone 创建。M在绑定有效的 P 后，进入一个调度循环，而调度循环的机制大致是从 P 的本地运行队列以及全局队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作并回到 M，如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础。M的数量有限制，默认数量限制是 10000，可以通过 debug.SetMaxThreads() 方法进行设置，如果有M空闲，那么就会回收或者睡眠。\nP（Processor）：**虚拟处理器，M执行G所需要的资源和上下文，只有将 P 和 M 绑定，才能让 P 的 runq 中的 G 真正运行起来。P 的数量决定了系统内最大可并行的 G 的数量，**P的数量受本机的CPU核数影响，可通过环境变量$GOMAXPROCS或在runtime.GOMAXPROCS()来设置，默认为CPU核心数。\nSched：调度器结构，它维护有存储M和G的全局队列，以及调度器的一些状态信息\nG M P 数量限制 无限制，受机器内存影响 有限制，默认最多10000 有限制，最多GOMAXPROCS个 创建时机 go func 当没有足够的M来关联P并运行其中的可运行的G时会请求创建新的M 在确定了P的最大数量n后，运行时系统会根据这个数量创建个P 核心数据结构:\n//src/runtime/runtime2.go type g struct { goid int64 // 唯一的goroutine的ID sched gobuf // goroutine切换时，用于保存g的上下文 stack stack // 栈 gopc // pc of go statement that created this goroutine startpc uintptr // pc of goroutine function ... } type p struct { lock mutex id int32 status uint32 // one of pidle/prunning/... // Queue of runnable goroutines. Accessed without lock. runqhead uint32 // 本地队列队头 runqtail uint32 // 本地队列队尾 runq [256]guintptr // 本地队列，大小256的数组，数组往往会被都读入到缓存中，对缓存友好，效率较高 runnext guintptr // 下一个优先执行的goroutine（一定是最后生产出来的)，为了实现局部性原理，runnext中的G永远会被最先调度执行 ... } type m struct { g0 *g // 每个M都有一个自己的G0，不指向任何可执行的函数，在调度或系统调用时，M会切换到G0，使用G0的栈空间来调度 curg *g // 当前正在执行的G ... } type schedt struct { ... runq gQueue // 全局队列，链表（长度无限制） runqsize int32 // 全局队列长度 ... } GMP模型的实现算是Go调度器的一大进步，但调度器仍然有一个令人头疼的问题，那就是不支持抢占式调度，这导致一旦某个 G 中出现死循环的代码逻辑，那么 G 将永久占用分配给它的 P 和 M，而位于同一个 P 中的其他 G 将得不到调度，出现“饿死”的情况。\n当只有一个 P（GOMAXPROCS=1）时，整个 Go 程序中的其他 G 都将“饿死”。于是在 Go 1.2 版本中实现了基于协作的“抢占式”调度，在Go 1.14 版本中实现了基于信号的“抢占式”调度。\nGM模型 Go早期是GM模型，没有P组件\nGM调度存在的问题：\n全局队列的锁竞争，当 M 从全局队列中添加或者获取 G 的时候，都需要获取队列锁，导致激烈的锁竞争 M 转移 G 增加额外开销，当 M1 在执行 G1 的时候， M1 创建了 G2，为了继续执行 G1，需要把 G2 保存到全局队列中，无法保证G2是被M1处理。因为 M1 原本就保存了 G2 的信息，所以 G2 最好是在 M1 上执行，这样的话也不需要转移G到全局队列和线程上下文切换 线程使用效率不能最大化，没有work-stealing 和hand-off 机制 计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决，为了解决这一的问题 go 从 1.1 版本引入P，在运行时系统的时候加入 P 对象，让 P 去管理这个 G 对象，M 想要运行 G，必须绑定 P，才能运行 P 所管理 的 G\nGo 调度原理 goroutine调度的本质就是将 **Goroutine (G）**按照一定算法放到CPU上去执行。\nCPU感知不到Goroutine，只知道内核线程，所以需要Go调度器将协程调度到内核线程上面去，然后操作系统调度器将内核线程放到CPU上去执行\nM是对内核级线程的封装，所以Go调度器的工作就是将G分配到M\nGo 调度器的实现不是一蹴而就的，它的调度模型与算法也是几经演化，从最初的 GM 模型、到 GMP模型，从不支持抢占，到支持协作式抢占，再到支持基于信号的异步抢占，经历了不断地优化与打磨。\n设计思想 线程复用（work stealing 机制和hand off 机制） 利用并行（利用多核CPU） 抢占调度（解决公平性问题） 调度对象 Go 调度器\nGo 调度器是属于Go runtime中的一部分，Go runtime负责实现Go的并发调度、垃圾回收、内存堆栈管理等关键功能\n被调度对象 G的来源\nP的runnext（只有1个G，局部性原理，永远会被最先调度执行） P的本地队列（数组，最多256个G） 全局G队列（链表，无限制） 网络轮询器network poller（存放网络调用被阻塞的G） P的来源\n全局P队列（数组，GOMAXPROCS个P） M的来源\n休眠线程队列（未绑定P，长时间休眠会等待GC回收销毁） 运行线程（绑定P，指向P中的G） 自旋线程（绑定P，指向M的G0） 其中运行线程数 + 自旋线程数 \u0026lt;= P的数量（GOMAXPROCS），M个数 \u0026gt;= P个数\n调度流程 协程的调度采用了生产者-消费者模型，实现了用户任务与调度器的解耦\n生产端我们开启的每个协程都是一个计算任务，这些任务会被提交给 go 的 runtime。如果计算任务非常多，有成千上万个，那么这些任务是不可能同时被立刻执行的，所以这个计算任务一定会被先暂存起来，一般的做法是放到内存的队列中等待被执行。\nG的生命周期：G 从创建、保存、被获取、调度和执行、阻塞、销毁，步骤如下：\n步骤 1：创建 G，关键字 go func() 创建 G 步骤 2：保存 G，创建的 G 优先保存到本地队列 P，如果 P 满了，则会平衡部分P到全局队列中\n步骤3：唤醒或者新建M执行任务，进入调度循环（步骤4,5,6)\n步骤 4：M 获取 G，M首先从P的本地队列获取 G，如果 P为空，则从全局队列获取 G，如果全局队列也为空，则从另一个本地队列偷取一半数量的 G（负载均衡），这种从其它P偷的方式称之为 work stealing\n步骤 5：M 调度和执行 G，M调用 G.func() 函数执行 G\n如果 M在执行 G 的过程发生系统调用阻塞（同步），会阻塞G和M（操作系统限制），此时P会和当前M解绑，并寻找新的M，如果没有空闲的M就会新建一个M ，接管正在阻塞G所属的P，接着继续执行 P中其余的G，这种阻塞后释放P的方式称之为hand off。当系统调用结束后，这个G会尝试获取一个空闲的P执行，优先获取之前绑定的P，并放入到这个P的本地队列，如果获取不到P，那么这个线程M变成休眠状态，加入到空闲线程中，然后这个G会被放入到全局队列中。 如果M在执行G的过程发生网络IO等操作阻塞时（异步），阻塞G，不会阻塞M。M会寻找P中其它可执行的G继续执行，G会被网络轮询器network poller 接手，当阻塞的G恢复后，G1从network poller 被移回到P的 LRQ 中，重新进入可执行状态。异步情况下，通过调度，Go scheduler 成功地将 I/O 的任务转变成了 CPU 任务，或者说将内核级别的线程切换转变成了用户级别的 goroutine 切换，大大提高了效率。 步骤6：M执行完G后清理现场，重新进入调度循环（将M上运⾏的goroutine切换为G0，G0负责调度时协程的切换）\n其中步骤2中保存 G的详细流程如下：\n执行 go func 的时候，主线程 M0 会调用 newproc()生成一个 G 结构体，这里会先选定当前 M0 上的 P 结构 每个协程 G 都会被尝试先放到 P 中的 runnext，若 runnext 为空则放到 runnext 中，生产结束 若 runnext 满，则将原来 runnext 中的 G 踢到本地队列中，将当前 G 放到 runnext 中，生产结束 若本地队列也满了，则将本地队列中的 G 拿出一半，放到全局队列中，生产结束。 调度时机 什么时候进行调度（执行/切换）？\n在以下情形下，会切换正在执行的goroutine\n抢占式调度 sysmon 检测到协程运行过久（比如sleep，死循环） 切换到g0，进入调度循环 主动调度 新起一个协程和协程执行完毕 触发调度循环 主动调用runtime.Gosched() 切换到g0，进入调度循环 垃圾回收之后 stw之后，会重新选择g开始执行 被动调度 系统调用（比如文件IO）阻塞（同步） 阻塞G和M，P与M分离，将P交给其它M绑定，其它M执行P的剩余G 网络IO调用阻塞（异步） 阻塞G，G移动到NetPoller，M执行P的剩余G atomic/mutex/channel等阻塞（异步） 阻塞G，G移动到channel的等待队列中，M执行P的剩余G 调度策略 使用什么策略来挑选下一个goroutine执行？\n由于 P 中的 G 分布在 runnext、本地队列、全局队列、网络轮询器中，则需要挨个判断是否有可执行的 G，大体逻辑如下：\n每执行61次调度循环，从全局队列获取G，若有则直接返回 从P 上的 runnext 看一下是否有 G，若有则直接返回 从P 上的 本地队列 看一下是否有 G，若有则直接返回 上面都没查找到时，则去全局队列、网络轮询器查找或者从其他 P 中窃取，一直阻塞直到获取到一个可用的 G 为止 源码实现如下：\nfunc schedule() { _g_ := getg() var gp *g var inheritTime bool ... if gp == nil { // 每执行61次调度循环会看一下全局队列。为了保证公平，避免全局队列一直无法得到执行的情况，当全局运行队列中有待执行的G时，通过schedtick保证有一定几率会从全局的运行队列中查找对应的Goroutine； if _g_.m.p.ptr().schedtick%61 == 0 \u0026amp;\u0026amp; sched.runqsize \u0026gt; 0 { lock(\u0026amp;sched.lock) gp = globrunqget(_g_.m.p.ptr(), 1) unlock(\u0026amp;sched.lock) } } if gp == nil { // 先尝试从P的runnext和本地队列查找G gp, inheritTime = runqget(_g_.m.p.ptr()) } if gp == nil { // 仍找不到，去全局队列中查找。还找不到，要去网络轮询器中查找是否有G等待运行；仍找不到，则尝试从其他P中窃取G来执行。 gp, inheritTime = findrunnable() // blocks until work is available // 这个函数是阻塞的，执行到这里一定会获取到一个可执行的G } ... // 调用execute，继续调度循环 execute(gp, inheritTime) } 从全局队列查找时，如果要所有 P 平分全局队列中的 G，每个 P 要分得多少个，这里假设会分得 n 个。然后把这 n 个 G，转移到当前 G 所在 P 的本地队列中去。但是最多不能超过 P 本地队列长度的一半（即 128）。这样做的目的是，如果下次调度循环到来的时候，就不必去加锁到全局队列中在获取一次 G 了，性能得到了很好的保障。\nfunc globrunqget(_p_ *p, max int32) *g { ... // gomaxprocs = p的数量 // sched.runqsize是全局队列长度 // 这里n = 全局队列的G平分到每个P本地队列上的数量 + 1 n := sched.runqsize/gomaxprocs + 1 if n \u0026gt; sched.runqsize { n = sched.runqsize } if max \u0026gt; 0 \u0026amp;\u0026amp; n \u0026gt; max { n = max } // 平分后的数量n不能超过本地队列长度的一半，也就是128 if n \u0026gt; int32(len(_p_.runq))/2 { n = int32(len(_p_.runq)) / 2 } // 执行将G从全局队列中取n个分到当前P本地队列的操作 sched.runqsize -= n gp := sched.runq.pop() n-- for ; n \u0026gt; 0; n-- { gp1 := sched.runq.pop() runqput(_p_, gp1, false) } return gp } 从其它P查找时，会偷一半的G过来放到当前P的本地队列.\nGo work stealing 机制？ 概念 当线程M⽆可运⾏的G时，尝试从其他M绑定的P偷取G，减少空转，提高了线程利用率（避免闲着不干活）。\n当从本线程绑定 P 本地 队列、全局G队列、netpoller都找不到可执行的 g，会从别的 P 里窃取G并放到当前P上面。\n从netpoller 中拿到的G是_Gwaiting状态（ 存放的是因为网络IO被阻塞的G），从其它地方拿到的G是_Grunnable状态\n从全局队列取的G数量：N = min(len(GRQ)/GOMAXPROCS + 1, len(GRQ/2)) （根据GOMAXPROCS负载均衡）\n从其它P本地队列窃取的G数量：N = len(LRQ)/2（平分）\n窃取流程 源码见runtime/proc.go stealWork函数，窃取流程如下，如果经过多次努力一直找不到需要运行的goroutine则调用stopm进入睡眠状态，等待被其它工作线程唤醒。\n选择要窃取的P 从P中偷走一半G 选择要窃取的P 窃取的实质就是遍历allp中的所有p，查看其运行队列是否有goroutine，如果有，则取其一半到当前工作线程的运行队列\n为了保证公平性，遍历allp时并不是固定的从allp[0]即第一个p开始，而是从随机位置上的p开始，而且遍历的顺序也随机化了，并不是现在访问了第i个p下一次就访问第i+1个p，而是使用了一种伪随机的方式遍历allp中的每个p，防止每次遍历时使用同样的顺序访问allp中的元素\noffset := uint32(random()) % nprocs coprime := 随机选取一个小于nprocs且与nprocs互质的数 const stealTries = 4 // 最多重试4次 for i := 0; i \u0026lt; stealTries; i++ { for i := 0; i \u0026lt; nprocs; i++ { p := allp[offset] 从p的运行队列偷取goroutine if 偷取成功 { break } offset += coprime offset = offset % nprocs } } 可以看到只要随机数不一样，偷取p的顺序也不一样，但可以保证经过nprocs次循环，每个p都会被访问到。\n从P中偷走一半G 源码见runtime/proc.go runqsteal函数：\n挑选出盗取的对象p之后，则调用runqsteal盗取p的运行队列中的goroutine，runqsteal函数再调用runqgrap从p的本地队列尾部批量偷走一半的g\n为啥是偷一半的g，可以理解为负载均衡\nfunc runqgrab(_p_ *p, batch *[256]guintptr, batchHead uint32, stealRunNextG bool) uint32 { for { h := atomic.LoadAcq(\u0026amp;_p_.runqhead) // load-acquire, synchronize with other consumers t := atomic.LoadAcq(\u0026amp;_p_.runqtail) // load-acquire, synchronize with the producer n := t - h //计算队列中有多少个goroutine n = n - n/2 //取队列中goroutine个数的一半 if n == 0 { ...... return ...... } return n } } Go hand off 机制？ 概念 也称为P分离机制，当本线程 M 因为 G 进行的系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的 M 执行，也提高了线程利用率（避免站着茅坑不拉shi）。\n分离流程 当前线程M阻塞时，释放P，给其它空闲的M处理\nGo 抢占式调度？ 在1.2版本之前，Go的调度器仍然不支持抢占式调度，程序只能依靠Goroutine主动让出CPU资源才能触发调度，这会引发一些问题，比如：\n某些 Goroutine 可以长时间占用线程，造成其它 Goroutine 的饥饿 垃圾回收器是需要stop the world的，如果垃圾回收器想要运行了，那么它必须先通知其它的goroutine停下来，这会造成较长时间的等待时间 为解决这个问题：\nGo 1.2 中实现了基于协作的“抢占式”调度 Go 1.14 中实现了基于信号的“抢占式”调度 基于协作的抢占式调度 协作式：大家都按事先定义好的规则来，比如：一个goroutine执行完后，退出，让出p，然后下一个goroutine被调度到p上运行。这样做的缺点就在于 是否让出p的决定权在groutine自身。一旦某个g不主动让出p或执行时间较长，那么后面的goroutine只能等着，没有方法让前者让出p，导致延迟甚至饿死。\n非协作式: 就是由runtime来决定一个goroutine运行多长时间，如果你不主动让出，对不起，我有手段可以抢占你，把你踢出去，让后面的goroutine进来运行。\n基于协作的抢占式调度流程：\n编译器会在调用函数前插入 runtime.morestack，让运行时有机会在这段代码中检查是否需要执行抢占调度 Go语言运行时会在垃圾回收暂停程序、系统监控发现 Goroutine 运行超过 10ms，那么会在这个协程设置一个抢占标记 当发生函数调用时，可能会执行编译器插入的 runtime.morestack，它调用的 runtime.newstack会检查抢占标记，如果有抢占标记就会触发抢占让出cpu，切到调度主协程里 这种解决方案只能说局部解决了“饿死”问题，只在有函数调用的地方才能插入“抢占”代码（埋点），对于没有函数调用而是纯算法循环计算的 G，Go 调度器依然无法抢占。\n比如，死循环等并没有给编译器插入抢占代码的机会，以下程序在 go 1.14 之前的 go版本中，运行后会一直卡住，而不会打印 I got scheduled!\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; ) func main() { runtime.GOMAXPROCS(1) go func() { for { } }() time.Sleep(time.Second) fmt.Println(\u0026#34;I got scheduled!\u0026#34;) } 为了解决这些问题，Go 在 1.14 版本中增加了对非协作的抢占式调度的支持，这种抢占式调度是基于系统信号的，也就是通过向线程发送信号的方式来抢占正在运行的 Goroutine\n基于信号的抢占式调度 真正的抢占式调度是基于信号完成的，所以也称为“异步抢占”。不管协程有没有意愿主动让出 cpu 运行权，只要某个协程执行时间过长，就会发送信号强行夺取 cpu 运行权。\nM 注册一个 SIGURG 信号的处理函数：sighandler sysmon启动后会间隔性的进行监控，最长间隔10ms，最短间隔20us。如果发现某协程独占P超过10ms，会给M发送抢占信号 M 收到信号后，内核执行 sighandler 函数把当前协程的状态从_Grunning正在执行改成 _Grunnable可执行，把抢占的协程放到全局队列里，M继续寻找其他 goroutine 来运行 被抢占的 G 再次调度过来执行时，会继续原来的执行流 抢占分为_Prunning和_Psyscall，_Psyscall抢占通常是由于阻塞性系统调用引起的，比如磁盘io、cgo。_Prunning抢占通常是由于一些类似死循环的计算逻辑引起的。\nGo 如何查看运行时调度信息？ 有 2 种方式可以查看一个程序的调度GMP信息，分别是go tool trace和GODEBUG\ntrace.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime/trace\u0026#34; \u0026#34;time\u0026#34; ) func main() { //创建trace文件 f, err := os.Create(\u0026#34;trace.out\u0026#34;) if err != nil { panic(err) } defer f.Close() //启动trace goroutine err = trace.Start(f) if err != nil { panic(err) } defer trace.Stop() //main for i := 0; i \u0026lt; 5; i++ { time.Sleep(time.Second) fmt.Println(\u0026#34;Hello World\u0026#34;) } } go tool trace 启动可视化界面：\ngo run trace.go go tool trace trace.out 2022/04/22 10:44:11 Parsing trace... 2022/04/22 10:44:11 Splitting trace... 2022/04/22 10:44:11 Opening browser. Trace viewer is listening on http://127.0.0.1:35488 1.打开 http://127.0.0.1:35488 查看可视化界面：\n点击 view trace 能够看见可视化的调度流程：\n一共有2个G在程序中，一个是特殊的G0，是每个M必须有的一个初始化的G，另外一个是G1 main goroutine (执行 main 函数的协程)，在一段时间内处于可运行和运行的状态。\n2. 点击 Threads 那一行可视化的数据条，我们会看到M详细的信息\n一共有2个 M 在程序中，一个是特殊的 M0，用于初始化使用，另外一个是用于执行G1的M1\n3. 点击 Proc 那一行可视化的数据条，我们会看到P上正在运行goroutine详细的信息\n一共有3个 P 在程序中，分别是P0、P1、P2\n点击具体的 Goroutine 行为后可以看到其相关联的详细信息:\nStart：开始时间 Wall Duration：持续时间 Self Time：执行时间 Start Stack Trace：开始时的堆栈信息 End Stack Trace：结束时的堆栈信息 Incoming flow：输入流 Outgoing flow：输出流 Preceding events：之前的事件 Following events：之后的事件 All connected：所有连接的事件 GODEBUG GODEBUG 变量可以控制运行时内的调试变量。查看调度器信息，将会使用如下两个参数：\nschedtrace：设置 schedtrace=X 参数可以使运行时在每 X 毫秒发出一行调度器的摘要信息到标准 err 输出中。 scheddetail：设置 schedtrace=X 和 scheddetail=1 可以使运行时在每 X 毫秒发出一次详细的多行信息，信息内容主要包括调度程序、处理器、OS 线程 和 Goroutine 的状态。 查看基本信息\ngo build trace.go GODEBUG=schedtrace=1000 ./trace SCHED 0ms: gomaxprocs=8 idleprocs=6 threads=4 spinningthreads=1 idlethreads=0 runqueue=0 [1 0 0 0 0 0 0 0] Hello World SCHED 1010ms: gomaxprocs=8 idleprocs=8 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0] Hello World SCHED 2014ms: gomaxprocs=8 idleprocs=8 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0] Hello World SCHED 3024ms: gomaxprocs=8 idleprocs=8 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0] Hello World SCHED 4027ms: gomaxprocs=8 idleprocs=8 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0] Hello World SCHED 5029ms: gomaxprocs=8 idleprocs=7 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0] sched：每一行都代表调度器的调试信息，后面提示的毫秒数表示启动到现在的运行时间，输出的时间间隔受 schedtrace 的值影响。\ngomaxprocs：当前的 CPU 核心数（GOMAXPROCS 的当前值）。\nidleprocs：空闲的处理器数量，后面的数字表示当前的空闲数量。\nthreads：OS 线程数量，后面的数字表示当前正在运行的线程数量。\nspinningthreads：自旋状态的 OS 线程数量。\nidlethreads：空闲的线程数量。\nrunqueue：全局队列中中的 Goroutine 数量，而后面的[0 0 0 0 0 0 0 0] 则分别代表这 8 个 P 的本地队列正在运行的 Goroutine 数量。\n查看详细信息\ngo build trace.go GODEBUG=scheddetail=1,schedtrace=1000 ./trace SCHED 0ms: gomaxprocs=8 idleprocs=6 threads=4 spinningthreads=1 idlethreads=0 runqueue=0 gcwaiting=0 nmidlelocked=0 stopwait=0 sysmonwait=0 P0: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=1 gfreecnt=0 timerslen=0 P1: status=1 schedtick=0 syscalltick=0 m=2 runqsize=0 gfreecnt=0 timerslen=0 P2: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P3: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P4: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P5: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P6: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P7: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 M3: p=0 curg=-1 mallocing=0 throwing=0 preemptoff= locks=1 dying=0 spinning=false blocked=false lockedg=-1 M2: p=1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=2 dying=0 spinning=false blocked=false lockedg=-1 M1: p=-1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=2 dying=0 spinning=false blocked=false lockedg=-1 M0: p=-1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=1 dying=0 spinning=false blocked=false lockedg=1 G1: status=1(chan receive) m=-1 lockedm=0 G2: status=1() m=-1 lockedm=-1 G3: status=1() m=-1 lockedm=-1 G4: status=4(GC scavenge wait) m=-1 lockedm=-1 G\nstatus：G 的运行状态。 m：隶属哪一个 M。 lockedm：是否有锁定 M。 1 2 3\n复制代码\nG 的运行状态共涉及如下 9 种状态：\n状态 值 含义 _Gidle 0 刚刚被分配，还没有进行初始化。 _Grunnable 1 已经在运行队列中，还没有执行用户代码。 _Grunning 2 不在运行队列里中，已经可以执行用户代码，此时已经分配了 M 和 P。 _Gsyscall 3 正在执行系统调用，此时分配了 M。 _Gwaiting 4 在运行时被阻止，没有执行用户代码，也不在运行队列中，此时它正在某处阻塞等待中。 _Gmoribund_unused 5 尚未使用，但是在 gdb 中进行了硬编码。 _Gdead 6 尚未使用，这个状态可能是刚退出或是刚被初始化，此时它并没有执行用户代码，有可能有也有可能没有分配堆栈。 _Genqueue_unused 7 尚未使用。 _Gcopystack 8 正在复制堆栈，并没有执行用户代码，也不在运行队列中。 M\np：隶属哪一个 P。 curg：当前正在使用哪个 G。 runqsize：运行队列中的 G 数量。 gfreecnt：可用的G（状态为 Gdead）。 mallocing：是否正在分配内存。 throwing：是否抛出异常。 preemptoff：不等于空字符串的话，保持 curg 在这个 m 上运行。 P\nstatus：P 的运行状态。 schedtick：P 的调度次数。 syscalltick：P 的系统调用次数。 m：隶属哪一个 M。 runqsize：运行队列中的 G 数量。 gfreecnt：可用的G（状态为 Gdead） 状态 值 含义 _Pidle 0 刚刚被分配，还没有进行进行初始化。 _Prunning 1 当 M 与 P 绑定调用 acquirep 时，P 的状态会改变为 _Prunning。 _Psyscall 2 正在执行系统调用。 _Pgcstop 3 暂停运行，此时系统正在进行 GC，直至 GC 结束后才会转变到下一个状态阶段。 _Pdead 4 废弃，不再使用。 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B%E7%AF%87/","summary":"Go 线程实现模型 Go实现的是两级线程模型（M：N)，准确的说是GMP模型，是对两级线程模型的改进实现，使它能够更加灵活地进行线程之间的调度。 背景 含义 缺点 单进程时代 每个程序就是一个进程，直到一个程序运行完，才能进行下一个进程 1. 无法并发，只能串行 2. 进程阻塞所带来的 CPU 时间浪费 多进程/线程","title":"Go 调度模型篇"},{"content":"1.Go 常用的并发模型 并发模型说的是系统中的线程如何协作完成并发任务，不同的并发模型，线程以不同的方式进行通信和协作。\n线程间通信方式 线程间通信方式有两种：共享内存和消息传递，无论是哪种通信模型，线程或者协程最终都会从内存中获取数据，所以更为准确的说法是直接共享内存、发送消息的方式来同步信息\n共享内存 抽象层级：抽象层级低，当我们遇到对资源进行更细粒度的控制或者对性能有极高要求的场景才应该考虑抽象层级更低的方法\n耦合：高，线程需要在读取或者写入数据时先获取保护该资源的互斥锁\n线程竞争：需要加锁，才能避免线程竞争和数据冲突\n发送消息 抽象层级：抽象层级高，提供了更良好的封装和与领域更相关和契合的设计，比如Go 语言中的Channel就提供了 Goroutine 之间用于传递信息的方式，它在内部实现时就广泛用到了共享内存和锁，通过对两者进行的组合提供了更高级的同步机制\n耦合：低，生产消费者模型\n线程竞争：保证同一时间只有一个活跃的线程能够访问数据，channel维护所有被该chanel阻塞的协程，保证有资源的时候只唤醒一个协程，从而避免竞争\nGo语言中实现了两种并发模型，一种是共享内存并发模型，另一种则是CSP模型。\n共享内存并发模型 通过直接共享内存 + 锁的方式同步信息，传统多线程并发\nCSP并发模型 通过发送消息的方式来同步信息，Go语言推荐使用的通信顺序进程（communicating sequential processes）并发模型，通过goroutine和channel来实现\ngoroutine 是Go语言中并发的执行单位，可以理解为”线程“ channel是Go语言中各个并发结构体(goroutine)之前的通信机制。 通俗的讲，就是各个goroutine之间通信的”管道“，类似于Linux中的管道 Go 并发同步原语 Go是一门以并发编程见长的语言，它提供了一系列的同步原语方便开发者使用\n原子操作 Mutex、RWMutex 等并发原语的底层实现是通过 atomic 包中的一些原子操作来实现的，原子操作是最基础的并发原语\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync/atomic\u0026#34; ) var opts int64 = 0 func main() { add(\u0026amp;opts, 3) load(\u0026amp;opts) compareAndSwap(\u0026amp;opts, 3, 4) swap(\u0026amp;opts, 5) store(\u0026amp;opts, 6) } func add(addr *int64, delta int64) { atomic.AddInt64(addr, delta) //加操作 fmt.Println(\u0026#34;add opts: \u0026#34;, *addr) } func load(addr *int64) { fmt.Println(\u0026#34;load opts: \u0026#34;, atomic.LoadInt64(\u0026amp;opts)) } func compareAndSwap(addr *int64, oldValue int64, newValue int64) { if atomic.CompareAndSwapInt64(addr, oldValue, newValue) { fmt.Println(\u0026#34;cas opts: \u0026#34;, *addr) return } } func swap(addr *int64, newValue int64) { atomic.SwapInt64(addr, newValue) fmt.Println(\u0026#34;swap opts: \u0026#34;, *addr) } func store(addr *int64, newValue int64) { atomic.StoreInt64(addr, newValue) fmt.Println(\u0026#34;store opts: \u0026#34;, *addr) } Channel channel 管道，高级同步原语，goroutine之间通信的桥梁\n使用场景：消息队列、数据传递、信号通知、任务编排、锁\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { c := make(chan struct{}, 1) for i := 0; i \u0026lt; 10; i++ { go func() { c \u0026lt;- struct{}{} time.Sleep(1 * time.Second) fmt.Println(\u0026#34;通过ch访问临界区\u0026#34;) \u0026lt;-c }() } for { } } 基本并发原语 Go 语言在 sync包中提供了用于同步的一些基本原语，这些基本原语提供了较为基础的同步功能，但是它们是一种相对原始的同步机制，在多数情况下，我们都应该使用抽象层级更高的 Channel 实现同步。\n常见的并发原语如下：sync.Mutex、sync.RWMutex、sync.WaitGroup、sync.Cond、sync.Once、sync.Pool、sync.Context\nsync.Mutex sync.Mutex （互斥锁） 可以限制对临界资源的访问，保证只有一个 goroutine 访问共享资源\n使用场景：大量读写，比如多个 goroutine 并发更新同一个资源，像计数器\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { // 封装好的计数器 var counter Counter var wg sync.WaitGroup var gNum = 1000 wg.Add(gNum) // 启动10个goroutine for i := 0; i \u0026lt; gNum; i++ { go func() { defer wg.Done() counter.Incr() // 受到锁保护的方法 }() } wg.Wait() fmt.Println(counter.Count()) } // 线程安全的计数器类型 type Counter struct { mu sync.Mutex count uint64 } // 加1的方法，内部使用互斥锁保护 func (c *Counter) Incr() { c.mu.Lock() c.count++ c.mu.Unlock() } // 得到计数器的值，也需要锁保护 func (c *Counter) Count() uint64 { c.mu.Lock() defer c.mu.Unlock() return c.count } sync.RWMutex sync.RWMutex （读写锁） 可以限制对临界资源的访问，保证只有一个 goroutine 写共享资源，可以有多个goroutine 读共享资源\n使用场景：大量并发读，少量并发写，有强烈的性能要求\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { // 封装好的计数器 var counter Counter var gNum = 1000 // 启动10个goroutine for i := 0; i \u0026lt; gNum; i++ { go func() { counter.Count() // 受到锁保护的方法 }() } for { // 一个writer counter.Incr() // 计数器写操作 fmt.Println(\u0026#34;incr\u0026#34;) time.Sleep(time.Second) } } // 线程安全的计数器类型 type Counter struct { mu sync.RWMutex count uint64 } // 加1的方法，内部使用互斥锁保护 func (c *Counter) Incr() { c.mu.Lock() c.count++ c.mu.Unlock() } // 得到计数器的值，也需要锁保护 func (c *Counter) Count() uint64 { c.mu.RLock() defer c.mu.RUnlock() return c.count } sync.WaitGroup sync.WaitGroup 可以等待一组 Goroutine 的返回\n使用场景：并发等待，任务编排，一个比较常见的使用场景是批量发出 RPC 或者 HTTP 请求\nrequests := []*Request{...} wg := \u0026amp;sync.WaitGroup{} wg.Add(len(requests)) for _, request := range requests { go func(r *Request) { defer wg.Done() // res, err := service.call(r) }(request) } wg.Wait() sync.Cond sync.Cond 可以让一组的 Goroutine 都在满足特定条件时被唤醒\n使用场景：利用等待 / 通知机制实现阻塞或者唤醒\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) var status int64 func main() { c := sync.NewCond(\u0026amp;sync.Mutex{}) for i := 0; i \u0026lt; 10; i++ { go listen(c) } time.Sleep(1 * time.Second) go broadcast(c) time.Sleep(1 * time.Second) } func broadcast(c *sync.Cond) { c.L.Lock() atomic.StoreInt64(\u0026amp;status, 1) c.Signal() c.L.Unlock() } func listen(c *sync.Cond) { c.L.Lock() for atomic.LoadInt64(\u0026amp;status) != 1 { c.Wait() } fmt.Println(\u0026#34;listen\u0026#34;) c.L.Unlock() } sync.Once sync.Once 可以保证在 Go 程序运行期间的某段代码只会执行一次\n使用场景：常常用于单例对象的初始化场景\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { o := \u0026amp;sync.Once{} for i := 0; i \u0026lt; 10; i++ { o.Do(func() { fmt.Println(\u0026#34;only once\u0026#34;) }) } } sync.Pool sync.Pool可以将暂时将不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能（频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺）\n使用场景：对象池化， TCP连接池、数据库连接池、Worker Pool\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { pool := sync.Pool{ New: func() interface{} { return 0 }, } for i := 0; i \u0026lt; 10; i++ { v := pool.Get().(int) fmt.Println(v) // 取出来的值是put进去的，对象复用；如果是新建对象，则取出来的值为0 pool.Put(i) } } sync.Map sync.Map 线程安全的map\n使用场景：map 并发读写\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var scene sync.Map // 将键值对保存到sync.Map scene.Store(\u0026#34;1\u0026#34;, 1) scene.Store(\u0026#34;2\u0026#34;, 2) scene.Store(\u0026#34;3\u0026#34;, 3) // 从sync.Map中根据键取值 fmt.Println(scene.Load(\u0026#34;1\u0026#34;)) // 根据键删除对应的键值对 scene.Delete(\u0026#34;1\u0026#34;) // 遍历所有sync.Map中的键值对 scene.Range(func(k, v interface{}) bool { fmt.Println(\u0026#34;iterate:\u0026#34;, k, v) return true }) } sync.Context sync.Context 可以进行上下文信息传递、提供超时和取消机制、控制子 goroutine 的执行\n使用场景：取消一个goroutine的执行\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ctx, cancel := context.WithCancel(context.Background()) go func() { defer func() { fmt.Println(\u0026#34;goroutine exit\u0026#34;) }() for { select { case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;receive cancel signal!\u0026#34;) return default: fmt.Println(\u0026#34;default\u0026#34;) time.Sleep(time.Second) } } }() time.Sleep(time.Second) cancel() time.Sleep(2 * time.Second) } 扩展并发原语 ErrGroup errgroup 可以在一组 Goroutine 中提供了同步、错误传播以及上下文取消的功能\n使用场景：只要一个 goroutine 出错我们就不再等其他 goroutine 了，减少资源浪费，并且返回错误\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) func main() { var g errgroup.Group var urls = []string{ \u0026#34;http://www.baidu.com/\u0026#34;, \u0026#34;https://www.sina.com.cn/\u0026#34;, } for i := range urls { url := urls[i] g.Go(func() error { resp, err := http.Get(url) if err == nil { resp.Body.Close() } return err }) } err := g.Wait() if err == nil { fmt.Println(\u0026#34;Successfully fetched all URLs.\u0026#34;) } else { fmt.Println(\u0026#34;fetched error:\u0026#34;, err.Error()) } } Semaphore Semaphore带权重的信号量，控制多个goroutine同时访问资源\n使用场景：控制 goroutine 的阻塞和唤醒\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/sync/semaphore\u0026#34; ) var ( maxWorkers = runtime.GOMAXPROCS(0) sema = semaphore.NewWeighted(int64(maxWorkers)) //信号量 task = make([]int, maxWorkers*4) // 任务数，是worker的四 ) func main() { ctx := context.Background() for i := range task { // 如果没有worker可用，会阻塞在这里，直到某个worker被释放 if err := sema.Acquire(ctx, 1); err != nil { break } // 启动worker goroutine go func(i int) { defer sema.Release(1) time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作 task[i] = i + 1 }(i) } // 请求所有的worker,这样能确保前面的worker都执行完 if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil { log.Printf(\u0026#34;获取所有的worker失败: %v\u0026#34;, err) } fmt.Println(maxWorkers, task) } SingleFlight 用于抑制对下游的重复请求\n使用场景：访问缓存、数据库等场景，缓存过期时只有一个请求去更新数据库\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/sync/singleflight\u0026#34; ) // 模拟从数据库读取 func getArticle(id int) (article string, err error) { // 假设这里会对数据库进行调用, 模拟不同并发下耗时不同 atomic.AddInt32(\u0026amp;count, 1) time.Sleep(time.Duration(count) * time.Millisecond) return fmt.Sprintf(\u0026#34;article: %d\u0026#34;, id), nil } // 模拟优先读缓存，缓存不存在读取数据库，并且只有一个请求读取数据库，其它请求等待 func singleflightGetArticle(sg *singleflight.Group, id int) (string, error) { v, err, _ := sg.Do(fmt.Sprintf(\u0026#34;%d\u0026#34;, id), func() (interface{}, error) { return getArticle(id) }) return v.(string), err } var count int32 func main() { time.AfterFunc(1*time.Second, func() { atomic.AddInt32(\u0026amp;count, -count) }) var ( wg sync.WaitGroup now = time.Now() n = 1000 sg = \u0026amp;singleflight.Group{} ) for i := 0; i \u0026lt; n; i++ { wg.Add(1) go func() { res, _ := singleflightGetArticle(sg, 1) // res, _ := getArticle(1) if res != \u0026#34;article: 1\u0026#34; { panic(\u0026#34;err\u0026#34;) } wg.Done() }() } wg.Wait() fmt.Printf(\u0026#34;同时发起 %d 次请求，耗时: %s\u0026#34;, n, time.Since(now)) } Go WaitGroup实现原理？ 概念 Go标准库提供了WaitGroup原语, 可以用它来等待一批 Goroutine 结束\n底层数据结构 // A WaitGroup must not be copied after first use. type WaitGroup struct { noCopy noCopy state1 [3]uint32 } 其中 noCopy 是 golang 源码中检测禁止拷贝的技术。如果程序中有 WaitGroup 的赋值行为，使用 go vet 检查程序时，就会发现有报错。但需要注意的是，noCopy 不会影响程序正常的编译和运行。\nstate1主要是存储着状态和信号量，状态维护了 2 个计数器，一个是请求计数器counter ，另外一个是等待计数器waiter（已调用 WaitGroup.Wait 的 goroutine 的个数）\n当数组的首地址是处于一个8字节对齐的位置上时，那么就将这个数组的前8个字节作为64位值使用表示状态，后4个字节作为32位值表示信号量(semaphore)；同理如果首地址没有处于8字节对齐的位置上时，那么就将前4个字节作为semaphore，后8个字节作为64位数值。\n使用方法 在WaitGroup里主要有3个方法：\nWaitGroup.Add()：可以添加或减少请求的goroutine数量，Add(n) 将会导致 counter += n WaitGroup.Done()：相当于Add(-1)，Done() 将导致 counter -=1，请求计数器counter为0 时通过信号量调用runtime_Semrelease唤醒waiter线程 WaitGroup.Wait()：会将 waiter++，同时通过信号量调用 runtime_Semacquire(semap)阻塞当前 goroutine func main() { var wg sync.WaitGroup for i := 1; i \u0026lt;= 5; i++ { wg.Add(1) go func() { defer wg.Done() println(\u0026#34;hello\u0026#34;) }() } wg.Wait() } Go Cond实现原理？ 概念 Go标准库提供了Cond原语，可以让 Goroutine 在满足特定条件时被阻塞和唤醒\n底层数据结构 type Cond struct { noCopy noCopy // L is held while observing or changing the condition L Locker notify notifyList checker copyChecker } type notifyList struct { wait uint32 notify uint32 lock uintptr // key field of the mutex head unsafe.Pointer tail unsafe.Pointer } 主要有4个字段：\nnocopy ： golang 源码中检测禁止拷贝的技术。如果程序中有 WaitGroup 的赋值行为，使用 go vet 检查程序时，就会发现有报错，但需要注意的是，noCopy 不会影响程序正常的编译和运行 checker：用于禁止运行期间发生拷贝，双重检查(Double check) L：可以传入一个读写锁或互斥锁，当修改条件或者调用Wait方法时需要加锁 notify：通知链表，调用Wait()方法的Goroutine会放到这个链表中，从这里获取需被唤醒的Goroutine列表 使用方法 在Cond里主要有3个方法：\nsync.NewCond(l Locker): 新建一个 sync.Cond 变量，注意该函数需要一个 Locker 作为必填参数，这是因为在 cond.Wait() 中底层会涉及到 Locker 的锁操作 Cond.Wait(): 阻塞等待被唤醒，调用Wait函数前需要先加锁；并且由于Wait函数被唤醒时存在虚假唤醒等情况，导致唤醒后发现，条件依旧不成立，因此需要使用 for 语句来循环地进行等待，直到条件成立为止 Cond.Signal(): 只唤醒一个最先 Wait 的 goroutine，可以不用加锁 Cond.Broadcast(): 唤醒所有Wait的goroutine，可以不用加锁 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) var status int64 func main() { c := sync.NewCond(\u0026amp;sync.Mutex{}) for i := 0; i \u0026lt; 10; i++ { go listen(c) } go broadcast(c) time.Sleep(1 * time.Second) } func broadcast(c *sync.Cond) { // 原子操作 atomic.StoreInt64(\u0026amp;status, 1) c.Broadcast() } func listen(c *sync.Cond) { c.L.Lock() for atomic.LoadInt64(\u0026amp;status) != 1 { c.Wait() // Wait 内部会先调用 c.L.Unlock()，来先释放锁，如果调用方不先加锁的话，会报错 } fmt.Println(\u0026#34;listen\u0026#34;) c.L.Unlock() } Go 有哪些方式安全读写共享变量 方法 并发原语 备注 不要修改变量 sync.Once 不要去写变量，变量只初始化一次 只允许一个goroutine访问变量 Channel 不要通过共享变量来通信，通过通信(channel)来共享变量 允许多个goroutine访问变量，但是同一时间只允许一个goroutine访问 sync.Mutex、sync.RWMutex、原子操作 实现锁机制，同时只有一个线程能拿到锁 Go 如何排查数据竞争问题 概念 只要有两个以上的goroutine并发访问同一变量，且至少其中的一个是写操作的时候就会发生数据竞争；全是读的情况下是不存在数据竞争的。\n排查方式 package main import \u0026#34;fmt\u0026#34; func main() { i := 0 go func() { i++ // write i }() fmt.Println(i) // read i } go命令行有个参数race可以帮助检测代码中的数据竞争\n$ go run -race main.go WARNING: DATA RACE Write at 0x00c0000ba008 by goroutine 7: exit status 66 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%AF%87/","summary":"1.Go 常用的并发模型 并发模型说的是系统中的线程如何协作完成并发任务，不同的并发模型，线程以不同的方式进行通信和协作。 线程间通信方式 线程间通信方式有两种：共享内存和消息传递，无论是哪种通信模型，线程或者协程最终都会从内存中获取数据，所以更为准确的说法是直接共享内存、发送消息的方式来同步","title":"Go 并发编程篇"},{"content":"一般参数的意思 -a all（全部）\n-r recursion（递归）\n-f force（强制）\n-h 以K，M，G为单位，提高信息的可读性。\n一、文件目录操作 1. ls 命令 ls 命令不仅可以查看 linux 文件夹包含的文件而且可以查看文件权限(包括目录、文件夹、文件权限)查看目录信息等等。\n命令格式\nls [选项][目录名]\n常用参数\n-l ：列出长数据串，包含文件的属性与权限数据等 -a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用） -d ：仅列出目录本身，而不是列出目录的文件数据 -h ：将文件容量以较易读的方式（GB，kB等）列出来 -R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来 使用实例\n1.列出 home 目录下的所有文件和目录的详细资料。\nls -al /home 2.列出当前目录下所有以\u0026quot;d\u0026quot;开头的文件目录详情内容。\nls -l d* 2.cd命令 最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。用于切换当前目录至dirName。\n命令格式\ncd [目录名]\n操作案例\n1.从当前目录进入系统根目录。\ncd / 2.跳转到 home/Code 目录。\ncd /home/Code 3.pwd 命令 查看\u0026quot;当前工作目录\u0026quot;的完整路径。\n命令格式：\npwd [选项]\n常用参数\n-P :显示实际物理路径，而非使用连接（link）路径 -L :当目录为连接路径时，显示连接路径 操作案例\n1.显示当前所在路径。\npwd 4.mkdir 命令 用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。\n命令格式\nmkdir [选项] 目录\n常用参数\n-m, \u0026ndash;mode=模式，设定权限\u0026lt;模式\u0026gt; (类似 chmod)，而不是 rwxrwxrwx 减 umask -p, \u0026ndash;parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录; -v, \u0026ndash;verbose 每次创建新目录都显示信息 \u0026ndash;help 显示此帮助信息并退出 \u0026ndash;version 输出版本信息并退出 使用实例\n1.创建一个空目录。\nmkdir test 2.递归创建多个目录。\nmkdir test/test1 3.创建权限为777的目录。\nmkdir -m 777 test2 4.创建目录都显示信息。\nmkdir -v test4 5.rm 命令 删除一个目录中的一个或多个文件或目录，如果没有使用 -r 选项，则rm不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。\n命令格式\nrm [选项] 文件\n常用参数\n-f, \u0026ndash;force 忽略不存在的文件，从不给出提示。 -i, \u0026ndash;interactive 进行交互式删除 -r, -R, \u0026ndash;recursive 指示rm将参数中列出的全部目录和子目录均递归地删除。 -v, \u0026ndash;verbose 详细显示进行的步骤 \u0026ndash;help 显示此帮助信息并退出 \u0026ndash;version 输出版本信息并退出 使用实例\n1.删除文件 test.txt,系统会提示是否删除。\nrm test.txt 2.强制删除 test.txt，系统不再提示。\nrm -f test.txt 3.将 test 子目录及目录中所有档案删除。\nrm -r test 6.rmdir 命令 该命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对父目录的写权限。\n命令格式\nrmdir [选项] 目录\n常用参数\np 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。如果整个路径被删除或者由于某种原因保留部分路径，则系统在标准输出上显示相应的信息。 -v, \u0026ndash;verbose 显示指令执行过程 使用实例\n1.删除空目录 test1，非空目录无法删除。\nrmdir test1 2.当子目录被删除后使它也成为空目录的话，则顺便一并删除\nrmdir -p test2 # test 目录下仅有 test2 7. mv 命令 可以用来移动文件或者将文件改名（move (rename) files）。\n当第二个参数类型是文件时，mv命令完成文件重命名。 当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。 命令格式\nmv [选项] 源文件或目录 目标文件或目录\n常用参数\n-b ：若需覆盖文件，则覆盖前先行备份 -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖 -u ：若目标文件已经存在，且 source 比较新，才会更新(update) -t ： \u0026ndash;target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY，即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后 使用实例\n1.将 test1.txt 重命名为 test2.txt。\nmv test1.txt test2.txt 2.移动文件 test1.txt 到目录 test2\nmv test1.txt test2 3.将文件 test1.txt、test2.txt、test3.txt 移动到目录 test3。\nmv test1.txt test2.txt test3.txt test3 8.cp 命令 将源文件复制至目标文件，或将多个源文件复制至目标目录。\n命令格式\ncp [选项] 源文件 目录 或 cp [选项] -t 目录 源文件\n常用参数\n-t \u0026ndash;target-directory 指定目标目录 -i \u0026ndash;interactive 覆盖前询问（使前面的 -n 选项失效） -n \u0026ndash;no-clobber 不要覆盖已存在的文件（使前面的 -i 选项失效） -f \u0026ndash;force 强行复制文件或目录，不论目的文件或目录是否已经存在 -u \u0026ndash;update 使用这项参数之后，只会在源文件的修改时间较目的文件更新时，或是对应的目的文件并不存在，才复制文件 使用实例\n1.复制文件 test1.txt 到 test1 目录\ncp test1.txt test1 # 若文件存在，会提示是否覆盖。若不存在直接完成复制 2.复制 test1 整个目录到 test2\ncp -a test1 test2 9. touch 命令 touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。\n命令格式\ntouch [选项] 文件\n常用参数\n-a 或\u0026ndash;time=atime或\u0026ndash;time=access或\u0026ndash;time=use 只更改存取时间 -c 或\u0026ndash;no-create 不建立任何文档 -d 使用指定的日期时间，而非现在的时间 -f 此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题 -m 或\u0026ndash;time=mtime或\u0026ndash;time=modify 只更改变动时间 -r 把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同 -t 使用指定的日期时间，而非现在的时间 使用实例\n1.创建不存在的文件test.txt\ntouch test.txt 2.更新 test.txt 的实践和 test1.txt 时间戳相同\ntouch -r test.txt test1.txt 10.cat 命令 用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。\n命令格式\ncat [选项] [文件]\n常用参数\n-A, \u0026ndash;show-all 等价于 -vET -b, \u0026ndash;number-nonblank 对非空输出行编号 -e 等价于 -vE -E, \u0026ndash;show-ends 在每行结束处显示 $ -n, \u0026ndash;number 对输出的所有行编号,由1开始对所有输出的行数编号 -s, \u0026ndash;squeeze-blank 有连续两行以上的空白行，就代换为一行的空白行 -t 与 -vT 等价 -T, \u0026ndash;show-tabs 将跳格字符显示为 ^I -u (被忽略) -v, \u0026ndash;show-nonprinting 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 使用实例\n1.把 test.log 的文件内容和 test1.log 加上行号后一起展示。\ncat -n test.log test1.log 2.将file1文件里的内容追加到file2：\ncat file1 \u0026gt;\u0026gt; file2 3.将file1文件里的内容写入到file2，写入前清空file2（即覆盖）：\ncat file1 \u0026gt; file2 4.将多个文件的内容追加到另一个文件（合并file1和file2的内容写入到file3）：\ncat file1 file2 \u0026gt;\u0026gt; file3 5.将 test.log 的文件内容反向显示。\ntac test.log 11. nl 命令 输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。\n命令格式\nnl [选项] [文件]\n常用参数\n-b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n) -b t ：如果有空行，空的那一行不要列出行号(默认值) -n ：列出行号表示的方法，主要有三种： -n ln ：行号在萤幕的最左方显示 -n rn ：行号在自己栏位的最右方显示，且不加 0 -n rz ：行号在自己栏位的最右方显示，且加 0 -w ：行号栏位的占用的位数 使用实例\nroot@VM-12-12-ubuntu:/Blaine# nl test.txt 1 hie 2 3 3 df 4 d root@VM-12-12-ubuntu:/Blaine# nl -b a test.txt 1 hie 2 3 3 df 4 5 d 12.more 命令 more 命令和 cat 的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。\n命令格式\nmore [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file \u0026hellip; ]\n常用参数\n+n 从第n行开始显示 -n 定义屏幕大小为n行 +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 操作指令\nEnter：向下n行，需要定义。默认为1行 Ctrl+F：向下滚动一屏 空格键：向下滚动一屏 Ctrl+B：返回上一屏 = ：输出当前行的行号 ：f ：输出文件名和当前行的行号 V ：调用vi编辑器 !命令 ：调用Shell，并执行命令 q ：退出more 使用实例\n1.显示文件 test.log 第3行起内容。\nmore +3 test.log 2.从文件 test.log 查找第一个出现“day3”字符串的行，并从该处前2行开始显示输出。\nmore +/day3 test.log 设置每屏显示行数 more -5 test.log 13. less 命令 less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。\n命令格式\nless [参数] 文件\n常用参数\n-b \u0026lt;缓冲区大小\u0026gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o \u0026lt;文件名\u0026gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x \u0026lt;数字\u0026gt; 将“tab”键显示为规定的数字空格 操作命令\n/字符串：向下搜索“字符串”的功能 ?字符串：向上搜索“字符串”的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 使用实例\n1.查看文件 test.log。\nless test.log 14. head 命令 head 用来显示档案的开头至标准输出中，默认 head 命令打印其相应文件的开头 10 行。\n命令格式\nhead [参数] [文件]\n常用参数\n-q 隐藏文件名 -v 显示文件名 -c\u0026lt;字节\u0026gt; 显示字节数 -n\u0026lt;行数\u0026gt; 显示的行数 使用实例\n1.显示文件 test.log 的前 5 行\nhead -n 5 test.log 2.显示文件 test.log 前 20 个字节\nhead -c 20 test.log 15.tail 命令 显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。\n命令格式\ntail [必要参数] [选择参数] [文件]\n常用参数\n-f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c\u0026lt;数目\u0026gt; 显示的字节数 -n\u0026lt;行数\u0026gt; 显示行数 \u0026ndash;pid=PID 与-f合用,表示在进程ID,PID死掉之后结束. -q, \u0026ndash;quiet, \u0026ndash;silent 从不输出给出文件名的首部 -s, \u0026ndash;sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 使用实例\n1.显示文件 test.log 最后 5 行内容。\ntail -n 5 test.log 2.循环查看文件内容\ntail -f test.log 二、文件查找 16.which 命令 which指令会在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。\n命令格式\nwhich 可执行文件名称\n常用参数\n-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名 -p 与-n参数相同，但此处的包括了文件的路径 -w 指定输出时栏位的宽度 -V 显示版本信息 使用实例\n1.查找文件、显示命令路径。\nwhich pwd 用 which 去找出 which which which 17.whereis 命令 whereis命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。\n命令格式\nwhereis [-bmsu] [BMS 目录名 -f ] 文件名\n常用参数\n-b 定位可执行文件 -m 定位帮助文件 -s 定位源代码文件 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件 -B 指定搜索可执行文件的路径 -M 指定搜索帮助文件的路径 -S 指定搜索源代码文件的路径 使用实例\n1.将和 svn 文件相关的文件都查找出来。\nwhereis svn 2.只将二进制文件查找出来。\nwhereis -b svn 18.locate 命令 可以很快速的搜寻档案系统内是否有指定的档案。\n注意：如果没有需要安装下：\nroot@VM-12-12-ubuntu:/Blaine# locate pwd Command \u0026#39;locate\u0026#39; not found, but can be installed with: apt install mlocate 命令格式\nLocate [选择参数] [样式]\n常用参数\n-e 将排除在寻找的范围之外。 -1 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的 权限资料。 -f 将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案 放在资料库中。 -q 安静模式，不会显示任何错误讯息。 -n 至多显示 n个输出。 -r 使用正规运算式 做寻找的条件。 -o 指定资料库存的名称。 -d 指定资料库的路径 使用实例\n1.查找和 pwd 相关的所有文件。\nlocate pwd 搜索etc 目录下，所有以 m 开头的文件。 locate /etc/m 19. find 命令 主要作用是沿着文件层次结构向下遍历，匹配符合条件的文件，并执行相应的操作。\n命令格式\nfind [选项] [搜索路径] [表达式]\n常用参数\n-print find 命令将匹配的文件输出到标准输出 -exec find 命令对匹配的文件执行该参数所给出的 shell 命令 -name 按照文件名查找文件 -type 查找某一类型的文件 使用实例\n1.打印当前目录文件目录列表。\nfind . -print 2.打印当前目录下所有不以.txt 结尾的文件名。\nfind . ! -name \u0026#34;*.txt\u0026#34; 3.打印当前目录下所有权限为 777 的 php 文件。\nfind . -type f -name \u0026#34;*.php\u0026#34; -perm 777 4.找到当前目录下所有 php 文件，并显示其详细信息。\nfind . -name \u0026#34;*.php\u0026#34; -exec ls -l {} \\; 5.查找当前目录下所有 c 代码文件，统计总行数。\nfind . -type f -name \u0026#34;*.c\u0026#34; | xargs wc -l xargs 命令可以从标准输入接收输入，并把输入转换为一个特定的参数列表。 命令格式: command | xargs [选项] [command] xargs 命令应该紧跟在管道操作符之后，因为它以标准输入作为主要的源数据流。 常用参数\n-n 指定每行最大的参数数量 -d 指定分隔符 三、文件打包上传和下载 20.tar 命令 用来压缩和解压文件。tar本身不具有压缩功能。他是调用压缩功能实现的。\n命令格式\ntar [必要参数] [选择参数] [文件]\n常用参数\n必要参数：\n-A 新增压缩文件到已存在的压缩 -B 设置区块大小 -c 建立新的压缩文件 -d 记录文件的差别 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -x 从压缩的文件中提取文件 -t 显示压缩文件的内容 -z 支持gzip解压文件 -j 支持bzip2解压文件 -Z 支持compress解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -W 确认压缩文件的正确性 可选参数：\n-b 设置区块数目 -C 切换到指定目录 -f 指定压缩文件 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.将文件打全部打包成tar包。\ntar -cvf test.tar test.log # 仅打包，不压缩！ tar -zcvf test.tar.gz test.log # 打包后，以 gzip 压缩 tar -zcvf test.tar.bz2 test.log # 打包后，以 bzip2 压缩 2.将 tar 包解压缩\ntar -zxvf test.tar.gz 21.gzip 命令 使用广泛的压缩程序，文件经它压缩过后，其名称后面会多出\u0026quot;.gz\u0026quot;的扩展名。\n命令格式\ngzip [参数] [文件或者目录]\n常用参数\n-a或\u0026ndash;ascii 使用ASCII文字模式。 -c或\u0026ndash;stdout或\u0026ndash;to-stdout 把压缩后的文件输出到标准输出设备，不去更动原始文件。 -d或\u0026ndash;decompress或\u0026mdash;-uncompress 解开压缩文件。 -f或\u0026ndash;force 强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 -h或\u0026ndash;help 在线帮助。 使用实例\n1.把 test1 目录下的每个文件压缩成.gz 文件。\ntest6 $ gzip * 四、文件权限设置 22.chmod 命令 用于改变linux系统文件或目录的访问权限。\n命令格式\nchmod [-cfvR] [\u0026ndash;help] [\u0026ndash;version] mode file\n常用参数\n必要参数：\n-c 当发生改变时，报告处理信息 -f 错误信息不输出 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细处理信息 选择参数： \u0026ndash;reference=\u0026lt;目录或者文件\u0026gt; 设置成具有指定目录或者文件具有相同的权限 \u0026ndash;version 显示版本信息 \u0026lt;权限范围\u0026gt;+\u0026lt;权限设置\u0026gt; 使权限范围内的目录或者文件具有指定的权限 \u0026lt;权限范围\u0026gt;-\u0026lt;权限设置\u0026gt; 删除权限范围的目录或者文件的指定权限 \u0026lt;权限范围\u0026gt;=\u0026lt;权限设置\u0026gt; 设置权限范围内的目录或者文件的权限为指定的值 权限范围：\nu ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组 权限代号：\nr：读权限，用数字4表示 w：写权限，用数字2表示 x：执行权限，用数字1表示 -：删除权限，用数字0表示 使用实例\n1.增加文件所有用户组可执行权限\nchmod a+x test.log 删除所有用户的可执行权限 chmod a-x test.log 23.chgrp 命令 可采用群组名称或群组识别码的方式改变文件或目录的所属群组。\n命令格式\nchgrp [选项] [组] [文件]\n常用参数\n必要参数:\n-c 当发生改变时输出调试信息 -f 不显示错误信息 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细的处理信息 \u0026ndash;dereference 作用于符号链接的指向，而不是符号链接本身 \u0026ndash;no-dereference 作用于符号链接本身 选择参数:\n\u0026ndash;reference=\u0026lt;文件或者目录\u0026gt; \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.改变文件的群组属性\nchgrp -v bin test.log 2.改变文件test1.log 的群组属性，使得文件test1.log的群组属性和参考文件test.log的群组属性相同\nchgrp --reference=test.log test1.log 24.chown 命令 通过chown改变文件的拥有者和群组。\n命令格式\nchown [选项] [所有者] [:[组]] 文件\n常用参数\n必要参数:\n-c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -R 处理指定目录以及其子目录下的所有文件 -v 显示详细的处理信息 -deference 作用于符号链接的指向，而不是链接文件本身 选择参数:\n\u0026ndash;reference=\u0026lt;目录或文件\u0026gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组 \u0026ndash;from=\u0026lt;当前用户：当前群组\u0026gt; 只有当前用户和群组跟指定的用户和群组相同时才进行改变 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.改变拥有者和群组\nchown mail:mail test.log 五、磁盘存储 25. df 命令 显示指定磁盘文件的可用空间。\n命令格式\ndf [选项] [文件]\n常用参数\n必要参数：\n-a 全部文件系统列表 -h 方便阅读方式显示 -H 等于“-h”，但是计算式，1K=1000，而不是1K=1024 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地文件系统 -m 区块为1048576字节 \u0026ndash;no-sync 忽略 sync 命令 -P 输出格式为POSIX \u0026ndash;sync 在取得磁盘信息前，先执行sync命令 -T 文件系统类型 选择参数：\n\u0026ndash;block-size=\u0026lt;区块大小\u0026gt; 指定区块大小 -t\u0026lt;文件系统类型\u0026gt; 只显示选定文件系统的磁盘信息 -x\u0026lt;文件系统类型\u0026gt; 不显示选定文件系统的磁盘信息 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.显示指定磁盘使用情况\ndf -t ext3 26. du 命令 显示每个文件和目录的磁盘使用空间。\n命令格式\ndu [选项] [文件]\n常用参数\n-a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 \u0026ndash; -c或\u0026ndash;total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或\u0026ndash;kilobytes 以KB(1024bytes)为单位输出。 -m或\u0026ndash;megabytes 以MB为单位输出。 -s或\u0026ndash;summarize 仅显示总计，只列出最后加总的值。 -h或\u0026ndash;human-readable 以K，M，G为单位，提高信息的可读性。 -x或\u0026ndash;one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 -L\u0026lt;符号链接\u0026gt;或\u0026ndash;dereference\u0026lt;符号链接\u0026gt; 显示选项中所指定符号链接的源文件大小。 -S或\u0026ndash;separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -X\u0026lt;文件\u0026gt;或\u0026ndash;exclude-from=\u0026lt;文件\u0026gt; 在\u0026lt;文件\u0026gt;指定目录或文件。 \u0026ndash;exclude=\u0026lt;目录或文件\u0026gt; 略过指定的目录或文件。 -D或\u0026ndash;dereference-args 显示指定符号链接的源文件大小。 -H或\u0026ndash;si 与-h参数相同，但是K，M，G是以1000为换算单位。 -l或\u0026ndash;count-links 重复计算硬件链接的文件。 使用实例\n1.显示指定目录或文件所占空间\ndu test # 目录 du test.log # 文件 六、性能监控和优化命令 27.top 命令 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等。\n命令格式\ntop [参数]\n常见参数\n-b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i\u0026lt;时间\u0026gt; 设置间隔时间 -u\u0026lt;用户名\u0026gt; 指定用户名 -p\u0026lt;进程号\u0026gt; 指定进程 -n\u0026lt;次数\u0026gt; 循环显示的次数 使用实例\n显示进程信息。 top 28.free 命令 显示系统使用和空闲的内存情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。\n命令格式\nfree [参数]\n常见参数\n-b 以Byte为单位显示内存使用情况 -k 以KB为单位显示内存使用情况 -m 以MB为单位显示内存使用情况 -g 以GB为单位显示内存使用情况 -o 不显示缓冲区调节列 -s\u0026lt;间隔秒数\u0026gt; 持续观察内存使用状况 -t 显示内存总和列。 -V 显示版本信息。 使用实例\n1.显示内存情况。\nfree free -g #以GB为单位 free -m #以MB为单位 29. vmstat 用来显示虚拟内存的信息。\n命令格式\nvmstat [-a] [-n] [-S unit] [delay [ count]] vmstat [-s] [-n] [-S unit] vmstat [-m] [-n] [delay [ count]] vmstat [-d] [-n] [delay [ count]] vmstat [-p disk partition] [-n] [delay [ count]] vmstat [-f] vmstat [-V] 常见参数\n-a：显示活跃和非活跃内存 -f：显示从系统启动至今的fork数量 -m：显示slabinfo -n：只在开始时显示一次各字段名称 -s：显示内存相关统计信息及多种系统活动数量 delay：刷新时间间隔。如果不指定，只显示一条结果 count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷 -d：显示磁盘相关统计信息 -p：显示指定磁盘分区统计信息 -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） 使用实例\n1.显示活跃和非活跃内存。\nvmstat -a 5 5 # 5秒时间内进行5次采样 30.lostat 命令 通过iostat方便查看CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况, 负载信息。\n命令格式\niostat [参数] [时间] [次数]\n常见参数\n-C 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 使用实例\n1.定时显示所有信息。\niostat 2 3 #每隔 2秒刷新显示，且显示3次 31. lsof 命令 lsof命令 用于查看你进程打开的文件，打开文件的进程，进程打开的端口(TCP、UDP)。找回/恢复删除的文件。是十分方便的系统监视工具，因为lsof命令需要访问核心内存和各种文件，所以需要root用户执行。\n命令格式\nlsof [参数] [文件]\n常见参数\n-a 列出打开文件存在的进程 -c\u0026lt;进程名\u0026gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d\u0026lt;文件号\u0026gt; 列出占用该文件号的进程 +d\u0026lt;目录\u0026gt; 列出目录下被打开的文件 +D\u0026lt;目录\u0026gt; 递归列出目录下被打开的文件 -n\u0026lt;目录\u0026gt; 列出使用NFS的文件 -i\u0026lt;条件\u0026gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p\u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 使用实例\n1.查看谁正在使用bash文件，也就是说查找某个文件相关的进程。\nlsof /bin/bash 2.结合 which\nroot@VM-12-12-ubuntu:/Blaine# which vim /usr/bin/vim root@VM-12-12-ubuntu:/Blaine# lsof /usr/bin/vim COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME vim 3774051 root txt REG 252,2 2906824 131244 /usr/bin/vim.basic 七、网络命令 32.ifconfig 命令 ifconfig 命令用来查看和配置网络设备。\n命令格式\nifconfig [网络设备] [参数]\n常见参数\nup 启动指定网络设备/网卡 down 关闭指定网络设备/网卡。 arp 设置指定网卡是否支持ARP协议 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 使用实例\n1.启动关闭指定网卡\nifconfig eth0 up ifconfig eth0 down 2.用ifconfig修改MAC地址\nifconfig eth0 hw ether 00:AA:BB:CC:DD:EE 33. route 命令 Route命令是用于操作基于内核ip路由表，它的主要作用是创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。\n命令格式\nroute [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]]\n常见参数\n-c 显示更多信息 -n 不解析名字 -v 显示详细的处理信息 -F 显示发送信息 -C 显示路由缓存 -f 清除所有网关入口的路由表。 -p 与 add 命令一起使用时使路由具有永久性。 add:添加一条新路由。 del:删除一条路由。 -net:目标地址是一个网络。 -host:目标地址是一个主机。 netmask:当添加一个网络路由时，需要使用网络掩码。 gw:路由数据包通过网关。注意，你指定的网关必须能够达到。 metric：设置路由跳数。 Command 指定您想运行的命令 (Add/Change/Delete/Print)。 Destination 指定该路由的网络目标。 使用实例\n1.显示当前路由\nroute route -n 2.添加网关/设置网关\nroute add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 34. ping 命令 确定网络和各外部主机的状态；跟踪和隔离硬件和软件问题；测试、评估和管理网络。\n命令格式\nping [参数] [主机名或IP地址]\n常见参数\n-d 使用Socket的SO_DEBUG功能 -f 极限检测。大量且快速地送网络封包给一台机器，看它的回应 -n 只输出数值 -q 不显示任何传送封包的信息，只显示最后的结果 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题 -R 记录路由过程 -v 详细显示指令的执行过程 -c 数目：在发送指定数目的包后停止 -i 秒数：设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次 -I 网络界面：使用指定的网络界面送出数据包 -l 前置载入：设置在送出要求信息之前，先行发出的数据包 -p 范本样式：设置填满数据包的范本样式 -s 字节数：指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节 -t 存活数值：设置存活数值TTL的大小 使用实例\nping 网关 ping -b 192.168.120.1 35.traceroute 命令 让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。\n命令格式\ntraceroute [参数] [主机]\n常见参数\n-d 使用Socket层级的排错功能 -f 设置第一个检测数据包的存活数值TTL的大小 -F 设置勿离断位 -g 设置来源路由网关，最多可设置8个 -i 使用指定的网络界面送出数据包 -I 使用ICMP回应取代UDP资料信息 -m 设置检测数据包的最大存活数值TTL的大小 -n 直接使用IP地址而非主机名称 -p 设置UDP传输协议的通信端口 -r 忽略普通的Routing Table，直接将数据包送到远端主机上 -s 设置本地主机送出数据包的IP地址 -t 设置检测数据包的TOS数值 -v 详细显示指令的执行过程 -w 设置等待远端主机回报的时间 -x 开启或关闭数据包的正确性检验 使用实例\n1.traceroute 用法简单、最常用的用法\ntraceroute www.baidu.com 跳数设置 traceroute -m 10 www.baidu.com 36.netstat 命令 用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。\n命令格式\nnetstat [-acCeFghilMnNoprstuvVwx] [-A\u0026lt;网络类型\u0026gt;] [\u0026ndash;ip]\n常见参数\n-a或–all 显示所有连线中的Socket -A\u0026lt;网络类型\u0026gt;或–\u0026lt;网络类型\u0026gt; 列出该网络类型连线中的相关地址 -c或–continuous 持续列出网络状态 -C或–cache 显示路由器配置的快取信息 -e或–extend 显示网络其他相关信息 -F或–fib 显示FIB -g或–groups 显示多重广播功能群组组员名单 -h或–help 在线帮助 -i或–interfaces 显示网络界面信息表单 -l或–listening 显示监控中的服务器的Socket -M或–masquerade 显示伪装的网络连线 -n或–numeric 直接使用IP地址，而不通过域名服务器 -N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称 -o或–timers 显示计时器 -p或–programs 显示正在使用Socket的程序识别码和程序名称 -r或–route 显示Routing Table -s或–statistice 显示网络工作信息统计表 -t或–tcp 显示TCP传输协议的连线状况 -u或–udp 显示UDP传输协议的连线状况 -v或–verbose 显示指令执行过程 -V或–version 显示版本信息 -w或–raw 显示RAW传输协议的连线状况 -x或–unix 此参数的效果和指定”-A unix”参数相同 –ip或–inet 此参数的效果和指定”-A inet”参数相同 使用实例\n列出所有端口 netstat -a 37.telnet 命令 执行telnet指令开启终端机阶段作业，并登入远端主机。\n命令格式\ntelnet [参数] [主机]\n常见参数\n-8 允许使用8位字符资料，包括输入与输出 -a 尝试自动登入远端系统 -b\u0026lt;主机别名\u0026gt; 使用别名指定远端主机名称 -c 不读取用户专属目录里的.telnetrc文件 -d 启动排错模式 -e\u0026lt;脱离字符\u0026gt; 设置脱离字符 -E 滤除脱离字符 -f 此参数的效果和指定\u0026quot;-F\u0026quot;参数相同 使用实例\n1.远程服务器无法访问\ntelnet 192.168.120.206 八、其他命令 38.ln 命令 为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。\n命令格式\nln [参数] [源文件或目录] [目标文件或目录]\n常用参数\n必要参数:\n-b 删除，覆盖以前建立的链接 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s 软链接(符号链接) -v 显示详细的处理过程 选择参数:\n-S “-S\u0026lt;字尾备份字符串\u0026gt; ”或 “\u0026ndash;suffix=\u0026lt;字尾备份字符串\u0026gt;” -V “-V\u0026lt;备份方式\u0026gt;”或“\u0026ndash;version-control=\u0026lt;备份方式\u0026gt;” 使用实例\n1.为 test.log文件创建软链接linktest。\nln -s test.log linktest 2.为 test.log创建硬链接lntest。\nln test.log lntest 39.diff 命令 比较单个文件或者目录内容。\n命令格式\ndiff [参数] [文件1或目录1] [文件2或目录2]\n常用参数\n-c 上下文模式，显示全部内文，并标出不同之处 -u 统一模式，以合并的方式来显示文件内容的不同 -a 只会逐行比较文本文件 -N 在比较目录时，若文件 A 仅出现在某个目录中，预设会显示：Only in 目录。若使用 -N 参数，则 diff 会将文件 A 与一个空白的文件比较 -r 递归比较目录下的文件 使用实例\n1.显示 test1.txt 和 test2.txt 两个文件差异。\ndiff test1.txt test2.txt 40.grep 命令 一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。\n命令格式\ngrep [option] pattern file\n常用参数\n-c 计算找到‘搜寻字符串’（即 pattern）的次数 -i 忽略大小写的不同，所以大小写视为相同 -n 输出行号 -v 反向选择，打印不匹配的行 -r 递归搜索 \u0026ndash;color=auto 将找到的关键词部分加上颜色显示 使用实例\n1.将 /etc/passwd 文件中出现 root 的行取出来，关键词部分加上颜色显示。\ngrep \u0026#34;root\u0026#34; /etc/passwd --color=auto cat /etc/passwd | grep \u0026#34;root\u0026#34; --color=auto 2.将 /etc/passwd 文件中没有出现 root 和 nologin 的行取出来。\ngrep -v \u0026#34;root\u0026#34; /etc/passwd | grep -v \u0026#34;nologin\u0026#34; 41.wc 命令 用来显示文件所包含的行、字和字节数。\n命令格式\nwc [选项] [文件]\n常用参数\n-c 统计字节数 -l 统计行数 -m 统计字符数，这个标志不能与 -c 标志一起使用 -w 统计字数，一个字被定义为由空白、跳格或换行字符分隔的字符串 -L 打印最长行的长度 使用实例\n1.统计文件的字节数、行数和字符数。\nwc -c test.txt wc -l test.txt wc -m test.txt 2.统计文件的字节数、行数和字符数，只打印数字，不打印文件名。\ncat test.txt | wc -c cat test.txt | wc -l cat test.txt | wc -m 42.ps 命令 用来显示当前进程的状态。\n命令格式\nps[参数]\n常用参数\na 显示所有进程 -a 显示同一终端下的所有程序 -A 显示所有进程 c 显示进程的真实名称 -N 反向选择 -e 等于“-A” e 显示环境变量 f 显示程序间的关系 -H 显示树状结构 r 显示当前终端的进程 T 显示当前终端的所有程序 u 指定用户的所有进程 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 -C\u0026lt;命令\u0026gt; 列出指定命令的状况 \u0026ndash;lines\u0026lt;行数\u0026gt; 每页显示的行数 \u0026ndash;width\u0026lt;字符数\u0026gt; 每页显示的字符数 使用实例\n1.显示所有进程信息。\nps -A 显示指定用户信息。 ps -u root 显示所有进程信息，连同命令行。 ps -ef 43.watch 命令 可以将命令的输出结果输出到标准输出设备，多用于周期性执行命令/定时执行命令。\n命令格式\nwatch [参数] [命令]\n常用参数\n-n或\u0026ndash;interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。 -d或\u0026ndash;differences 用-d或\u0026ndash;differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。 -t 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 -h, \u0026ndash;help 查看帮助文档 使用实例\n1.每隔一秒高亮显示网络链接数的变化情况\nwatch -n 1 -d netstat -ant 2.每隔一秒高亮显示http链接数的变化情况\nwatch -n 1 -d \u0026#39;pstree|grep http\u0026#39; 44. at 命令 在一个指定的时间执行一个指定任务，只能执行一次。（需开启atd进程）\n命令格式\nat [参数] [时间]\n常用参数\n-m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出 -I atq的别名 -d atrm的别名 -v 显示任务将被执行的时间 -c 打印任务的内容到标准输出 -V 显示版本信息 -q\u0026lt;列队\u0026gt; 使用指定的列队 -f\u0026lt;文件\u0026gt; 从指定文件读入任务而不是从标准输入读入 -t\u0026lt;时间参数\u0026gt; 以时间参数的形式提交要运行的任务 使用实例\n1.3天后的下午5点执行/bin/ls\nat 5pm+3 days at\u0026gt; /bin/ls at\u0026gt; \u0026lt;EOT\u0026gt; 45.crontab 命令 在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。(需开启crond服务)\n命令格式\ncrontab [-u user] file 或\ncrontab [-u user] [ -e | -l | -r ]\n常用参数\n-u user：用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。 file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。 -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i：在删除用户的crontab文件时给确认提示。 使用实例\n1.列出 crontab 文件。\ncrontab -l 2.编辑crontab 文件。\ncrontab -e Crontab 任务实例\n1.每1分钟执行一次command\n* * * * * command 2.每小时的第3和第15分钟执行\n3,15 * * * * command 3.在上午8点到11点的第3和第15分钟执行\n3,15 8-11 * * * command 46. vim 删除行命令 在Vim中删除一行的命令是dd。\n1、按Esc键进入正常模式。 2、将光标放在要删除的行上。 3、键入dd并按E​​nter键以删除该行。 删除多行，在dd命令前添加要删除的行数\n1、按Esc键进入正常模式。 2、将光标放在要删除的第一行上。 3、键入5dd并按E​​nter键以删除接下来的五行。 删除行范围\n:[start],[end]d\n例如，要删除从3到5的行，您可以执行以下操作： 1、按Esc键进入正常模式。 2、输入:3,5d，然后按Enter键以删除行。 删除所有行\n要删除所有行，您可以使用代表所有行的%符号或1，$范围： 1、按Esc键进入正常模式。 2、键入%d，然后按Enter键以删除所有行。 ","permalink":"https://Bin-lin-rgb.github.io/posts/deploy/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","summary":"一般参数的意思 -a all（全部） -r recursion（递归） -f force（强制） -h 以K，M，G为单位，提高信息的可读性。 一、文件目录操作 1. ls 命令 ls 命令不仅可以查看 linux 文件夹包含的文件而且可以查看文件权限(包括目录、文件夹、文件权限)查看目录信息等等。 命令格式 ls [选项][目录名] 常用参","title":"Linux常用命令"},{"content":"动态规划的解题步骤 \u0026ndash; from 代码随想录\n做动规题目的时候，很多同学会陷入一个误区，就是以为把状态转移公式背下来，照葫芦画瓢改改，就开始写代码，甚至把题目 AC 之后，都不太清楚 dp[i]表示的是什么。\n这就是一种朦胧的状态，然后就把题给过了，遇到稍稍难一点的，可能直接就不会了，然后看题解，然后继续照葫芦画瓢陷入这种恶性循环中。\n状态转移公式（递推公式）是很重要，但动规不仅仅只有递推公式。\n对于动态规划问题，我将拆解为如下五步曲，这五步都搞清楚了，才能说把动态规划真的掌握了！\n确定 dp 数组（dp table）以及下标的含义 确定递推公式 dp 数组如何初始化 确定遍历顺序 举例推导 dp 数组 遍历顺序：\n如果求组合数就是外层for循环遍历物品，内层for遍历背包。\n如果求排列数就是外层for遍历背包，内层for循环遍历物品。\n01 背包 二维数组 1、确定 dp 数组以及下标的含义\n对于背包问题，有一种写法，是使用二维数组，即 dp[i][j] 表示从下标为[0-i]的物品里任意取，放进容量为 j 的背包，价值总和最大是多少。\n2、确定递推公式\n再回顾一下 dp[i][j]的含义：从下标为[0~i]的物品里任意取，放进容量为 j 的背包，价值总和最大是多少。\n那么可以有两个方向推出来 dp[i][j]，\n不放物品 i：由 dp[i - 1][j]推出，即背包容量为 j，里面不放物品 i 的最大价值，此时 dp[i][j]就是 dp[i - 1][j]。(其实就是当物品 i 的重量大于背包 j 的重量时，物品 i 无法放进背包中，所以背包内的价值依然和前面相同。)\n放物品 i：由 dp[i - 1]j - weight[i]]推出，dp[i - 1]j - weight[i]] 为背包容量为 j - weight[i]的时候不放物品 i 的最大价值，那么 dp[i - 1]j - weight[i]] + value[i] （物品 i 的价值），就是背包放物品 i 得到的最大价值\n所以递归公式： dp[i][j] = max(dp[i - 1][j], dp[i - 1]j - weight[i]] + value[i]);\n3、初始化\nfor (int j = weight[0]; j \u0026lt;= bagweight; j++) { dp[0][j] = value[0]; } 4、遍历顺序\n那么问题来了，先遍历 物品还是先遍历背包重量呢？\n其实都可以！！ 但是先遍历物品更好理解。\n// weight数组的大小 就是物品个数 for(int i = 1; i \u0026lt; weight.size(); i++) { // 遍历物品 for(int j = 0; j \u0026lt;= bagweight; j++) { // 遍历背包容量 if (j \u0026lt; weight[i]) dp[i][j] = dp[i - 1][j]; else dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]); } } 一维数组 也就是滚动数组，只需要注意遍历的顺序！\nfunc test_1_wei_bag_problem(weight, value []int, bagWeight int) int { // 定义 and 初始化 dp := make([]int, bagWeight+1) // 递推顺序 for i := 0 ;i \u0026lt; len(weight) ; i++ { // 这里必须倒序,区别二维,因为二维dp保存了i的状态 for j:= bagWeight; j \u0026gt;= weight[i] ; j-- { // 递推公式 dp[j] = max(dp[j], dp[j-weight[i]]+value[i]) } } return dp[bagWeight] } func max(a,b int) int { if a \u0026gt; b { return a } return b } func main() { weight := []int{1,3,4} value := []int{15,20,30} test_1_wei_bag_problem(weight,value,4) } 416. 分割等和子集 力扣题目链接\n背包问题，大家都知道，有N件物品和一个最多能背重量为W 的背包。第i件物品的重量是weight[i]，得到的价值是value[i] 。每件物品只能用一次，求解将哪些物品装入背包里物品价值总和最大。\n背包问题有多种背包方式，常见的有：01背包、完全背包、多重背包、分组背包和混合背包等等。\n要注意题目描述中商品是不是可以重复放入。 即一个商品如果可以重复多次放入是完全背包，而只能放入一次是01背包，写法还是不一样的。\n要明确本题中我们要使用的是01背包，因为元素我们只能用一次。\n回归主题：首先，本题要求集合里能否出现总和为 sum / 2 的子集。\n只有确定了如下四点，才能把01背包问题套到本题上来。\n背包的体积为sum / 2 背包要放入的商品（集合里的元素）重量为 元素的数值，价值也为元素的数值 背包如果正好装满，说明找到了总和为 sum / 2 的子集。 背包中每一个元素是不可重复放入。 以上分析完，我们就可以套用01背包，来解决这个问题了。\n动规五部曲分析如下：\n1、确定dp数组以及下标的含义 01背包中，dp[j] 表示： 容量为j的背包，所背的物品价值最大可以为dp[j]。\n本题中每一个元素的数值既是重量，也是价值。\n套到本题，dp[j]表示 背包总容量（所能装的总重量）是j，放进物品后，背的最大重量为dp[j]。\n那么如果背包容量为target， dp[target]就是装满 背包之后的重量，所以 当 dp[target] == target 的时候，背包就装满了。\n有录友可能想，那还有装不满的时候？\n拿输入数组 [1, 5, 11, 5]，举例， dp[7] 只能等于 6，因为 只能放进 1 和 5， 1+5=6。\n而dp[6] 就可以等于6了，放进1 和 5，那么dp[6] == 6，说明背包装满了。\n2、确定递推公式\n01背包的递推公式为：dp[j] = max(dp[j], dp[j - weight[i]] + value[i]);\n本题，相当于背包里放入数值，那么物品i的重量是nums[i]，其价值也是nums[i]。\n所以递推公式：dp[j] = max(dp[j], dp[j - nums[i]] + nums[i]);\n3、dp数组如何初始化 在01背包，一维dp如何初始化，已经讲过，\n从dp[j]的定义来看，首先dp[0]一定是0。\n如果题目给的价值都是正整数那么非0下标都初始化为0就可以了，如果题目给的价值有负数，那么非0下标就要初始化为负无穷。\n这样才能让dp数组在递推的过程中取得最大的价值，而不是被初始值覆盖了。\n本题题目中 只包含正整数的非空数组，所以非0下标的元素初始化为0就可以了。\n// 分割等和子集 动态规划 // 时间复杂度O(n^2) 空间复杂度O(n) func canPartition(nums []int) bool { sum := 0 for _, num := range nums { sum += num } // 如果 nums 的总和为奇数则不可能平分成两个子集 if sum % 2 == 1 { return false } target := sum / 2 dp := make([]int, target + 1) for _, num := range nums { // 倒序！只能使用一次 for j := target; j \u0026gt;= num; j-- { if dp[j] \u0026lt; dp[j - num] + num { dp[j] = dp[j - num] + num } } } return dp[target] == target } 时间复杂度：O(n^2) 空间复杂度：O(n)，虽然dp数组大小为一个常数，但是大常数\n总结 这道题目就是一道01背包应用类的题目，需要我们拆解题目，然后套入01背包的场景。\n01背包相对于本题，主要要理解，题目中物品是nums[i]，重量是nums[i]，价值也是nums[i]，背包体积是sum/2。\n看代码的话，就可以发现，基本就是按照01背包的写法来的。\n目标和 https://leetcode.cn/problems/target-sum/description/\n给你一个非负整数数组 nums 和一个整数 target 。\n向数组中的每个整数前添加 \u0026lsquo;+\u0026rsquo; 或 \u0026lsquo;-\u0026rsquo; ，然后串联起所有整数，可以构造一个 表达式 ：\n例如，nums = [2, 1] ，可以在 2 之前添加 \u0026lsquo;+\u0026rsquo; ，在 1 之前添加 \u0026lsquo;-\u0026rsquo; ，然后串联起来得到表达式 \u0026ldquo;+2-1\u0026rdquo; 。 返回可以通过上述方法构造的、运算结果等于 target 的不同 表达式 的数目。\n示例 1： 输入：nums = [1,1,1,1,1], target = 3 输出：5 解释：一共有 5 种方法让最终目标和为 3 。 -1 + 1 + 1 + 1 + 1 = 3 +1 - 1 + 1 + 1 + 1 = 3 +1 + 1 - 1 + 1 + 1 = 3 +1 + 1 + 1 - 1 + 1 = 3 +1 + 1 + 1 + 1 - 1 = 3 示例 2： 输入：nums = [1], target = 1 输出：1 func findTargetSumWays(nums []int, target int) int { sum := 0 for _, v := range nums { sum += v } if abs(target) \u0026gt; sum { return 0 } if (sum+target)%2 == 1 { return 0 } // 计算背包大小 bag := (sum + target) / 2 // 定义dp数组 dp := make([]int, bag+1) // 初始化 dp[0] = 1 // 遍历顺序 for i := 0; i \u0026lt; len(nums); i++ { for j := bag; j \u0026gt;= nums[i]; j-- { //推导公式 dp[j] += dp[j-nums[i]] } } return dp[bag] } func abs(x int) int { return int(math.Abs(float64(x))) } 零钱兑换 给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。\n计算并返回可以凑成总金额所需的 最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。\n你可以认为每种硬币的数量是无限的。\n示例 1： 输入：coins = [1, 2, 5], amount = 11 输出：3 解释：11 = 5 + 5 + 1 示例 2： 输入：coins = [2], amount = 3 输出：-1 示例 3： 输入：coins = [1], amount = 0 输出：0 func coinChange(coins []int, amount int) int { dp := make([]int, amount+1) // 初始化dp[0] dp[0] = 0 // 初始化为math.MaxInt32 for j := 1; j \u0026lt;= amount; j++ { dp[j] = math.MaxInt32 } // 遍历物品 for i := 0; i \u0026lt; len(coins); i++ { // 遍历背包 for j := coins[i]; j \u0026lt;= amount; j++ { if dp[j-coins[i]] != math.MaxInt32 { // 推导公式 dp[j] = min(dp[j], dp[j-coins[i]]+1) //fmt.Println(dp,j,i) } } } // 没找到能装满背包的, 就返回-1 if dp[amount] == math.MaxInt32 { return -1 } return dp[amount] } 兑换零钱II https://leetcode.cn/problems/coin-change-ii/\n给你一个整数数组 coins 表示不同面额的硬币，另给一个整数 amount 表示总金额。\n请你计算并返回可以凑成总金额的硬币组合数。如果任何硬币组合都无法凑出总金额，返回 0 。\n假设每一种面额的硬币有无限个。\n题目数据保证结果符合 32 位带符号整数。\n示例 1： 输入：amount = 5, coins = [1, 2, 5] 输出：4 解释：有四种方式可以凑成总金额： 5=5 5=2+2+1 5=2+1+1+1 5=1+1+1+1+1 示例 2： 输入：amount = 3, coins = [2] 输出：0 解释：只用面额 2 的硬币不能凑成总金额 3 。 示例 3： 输入：amount = 10, coins = [10] 输出：1 func change(amount int, coins []int) int { // 求组合数，先物品后背包 // 1、定义dp数组 // dp[j] 的值表示 装满 j 容量 的方法数量 dp := make([]int, amount+1) // 2、递推公式： // dp[j] 就是所有的dp[j - coins[i]]（考虑coins[i]的情况）相加 // 所以递推公式：dp[j] += dp[j - coins[i]] // 3、初始化 // 首先dp[0]一定要为1，dp[0] = 1是 递归公式的基础。 // 如果dp[0] = 0 的话，后面所有推导出来的值都是0了 dp[0] = 1 // 4、遍历顺序 for i:=0;i\u0026lt;len(coins);i++ { for j:=coins[i];j\u0026lt;=amount;j++ { dp[j] += dp[j - coins[i]] } } return dp[amount] } ","permalink":"https://Bin-lin-rgb.github.io/posts/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","summary":"动态规划的解题步骤 \u0026ndash; from 代码随想录 做动规题目的时候，很多同学会陷入一个误区，就是以为把状态转移公式背下来，照葫芦画瓢改改，就开始写代码，甚至把题目 AC 之后，都不太清楚 dp[i]表示的是什么。 这就是一种朦胧的状态，然后就把题给过了，遇到稍稍难一点的，可能直接就不会了，然后看题解，然后继","title":"动态规划"},{"content":"二叉树的所有问题，就是让你在前中后序位置注入巧妙的代码逻辑，去达到自己的目的，你只需要单独思考每一个节点应该做什么，其他的不用你管，抛给二叉树遍历框架，递归会在所有节点上做相同的操作。\n理解二叉树的前中后序遍历 二叉树题目的递归解法可以分两类思路\n第一类是遍历一遍二叉树得出答案 第二类是通过分解问题计算出答案 这两类思路分别对应着 回溯 和 动态规划。\n最大深度 力扣第 104 题「二叉树的最大深度」：最大深度\n遍历 // 记录最大深度 var res int // 记录遍历到的节点的深度 var depth int // 主函数 func maxDepth(root *TreeNode) int { traverse(root) return res } // 二叉树遍历框架 func traverse(root *TreeNode) { if root == nil { return } // 前序位置 depth++ if root.Left == nil \u0026amp;\u0026amp; root.Right == nil { // 到达叶子节点，更新最大深度 res = max(res, depth) } traverse(root.Left) traverse(root.Right) // 后序位置 depth-- } func max(a, b int) int { if a \u0026gt; b { return a } return b } 分解问题 // 定义：输入根节点，返回这棵二叉树的最大深度 func maxDepth(root *TreeNode) int { if root == nil { return 0 } // 利用定义，计算左右子树的最大深度 leftMax := maxDepth(root.Left) rightMax := maxDepth(root.Right) // 整棵树的最大深度等于左右子树的最大深度取最大值， // 然后再加上根节点自己 res := max(leftMax, rightMax) + 1 return res } func max(a int, b int) int { if a \u0026gt; b { return a } return b } 后序的特殊 一旦你发现题目和子树有关，那大概率要给函数设置合理的定义和返回值，在后序位置写代码了。\n二叉树的直径 给你一棵二叉树的根节点，返回该树的 直径 。\n二叉树的 直径 是指树中任意两个节点之间最长路径的 长度 。这条路径可能经过也可能不经过根节点 root 。\n两节点之间路径的 长度 由它们之间边数表示。\n示例 1： 输入：root = [1,2,3,4,5] 输出：3 解释：3 ，取路径 [4,2,1,3] 或 [5,2,1,3] 的长度。 示例 2： 输入：root = [1,2] 输出：1 解决这题的关键在于，每一条二叉树的「直径」长度，就是一个节点的左右子树的最大深度之和\nfunc diameterOfBinaryTree(root *TreeNode) int { maxDiameter := 0 maxDepth(root, \u0026amp;maxDiameter) return maxDiameter } func maxDepth(node *TreeNode, maxDiameter *int) int { if node == nil { return 0 } leftMax := maxDepth(node.Left, maxDiameter) rightMax := maxDepth(node.Right, maxDiameter) // 后序位置，顺便计算最大直径 myDiameter := leftMax + rightMax if myDiameter \u0026gt; *maxDiameter { *maxDiameter = myDiameter } return 1 + max(leftMax, rightMax) } func max(a, b int) int { if a \u0026gt; b { return a } return b } 层序遍历 // 输入一棵二叉树的根节点，层序遍历这棵二叉树 func levelTraverse(root *TreeNode) { if root == nil { return } q := make([]*TreeNode, 0) q = append(q, root) // 从上到下遍历二叉树的每一层 for len(q) \u0026gt; 0 { sz := len(q) // 从左到右遍历每一层的每个节点 for i := 0; i \u0026lt; sz; i++ { cur := q[0] q = q[1:] // 将下一层节点放入队列 if cur.Left != nil { q = append(q, cur.Left) } if cur.Right != nil { q = append(q, cur.Right) } } } } ","permalink":"https://Bin-lin-rgb.github.io/posts/leetcode/%E4%BA%8C%E5%8F%89%E6%A0%91/","summary":"二叉树的所有问题，就是让你在前中后序位置注入巧妙的代码逻辑，去达到自己的目的，你只需要单独思考每一个节点应该做什么，其他的不用你管，抛给二叉树遍历框架，递归会在所有节点上做相同的操作。 理解二叉树的前中后序遍历 二叉树题目的递归解法可以分两类思路 第一类是遍历一遍二叉树得出答案 第二类是","title":"二叉树"},{"content":"快速排序 package main import \u0026#34;math/rand\u0026#34; func SortArray(nums []int) []int { quick(nums, 0, len(nums)-1) return nums } func quick(arr []int, i, j int) { if i \u0026gt;= j { return } mid := partition(arr, i, j) quick(arr, i, mid-1) quick(arr, mid+1, j) } func partition(nums []int, i int, j int) int { // 随机选择“支点”位置 p := rand.Intn(j-i+1) + i // 交换支点和第一个元素 nums[i], nums[p] = nums[p], nums[i] for i \u0026lt; j { // 从右向左找到第一个小于支点的元素 for nums[i] \u0026lt; nums[j] \u0026amp;\u0026amp; i \u0026lt; j { j-- } // 交换元素，将较小的元素移至左侧 if i \u0026lt; j { nums[i], nums[j] = nums[j], nums[i] i++ } // 从左向右找到第一个大于支点的元素 for nums[i] \u0026lt; nums[j] \u0026amp;\u0026amp; i \u0026lt; j { i++ } // 交换元素，将较大的元素移至右侧 if i \u0026lt; j { nums[i], nums[j] = nums[j], nums[i] j-- } } // 返回支点的最终位置 return i } ","permalink":"https://Bin-lin-rgb.github.io/posts/leetcode/%E6%8E%92%E5%BA%8F/","summary":"快速排序 package main import \u0026#34;math/rand\u0026#34; func SortArray(nums []int) []int { quick(nums, 0, len(nums)-1) return nums } func quick(arr []int, i, j int) { if i \u0026gt;= j { return } mid := partition(arr, i, j) quick(arr, i, mid-1) quick(arr, mid+1, j) } func partition(nums []int, i int, j int) int { // 随机选择“支点”位置 p := rand.Intn(j-i+1) + i // 交换支点和第一个元素 nums[i], nums[p] = nums[p], nums[i] for i \u0026lt; j { // 从右向左找到第一个小于支点的元素 for nums[i] \u0026lt; nums[j] \u0026amp;\u0026amp; i \u0026lt; j { j-- } // 交换元素，将较小的元素移至左侧 if i \u0026lt; j {","title":"排序"},{"content":"快慢指针 26. 删除有序数组中的重复项 给你一个 非严格递增排列 的数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。然后返回 nums 中唯一元素的个数。\n考虑 nums 的唯一元素的数量为 k ，你需要做以下事情确保你的题解可以被通过：\n更改数组 nums ，使 nums 的前 k 个元素包含唯一元素，并按照它们最初在 nums 中出现的顺序排列。nums 的其余元素与 nums 的大小不重要。 返回 k 。\n示例 1： 输入：nums = [1,1,2] 输出：2, nums = [1,2,_] 解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。 示例 2： 输入：nums = [0,0,1,1,1,2,2,3,3,4] 输出：5, nums = [0,1,2,3,4] 解释：函数应该返回新的长度 5 ， 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4 。不需要考虑数组中超出新长度后面的元素。 link to LeetCode\n使用快慢指针\nfunc removeDuplicates(nums []int) int { if len(nums) == 0 { return 0 } slow, fast := 0, 0 for fast \u0026lt; len(nums) { if nums[fast] != nums[slow] { // 慢指针先往前，再赋值 slow++ nums[slow] = nums[fast] } fast++ } // 数组长度为索引 + 1 return slow + 1 } 移除元素 https://leetcode.cn/problems/remove-element/\n给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\n不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。\n元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。\n示例 1： 输入：nums = [3,2,2,3], val = 3 输出：2, nums = [2,2] 解释：函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 2 ，而 nums = [2,2,3,3] 或 nums = [2,2,0,0]，也会被视作正确答案。 示例 2： 输入：nums = [0,1,2,2,3,0,4,2], val = 2 输出：5, nums = [0,1,4,0,3] 解释：函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。 func removeElement(nums []int, val int) int { fast, slow := 0, 0 for fast \u0026lt; len(nums) { if nums[fast] != val { nums[slow] = nums[fast] slow++ } fast++ } return slow } 注意这里和有序数组去重的解法有一个细节差异，我们这里是先给 nums[slow] 赋值然后再给 slow++，这样可以保证 nums[0..slow-1] 是不包含值为 val 的元素的，最后的结果数组长度就是 slow。\n左右指针 两数之和II func twoSum(nums []int, target int) []int { // 一左一右两个指针相向而行 left, right := 0, len(nums) - 1 for left \u0026lt; right { sum := nums[left] + nums[right] if sum == target { // 题目要求的索引是从 1 开始的 return []int{left + 1, right + 1} } else if sum \u0026lt; target { left++ // 让 sum 大一点 } else if sum \u0026gt; target { right-- // 让 sum 小一点 } } return []int{-1, -1} } ","permalink":"https://Bin-lin-rgb.github.io/posts/leetcode/%E5%8F%8C%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/","summary":"快慢指针 26. 删除有序数组中的重复项 给你一个 非严格递增排列 的数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。然后返回 nums 中唯一元素的个数。 考虑 nums 的唯一元素的数量为 k ，你需要做以下事情确保你的题解可以被通过： 更改数组 nums ，使 nums 的","title":"双指针（数组）"},{"content":"协程交替打印 a1b2c3\u0026hellip; package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var wg sync.WaitGroup wg.Add(1) chNumber := make(chan struct{}) chLetter := make(chan struct{}) i := 1 index := 0 a := \u0026#34;\u0026#34; for c := \u0026#39;a\u0026#39;; c \u0026lt;= \u0026#39;z\u0026#39;; c++ { a = a + string(c) } go func() { for { select { case \u0026lt;-chNumber: fmt.Print(i) i++ chLetter \u0026lt;- struct{}{} break default: break } } }() go func(wg *sync.WaitGroup) { for { select { case \u0026lt;-chLetter: if index \u0026gt; len(a)-1 { wg.Done() return } fmt.Print(string(a[index])) index++ chNumber \u0026lt;- struct{}{} break default: break } } }(\u0026amp;wg) chLetter \u0026lt;- struct{}{} wg.Wait() } ","permalink":"https://Bin-lin-rgb.github.io/posts/go/some_examples/","summary":"协程交替打印 a1b2c3\u0026hellip; package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var wg sync.WaitGroup wg.Add(1) chNumber := make(chan struct{}) chLetter := make(chan struct{}) i := 1 index := 0 a := \u0026#34;\u0026#34; for c := \u0026#39;a\u0026#39;; c \u0026lt;= \u0026#39;z\u0026#39;; c++ { a = a + string(c) } go func() { for { select { case \u0026lt;-chNumber: fmt.Print(i) i++ chLetter \u0026lt;- struct{}{} break default: break } } }() go func(wg *sync.WaitGroup) { for { select { case \u0026lt;-chLetter: if index \u0026gt; len(a)-1 { wg.Done() return } fmt.Print(string(a[index])) index++ chNumber \u0026lt;- struct{}{} break default: break } } }(\u0026amp;wg) chLetter \u0026lt;- struct{}{} wg.Wait() }","title":"Some_examples"},{"content":"合并两个有序链表 LeetCode\n这道题也是大二数据结构的课本题目，使用虚拟头结点方便操作；\nfunc mergeTwoLists(l1 *ListNode, l2 *ListNode) *ListNode { // 虚拟头结点 dummy := \u0026amp;ListNode{-1, nil} p := dummy p1 := l1 p2 := l2 for p1 != nil \u0026amp;\u0026amp; p2 != nil { // 比较 p1 和 p2 两个指针 // 将值较小的的节点接到 p 指针 if p1.Val \u0026gt; p2.Val { p.Next = p2 p2 = p2.Next } else { p.Next = p1 p1 = p1.Next } // p 指针不断前进 p = p.Next } if p1 != nil { p.Next = p1 } if p2 != nil { p.Next = p2 } return dummy.Next } 合并 k 个有序链表 LeetCode \u0026ndash; \u0026gt; 因此，我们需要一个数据结构，它支持：\n从数据结构中找到并移除最小节点。 插入节点。 这可以用最小堆实现。\n初始把所有链表的头节点入堆，然后不断弹出堆中最小节点 x，如果 x.next 不为空就加入堆中。\n循环直到堆为空。把弹出的节点按顺序拼接起来，就得到了答案。\ntype ListNode struct { Val int Next *ListNode } func mergeKLists(lists []*ListNode) *ListNode { if len(lists) == 0 { return nil } // 虚拟头结点 dummy := \u0026amp;ListNode{-1, nil} p := dummy // 优先级队列，最小堆 pq := make(PriorityQueue, 0) heap.Init(\u0026amp;pq) // 将 k 个链表的头结点加入最小堆 for _, head := range lists { if head != nil { heap.Push(\u0026amp;pq, head) } } for pq.Len() \u0026gt; 0 { // 获取最小节点，接到结果链表中 node := heap.Pop(\u0026amp;pq).(*ListNode) p.Next = node if node.Next != nil { heap.Push(\u0026amp;pq, node.Next) } // p 指针不断前进 p = p.Next } return dummy.Next } // Go 语言中可以通过实现 heap.Interface 来构建 // 实现 heap.Interface 需要同时实现 sort.Interface type PriorityQueue []*ListNode func (pq PriorityQueue) Len() int { return len(pq) } func (pq PriorityQueue) Less(i, j int) bool { return pq[i].Val \u0026lt; pq[j].Val } func (pq PriorityQueue) Swap(i, j int) { pq[i], pq[j] = pq[j], pq[i] } func (pq *PriorityQueue) Push(x interface{}) { node := x.(*ListNode) *pq = append(*pq, node) } func (pq *PriorityQueue) Pop() interface{} { old := *pq n := len(old) node := old[n-1] *pq = old[0 : n-1] return node } 倒数第 k 个 LeetCode \u0026ndash;\u0026gt; // 返回链表的倒数第 k 个节点 func findFromEnd(head *ListNode, k int) *ListNode { p1 := head // p1 先走 k 步 for i := 0; i \u0026lt; k; i++ { p1 = p1.Next } p2 := head // p1 和 p2 同时走 n - k 步 for p1 != nil { p1 = p1.Next p2 = p2.Next } // p2 现在指向第 n - k + 1 个节点，即倒数第 k 个节点 return p2 } 两个链表是否相交 跳转至 LeetCode func getIntersectionNode(headA *ListNode, headB *ListNode) *ListNode { // p1 指向 A 链表头结点，p2 指向 B 链表头结点 p1, p2 := headA, headB for p1 != p2 { // p1 走一步，如果走到 A 链表末尾，转到 B 链表 if p1 == nil { p1 = headB } else { p1 = p1.Next } // p2 走一步，如果走到 B 链表末尾，转到 A 链表 if p2 == nil { p2 = headA } else { p2 = p2.Next } } return p1 } ","permalink":"https://Bin-lin-rgb.github.io/posts/leetcode/%E5%8F%8C%E6%8C%87%E9%92%88%E9%93%BE%E8%A1%A8/","summary":"合并两个有序链表 LeetCode 这道题也是大二数据结构的课本题目，使用虚拟头结点方便操作； func mergeTwoLists(l1 *ListNode, l2 *ListNode) *ListNode { // 虚拟头结点 dummy := \u0026amp;ListNode{-1, nil} p := dummy p1 := l1 p2 := l2 for p1 != nil \u0026amp;\u0026amp; p2 != nil { // 比较 p1 和 p2 两个指针 // 将值较小的的节点接到 p 指针 if p1.Val \u0026gt; p2.Val { p.Next = p2 p2 = p2.Next } else { p.Next = p1 p1 = p1.Next } // p 指针不断前进 p = p.Next } if p1 != nil { p.Next = p1 } if","title":"双指针（链表）"},{"content":"前言 今天发现后端使用雪花算法生成的 PostId 传给前端之后，居然不一致！\n导致文章详情页带参数查询为空！\n为啥会这样呢？\n什么是雪花算法？ 雪花算法，Twitter 的分布式自增 ID 算法\nsnowflake 优缺点：\n优点：\n（1）经测试 snowflake 每秒能生成 26 万个自增可排序的 ID。 （2）snowflake 生成的 ID 结果是一个 64bit 大小的整数，转换成字符串后长度最多 19。[注意这里的 19 位数，后面会用] （3）分布式系统内不会产生 ID 碰撞（datacenter 和 workerId 作区分）并且效率高。 缺点：依赖机器时钟，如果机器时钟回拨，会导致 id 重复。由于是部署到分布式环境，每台机器上的时钟不可能完全同步，有时候出现不是全局递增的情况。\nGolang 如何实现？ 这里使用的是 sonyflake 库，基本实现和 snowflake 差不多，不过是配位不太一样，影响不大。\n地址在这里：https://github.com/sony/sonyflake\n具体使用代码：\npackage snowflake import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/sony/sonyflake\u0026#34; ) var ( sonyFlake *sonyflake.Sonyflake\t// 实例 sonyMachineID uint16\t// 机器ID ) func getMachineID() (uint16, error) { // 返回全局定义的机器ID return sonyMachineID, nil } // 需传入当前的机器ID func Init(machineId uint16) (err error) { sonyMachineID = machineId t, _ := time.Parse(\u0026#34;2006-01-02\u0026#34;, \u0026#34;2020-01-01\u0026#34;)\t// 初始化一个开始的时间 settings := sonyflake.Settings{\t// 生成全局配置 StartTime: t, MachineID: getMachineID,\t// 指定机器ID } sonyFlake = sonyflake.NewSonyflake(settings)\t// 用配置生成sonyflake节点 return } // GetID 返回生成的id值 func GetID() (id uint64, err error) {\t// 拿到sonyflake节点生成id值 if sonyFlake == nil { err = fmt.Errorf(\u0026#34;snoy flake not inited\u0026#34;) return } id, err = sonyFlake.NextID() return } func main() { if err := Init(1);err!=nil{ fmt.Printf(\u0026#34;Init failed,err:%v\\n\u0026#34;,err) return } id, _ := GetID() fmt.Println(id) } 如何解决返回前端的 id 不一致？ 看一下哪里不一样：\n139677942874636289 ==\u0026gt; 139677942874636290\n好家伙怎么就差一位数！我当时以为是精度的问题，上网一查发现 Number 精度是 16 位（雪花 ID 是 19 位的），所以是 JS 的 Number 数据类型导致的精度丢失。\n解决方案：后端的 ID(uint64) ==\u0026gt; uint64 转 String ==\u0026gt; 前端使用 String 类型的 ID，这样精度就不会丢失了。那前端再把 String 类型的 19 位数字传回服务端的时候，再转 uint64 。\n总结 提前发现 bug 也是一种好事，哈哈。\n解决方案：前端用 String 类型的 ID，后端及数据库继续使用 uint64 类型不影响数据库查询执行效率。\n","permalink":"https://Bin-lin-rgb.github.io/posts/go/%E9%9B%AA%E8%8A%B1id%E7%94%9F%E6%88%90%E5%89%8D%E5%90%8E%E7%AB%AF%E4%BC%A0%E8%BE%93%E4%B8%8D%E4%B8%80%E8%87%B4/","summary":"前言 今天发现后端使用雪花算法生成的 PostId 传给前端之后，居然不一致！ 导致文章详情页带参数查询为空！ 为啥会这样呢？ 什么是雪花算法？ 雪花算法，Twitter 的分布式自增 ID 算法 snowflake 优缺点： 优点： （1）经测试 snowflake 每秒能生成 26 万个自增可排序的 ID。 （2）snowflake 生成的 ID 结果是一个 64bit 大小的整","title":"雪花id生成，前后端传输不一致"},{"content":"","permalink":"https://Bin-lin-rgb.github.io/posts/basics/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%AF%87/","summary":"","title":"计算机网络之基础篇"},{"content":"数组/字符串 [27. 移除元素] (https://leetcode.cn/problems/remove-element/)\n简单\n给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\n不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。\n元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。\n示例 1：\n输入：nums = [3,2,2,3], val = 3 输出：2, nums = [2,2] 解释：函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 2 ，而 nums = [2,2,3,3] 或 nums = [2,2,0,0]，也会被视作正确答案。 示例 2： 输入：nums = [0,1,2,2,3,0,4,2], val = 2 输出：5, nums = [0,1,4,0,3] 解释：函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。 func removeElement(nums []int, val int) int { left, right := 0, len(nums) for left \u0026lt; right { if nums[left] == val { nums[left] = nums[right-1] right-- } else { left++ } } return left } [26. 删除有序数组中的重复项] (https://leetcode.cn/problems/remove-duplicates-from-sorted-array/)\n给你一个 非严格递增排列 的数组 nums ，请你** 原地** 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。然后返回 nums 中唯一元素的个数。\n考虑 nums 的唯一元素的数量为 k ，你需要做以下事情确保你的题解可以被通过：\n更改数组 nums ，使 nums 的前 k 个元素包含唯一元素，并按照它们最初在 nums 中出现的顺序排列。nums 的其余元素与 nums 的大小不重要。 返回 k 。 示例 1：\n输入：nums = [1,1,2] 输出：2, nums = [1,2,_] 解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。 示例 2：\n输入：nums = [0,0,1,1,1,2,2,3,3,4] 输出：5, nums = [0,1,2,3,4] 解释：函数应该返回新的长度 5 ， 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4 。不需要考虑数组中超出新长度后面的元素。 func removeDuplicates(nums []int) int { n := len(nums) if n \u0026lt; 2 { return n } slow, fast := 0, 0 for i:=0; i\u0026lt;n; i++ { if nums[fast] != nums[slow] { // 遇到不一致的先让慢指针前移后赋值 slow++ nums[slow] = nums[fast] } fast++ } return slow+1 } [88. 合并两个有序数组] (https://leetcode.cn/problems/merge-sorted-array/)\n给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。\n请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。\n**注意：**最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。\n示例 1：\n输入：nums1 = [1,2,3,0,0,0], m = 3, nums2 = [2,5,6], n = 3 输出：[1,2,2,3,5,6] 解释：需要合并 [1,2,3] 和 [2,5,6] 。 合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。 示例 2：\n输入：nums1 = [1], m = 1, nums2 = [], n = 0 输出：[1] 解释：需要合并 [1] 和 [] 。 合并结果是 [1] 。 示例 3：\n输入：nums1 = [0], m = 0, nums2 = [1], n = 1 输出：[1] 解释：需要合并的数组是 [] 和 [1] 。 合并结果是 [1] 。 注意，因为 m = 0 ，所以 nums1 中没有元素。nums1 中仅存的 0 仅仅是为了确保合并结果可以顺利存放到 nums1 中。 func merge(nums1 []int, m int, nums2 []int, n int) { for p1, p2, tail := m-1, n-1, m+n-1; p1 \u0026gt;= 0 || p2 \u0026gt;= 0; tail-- { var cur int if p1 == -1 { cur = nums2[p2] p2-- } else if p2 == -1 { cur = nums1[p1] p1-- } else if nums1[p1] \u0026gt; nums2[p2] { cur = nums1[p1] p1-- } else { cur = nums2[p2] p2-- } nums1[tail] = cur } } [125. 验证回文串] (https://leetcode.cn/problems/valid-palindrome/)\n如果在将所有大写字符转换为小写字符、并移除所有非字母数字字符之后，短语正着读和反着读都一样。则可以认为该短语是一个 回文串 。\n字母和数字都属于字母数字字符。\n给你一个字符串 s，如果它是 回文串 ，返回 true ；否则，返回 false 。\n示例 1：\n输入: s = \u0026#34;A man, a plan, a canal: Panama\u0026#34; 输出：true 解释：\u0026#34;amanaplanacanalpanama\u0026#34; 是回文串。 示例 2：\n输入：s = \u0026#34;race a car\u0026#34; 输出：false 解释：\u0026#34;raceacar\u0026#34; 不是回文串。 func isPalindrome(s string) bool { var sgood string for i := 0; i \u0026lt; len(s); i++ { if isalnum(s[i]) { sgood += string(s[i]) } } n := len(sgood) sgood = strings.ToLower(sgood) for i := 0; i \u0026lt; n/2; i++ { if sgood[i] != sgood[n-1-i] { return false } } return true } func isalnum(ch byte) bool { return (ch \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; ch \u0026lt;= \u0026#39;Z\u0026#39;) || (ch \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; ch \u0026lt;= \u0026#39;z\u0026#39;) || (ch \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; ch \u0026lt;= \u0026#39;9\u0026#39;) } 双指针 [392. 判断子序列] (https://leetcode.cn/problems/is-subsequence/)\n给定字符串 s 和 t ，判断 s 是否为 t 的子序列。\n字符串的一个子序列是原始字符串删除一些（也可以不删除）字符而不改变剩余字符相对位置形成的新字符串。（例如，\u0026quot;ace\u0026quot;是\u0026quot;abcde\u0026quot;的一个子序列，而\u0026quot;aec\u0026quot;不是）。\n示例 1：\n输入：s = \u0026#34;abc\u0026#34;, t = \u0026#34;ahbgdc\u0026#34; 输出：true 示例 2：\n输入：s = \u0026#34;axc\u0026#34;, t = \u0026#34;ahbgdc\u0026#34; 输出：false func isSubsequence(s string, t string) bool { n, m := len(s), len(t) i, j := 0, 0 for i \u0026lt; n \u0026amp;\u0026amp; j \u0026lt; m { if s[i] == t[j] { i++ } j++ } return i == n } 区间 [56. 合并区间] (https://leetcode.cn/problems/merge-intervals/)\n以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。\n示例 1：\n输入：intervals = [[1,3],[2,6],[8,10],[15,18]] 输出：[[1,6],[8,10],[15,18]] 解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 示例 2：\n输入：intervals = [[1,4],[4,5]] 输出：[[1,5]] 解释：区间 [1,4] 和 [4,5] 可被视为重叠区间。 func merge(intervals [][]int) (ans [][]int) { // 先根据每个区间的起始值进行排序 sort.Slice(intervals, func(i, j int) bool { return intervals[i][0] \u0026lt; intervals[j][0] }) // 初始化答案切片，并将第一个区间加入 ans = append(ans, intervals[0]) // 遍历每个区间，合并重叠的区间 for _, e := range intervals[1:] { if ans[len(ans)-1][1] \u0026lt; e[0] { // 如果当前区间的起始值大于答案切片中最后一个区间的结束值，说明它们不重叠 // 直接将当前区间加入答案切片 ans = append(ans, e) } else { // 如果当前区间和答案切片中最后一个区间重叠 // 更新答案切片中最后一个区间的结束值，取两者中的较大值 ans[len(ans)-1][1] = max(ans[len(ans)-1][1], e[1]) } } return } func max(a, b int) int { if a \u0026gt; b { return a } return b } 排序 快速排序 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; ) func main() { nums := []int{1, 2, 4, 2, 5, 6, 9, 90, 3} fmt.Println(nums) fmt.Println(sortArray(nums)) } func sortArray(nums []int) []int { quick(nums, 0, len(nums)-1) return nums } func quick(arr []int, i, j int) { if i \u0026gt;= j { return } mid := partition(arr, i, j) quick(arr, i, mid-1) quick(arr, mid+1, j) } func partition(nums []int, i int, j int) int { p := rand.Intn(j-i+1) + i // 随机选取“支点” nums[i], nums[p] = nums[p], nums[i] for i \u0026lt; j { for nums[i] \u0026lt; nums[j] \u0026amp;\u0026amp; i \u0026lt; j { j-- } if i \u0026lt; j { nums[i], nums[j] = nums[j], nums[i] i++ } for nums[i] \u0026lt; nums[j] \u0026amp;\u0026amp; i \u0026lt; j { i++ } if i \u0026lt; j { nums[i], nums[j] = nums[j], nums[i] j-- } } return i } ","permalink":"https://Bin-lin-rgb.github.io/posts/leetcode/top150/","summary":"数组/字符串 [27. 移除元素] (https://leetcode.cn/problems/remove-element/) 简单 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。 不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。 元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 示例 1： 输入：nums = [3,2,2,3], val = 3","title":"Top150"},{"content":"Docker 为什么使用Docker\n企业环境中存在的某个痛点 企业使用一项技术是为了解决当前企业环境中存在的某个痛点。\n目前整个软件行业存在着以下几个痛点。\n1.软件更新发布及部署低效，过程烦琐且需要人工介入。\n2.环境一致性难以保证。\n3.不同环境之间迁移成本太高。\nDocker能解决的问题 首先，Docker的使用十分简单，\n从开发的角度来看就是“三步走\u0026quot;：构建、运输、运行。\n其中，关键步骤是构建环节，即打包镜像文件。\n但是从测试和运维的角度来看，那就只有两步：复制、运行。\n有了这个镜像文件，想复制到哪里运行都可以，完全和平台无关。\nDocker这种容器技术隔离出了独立的运行空间，不会和其他应用争用系统资源，不需要考虑应用之间的相互影响。\n其次，因为在构建镜像时就处理完了服务程序对于系统的所有依赖，所以在使用时，可以忽略原本程序的依赖以及开发语言。对测试和运维人员而言，可以更专注于自己的业务内容。\n最后，Docker为开发者提供了一种开发环境的管理办法，帮助测试人员保证环境的同步，为运维人员提供了可移植的标准化部署流程。\n类 \u0026ndash;\u0026gt; 对象\n镜像 \u0026ndash;\u0026gt; 容器\n安装 centos uname -r yum update yum makecache fast yum install docker-ce docker version systemctl status docker systemctl start docker // 测试 docker pull hello-world docker run hello-world Ubuntu curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 常用命令 https://www.bilibili.com/video/BV1gr4y1U7CY?p=18\u0026amp;spm_id_from=pageDriver\u0026amp;vd_source=6168fe2db91f9a8c4c41d41f39d1703e\n启动docker:\tsystemctl start docker 停止docker:\tsystemctl stop docker 重启docker:\tsystemctl restart docker 查看docker状态:\tsystemctl status docker 开机启动:\tsystemctl enable docker 查看docker概要信息:\tdocker info 查看docker 总体帮助文档:\tdocker-help 查看docker 命令帮助文档:\tdocker具体命令-help docker 中央仓库 存放镜像的网站\n官网：https://hub.docker.com/\ndaocloud：http://hub.daocloud.io/\ndocker 镜像操作 拉取到本地 docker pull daocloud.io/library/tomcat:8.0.45 查看本地所有镜像 docker images 删除 // 查看正在运行的 docker ps -a docker rm a66\u0026lt;id前几位\u0026gt; docker rmi 镜像标识\u0026lt;id前几位\u0026gt; 镜像导出导入 docker save -o 路径 镜像id\u0026lt;前两位即可\u0026gt; docker load -i 镜像文件 修改镜像名称 docker tag 镜像id 新镜像名称:版本 docker tag fa tomcat:8.0 docker 容器操作 1、运行容器 基本操作\ndocker run 镜像的标识镜像名称[:tag] 常用的参数\ndocker run -d -p 宿主机端口:容器端口 --name 容器名称 镜像的标识镜像名称[:tag] docker run -d -p 8080:8080 --name tomcat fa 跑起来后直接访问即可 -d: 代表后台运行容器 -p 宿主机端口：容器端口：为了映射当前Liux的端口和容器的端口 \u0026ndash;name 容器名称：指定容器的名称 2、查看正在运行的容器 docker ps [-qa] -a：查看全部的容器，包括没有运行 -q：只查看容器得到标识 3、查看容器的日志 docker logs -f 容器id [root@localhost linbin]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS b01afd80c224 fa \u0026#34;catalina.sh run\u0026#34; 5 minutes ago Up 5 minutes [root@localhost linbin]# docker logs -f b0 08-Sep-2022 00:49:48.918 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.0.45 08-Sep-2022 00:49:48.921 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Jun 26 2017 20:06:07 UTC 8.0.45.0 08-Sep-2022 00:49:48.921 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux 4、进入到容器内部 docker exec -it 容器id bash [root@localhost linbin]# docker exec -it b0 bash root@b01afd80c224:/usr/local/tomcat# pwd /usr/local/tomcat root@b01afd80c224:/usr/local/tomcat# ls LICENSE NOTICE RELEASE-NOTES\tRUNNING.txt bin conf\tinclude lib logs native-jni-lib temp webapps work root@b01afd80c224:/usr/local/tomcat# cd webapps root@b01afd80c224:/usr/local/tomcat/webapps# ls ROOT docs examples host-manager manager root@b01afd80c224:/usr/local/tomcat/webapps# exit exit 5、删除容器 (删除容器前，需要先停止容器)\n#停止指定的容器 docker stop 容器id #停止全部容器 docker stop $(docker ps -qa) #删除指定容器 docker rm 容器id #删除全部容器 docker rm $(docker ps -qa) #启动容器 docker start 容器id 创建 mysql 容器 创建MySQL镜像\ndocker pull daocloud.io/library/mysq1:5.7.5-m15 查看MySQL镜像\ndocker images 创建MySQL容器\ndocker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root --name msyql 镜像tag eg： docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=Admin666 --name mysql 644 然后使用连接工具 Navicat 测试。\n坑1\u0026ndash;中文字符 查看里面的字符集，好家伙，Latin1\nmysql\u0026gt; SHOW VARIABLES LIKE \u0026#39;character%\u0026#39;; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | latin1 | | character_set_connection | latin1 | | character_set_database | utf8 | | character_set_filesystem | binary | | character_set_results | latin1 | | character_set_server | latin1 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.00 sec) 关键点2\u0026ndash;开启数据卷 删除容器后，里面的mysql数据如何办 容器实例一删除，啥数据也没了！\n解决办法 1、新增数据卷\ndocker run -d -p 3306:3306 --privileged=true -v /zzyyuse/mysql/log:/var/log/mysql -v /zzyyuse/mysql/data:/var/lib/mysql -v /zzyyuse/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:5.7 2、/zzyyuse/mysql/conf 下新增 my.cnf\n[client] default_character_set=utf8 [mysqld] collation_server = utf8_general_ci character_set_server = utf8 然后restart一下\n之前的DB 无效\n修改字符集操作+重启mysql容器实例\n之后的DB 有效，需要新建\n结论：docker安装完MySQL并run出容器后，建议请先修改完字符集编码后再新建mysql库-表-插数据\n将项目部署到Tomcat 上传项目 上传项目\n进入容器目录 docker exec -it 容器tag bash\n将项目拷贝到tomcat:容器的webapps目录下面 docker cp demo a17:/usr/local/tomcat/webapps\n查看tomcat运行日志 docker logs -f 容器tag\ndocker 数据卷 为了部署我们的demo工程，需要使用到 cp 的命令将宿主机内的 demo文件复制到容器内部\n数据卷：将宿主机的一个目录，映射到容器的一个目录中，可以在宿主机中操作目录中的内容，那么容器内部映射的文件，也会跟着一起改变。\n在挂载目录后多加一个参数 --privileged=true\n1.创建数据卷 docker volume create 数据卷名称 #创建数据卷之后，默认会存放在一个目录下/var/Tb/docker/volumes./数据卷名称/_data 2.查看数据卷的详细信息 docker volume inspect 数据卷名称 3.查看全部数据卷 docker volume ls 4.删除数据卷 docker volume rm 数据卷名称 5.应用数据卷 当你映射数据卷时，如果数据卷不存在。Docker会帮你自动创建，会将容器内部自带的文件，存储在默认的存放路径中。\ndocker run -v 数据卷名称:容器内部的路径镜像id #直接指定一个路径作为数据卷的存放位置。这个路径下是空的。 docker run -V 宿主机路径:容器内部的路径 镜像id docker run -d -p 8080:8080 -v /home/tomcat_webapps:/usr/local/tomcat/webapps/ --name tomcat fa6 测试 docker run -d --privileged=true -v /tmp/host_data/:/tmp/docker_data/ --name u1 ubuntu [root@iZwz982ksp86xdjeeirtsdZ tmp]# cd /tmp/host_data/ [root@iZwz982ksp86xdjeeirtsdZ host_data]# touch test.txt [root@iZwz982ksp86xdjeeirtsdZ host_data]# ls test.txt [root@iZwz982ksp86xdjeeirtsdZ host_data]# docker exec -it afb bash root@afb5e67ee3d4:/# cd /tmp/docker_data/ root@afb5e67ee3d4:/tmp/docker_data# ls test.txt root@afb5e67ee3d4:/tmp/docker_data# 查看是否挂载成功\n[root@iZwz982ksp86xdjeeirtsdZ host_data]# docker inspect af \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;bind\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/tmp/host_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/tmp/docker_data\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;rprivate\u0026#34; } ], 如果 docker stop 了，然后在宿主机绑定的目录新增了一个文件，然后在 start 一下，发现会同步过来。\n是共享的意思。\n只读 上面默认rw\ndocker run -it -privileged=true -v /宿主机绝对路径目录:/容器内目录:ro 镜像名 /容器目录:ro 镜像名 就能完成功能，此时容器自己只能读取不能写\nro = read only\n此时如果宿主机写入内容，可以同步给容器内，容器可以读取到。\n继承 容器1完成和宿主机的映射 容器2继承容器1的卷规则 一\ndocker run -it --privileged=true --volumes-from 父亲 --name u2 ubuntu Dockerfile 什么是Dockerfile? DockerFile详解\nDockerfile是一个包含用于组合映像的命令的文本文档。可以使用在命令行中调用的任何命令。\nDocker通过读取Dockerfile中的指令自动生成映像。\ndocker build 命令用于从 Dockerfile 构建映像。\n可以在docker buiId命令中使用-f标志指向文件系统中任何位置的Dockerfile。\n例：\ndocker build -f /path/to/a/Dockerfile Dockerfile的基本结构 Dockerfile一般分为四部分：\n1.基础镜像信息\n2.维护者信息\n3.镜像操作指令\n4.容器启动时执行指令\nDockerfile文件说明 Docker以从上到下的顺序运行 Dockerfile 的指令。为了指定基本映像，第一条指令必须是FROM。一个声明以#字符开头则被视为注释。可以在Docker文件中使用RUN,CMD,FROM,EXPOSE,ENV等指令。\n在这里列出了一些堂用的指令.\n指令 FROM 指定基础镜像，必须为第一个命令\n格式： FROM \u0026lt;image\u0026gt; FROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; FROM \u0026lt;image\u0026gt;@\u0026lt;digest\u0026gt; 示例： FROM mysq1:5.6 注：tag或digest是可选的，如果不使用这两个值时，会使用jlatest版本的基础镜像\nMAINTAINER 维护者信息\n格式： MAINTAINER \u0026lt;name\u0026gt; 示例： MAINTAINER Jasper Xu MAINTAINER sorex@163.com MAINTAINER Jasper Xu \u0026lt;sorex@163.com\u0026gt; RUN 构建镜像时执行的命令\nRUN用于在镜像容器中执行命令，其有以下两种命令执行方式： shell执行 格式： RUN \u0026lt;command\u0026gt; exec执行 格式： RUN [\u0026#34;executable\u0026#34;,\u0026#34;paraml\u0026#34;,\u0026#34;param2\u0026#34;] 示例： RUN [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] RUN apk update RUN [\u0026#34;/etc/execfile\u0026#34;,\u0026#34;arg1\u0026#34;,\u0026#34;arg1\u0026#34;] 注：RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定\u0026ndash;no-cache参数，如：docker build \u0026ndash;no-cache\nADD ADD 指令和 COPY 的使用格类似（同样需求下，官方推荐使用 COPY）。功能也类似，不同之处如下：\nADD 的优点：在执行 \u0026lt;源文件\u0026gt; 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会自动复制并解压到 \u0026lt;目标路径\u0026gt;。 ADD 的缺点：在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。 格式： ADD \u0026lt;src\u0026gt;...\u0026lt;dest\u0026gt; ADD[\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,...\u0026#34;\u0026lt;dest\u0026gt;\u0026#34; 用于支持包含空格的路径 示例： ADD hom* /mydir/\t#添加所有以\u0026#34;hom\u0026#34;开头的文件 ADD hom?.txt /mydir/\t#?替代一个单字符，例如：\u0026#34;home.txt\u0026#34; ADD test relativeDir/\t#添加\u0026#34;test\u0026#34;到`WORKDIR`/relativeDir/ ADD test /absoluteDir/\t#添加\u0026#34;test\u0026#34;到/absoluteDir/ CMD 类似于 RUN 指令，用于运行程序，但二者运行的时间点不同:\nCMD 在docker run 时运行。 RUN 是在 docker build。 作用：为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。\n注意：如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。\n格式：\nCMD \u0026lt;shell 命令\u0026gt; CMD [\u0026#34;\u0026lt;可执行文件或命令\u0026gt;\u0026#34;,\u0026#34;\u0026lt;param1\u0026gt;\u0026#34;,\u0026#34;\u0026lt;param2\u0026gt;\u0026#34;,...] CMD [\u0026#34;\u0026lt;param1\u0026gt;\u0026#34;,\u0026#34;\u0026lt;param2\u0026gt;\u0026#34;,...] # 该写法是为 ENTRYPOINT 指令指定的程序提供默认参数 推荐使用第二种格式，执行过程比较明确。第一种格式实际上在运行的过程中也会自动转换成第二种格式运行，并且默认可执行文件是 sh。\nCOPY 复制指令，从上下文目录中复制文件或者目录到容器里指定路径。\n格式：\nCOPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] \u0026lt;源路径1\u0026gt;... \u0026lt;目标路径\u0026gt; COPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] [\u0026#34;\u0026lt;源路径1\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;目标路径\u0026gt;\u0026#34;] [\u0026ndash;chown=:]：可选参数，用户改变复制到容器内文件的拥有者和属组。\n\u0026lt;源路径\u0026gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如：\nCOPY hom* /mydir/ COPY hom?.txt /mydir/ \u0026lt;目标路径\u0026gt;：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。\nFROM centos # 添加文件到目录下 COPY test.txt /mydir/ # 将文件内容写入 mytest COPY test.txt /mytest # 压缩文件,自动解压 COPY jmeter.log.zip /myzipdir/ # 添加目录 COPY TeamFile / # 其他文件 COPY jmeter.log /mydir/ # 多个文件 COPY test1.txt test2.txt /mydir/ # 通配符,dest 不存在自动创建 COPY test*.txt /mydir/test/ # 特殊字符串 COPY COPY[[]0].txt /mydir/ WORKDIR /data # 相对路径 COPY test.txt test/ VOLUME 定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷。\n作用：\n避免重要的数据，因容器重启而丢失，这是非常致命的。 避免容器不断变大。 格式：\nVOLUME [\u0026#34;\u0026lt;路径1\u0026gt;\u0026#34;, \u0026#34;\u0026lt;路径2\u0026gt;\u0026#34;...] VOLUME \u0026lt;路径\u0026gt; 尚 docker 自定义镜像 自定义镜像\ndocker-compose 需求\n之前运行一个镜像，需要添加大量的参数。\n可以通过Docker-Compose编写这些参数。\nDocker-Compose可以帮助我们批量的管理容器。\n只需要通过一个docker-compose.yml文件去维护即可。\n下载安装\n1.去github官网搜索docker-compose,下载Docker-Compose\ndocker-compose-Linux-x86_64\n2.将下载好的文件，拖拽到Liux操作系统中\n3.需要将DockerCompose文件的名称修改一下，基于DockerCompose文件一个可执行的权限\n[root@localhost compose]# mv docker-compose-linux-x86_64 docker-compose [root@localhost compose]# mv docker-compose /usr/local/bin //放到路径中 [root@localhost compose]# cd /usr/local/bin [root@localhost bin]# ls docker-compose [root@localhost bin]# chmod 777 docker-compose //可执行权限 [root@localhost bin]# ls -al total 3000 drwxr-xr-x. 2 root root 28 Sep 7 23:23 . drwxr-xr-x. 12 root root 131 Aug 14 01:15 .. -rwxrwxrwx. 1 linbin linbin 3072000 Sep 7 23:19 docker-compose [root@localhost bin]# 4.方便后期操作，配置一个环境变量，让在其他目录也可以执行\nvi /etc/profile yml 文件 Jenkins gitlab Jenkins sh docker stop jenkins \u0026gt; /dev/null 2\u0026gt; /dev/null || : docker container rm jenkins \u0026gt; /dev/null 2\u0026gt; /dev/null || : docker run \\ --name jenkins \\ -d \\ -p 8080:8080 \\ -p 50000:50000 \\ -v jenkins_home:/var/jenkins_home:z \\ --env=\u0026#34;JENKINS_OPTS=--prefix=/jenkins\u0026#34; \\ -v deploy:/var/deploy:z \\ --network bridge \\ jenkins:1.0 gitlab sh docker pull gitlab/gitlab-ce:15.4.0-ce.0\ndocker stop gitlab \u0026gt; /dev/null 2\u0026gt; /dev/null || : docker container rm gitlab \u0026gt; /dev/null 2\u0026gt; /dev/null || : docker run -d \\ --name gitlab \\ --hostname my-gitlab \\ --publish 19080:80 --publish 19022:22 \\ --restart always \\ --volume /gitLabs/config:/etc/gitlab:Z \\ --volume /gitLabs/logs:/var/log/gitlab:Z \\ --volume /gitLabs/data:/var/opt/gitlab:Z \\ gitlab/gitlab-ce:15.4.0-ce.0 https://www.cnblogs.com/diaomina/p/12830449.html\n修改 hostname\nvi /opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml Windows 编译后部署 [juejin] server windows 编译\n// 注意 --\u0026gt; 使用 cmd 而不是 powershell SET GOOS=linux SET GOARCH=amd64 go build ./main.go 将编译形成的二进制文件\ndockerfile\nFROM alpine:latest RUN mkdir \u0026#34;/app\u0026#34; RUN mkdir \u0026#34;/app/config\u0026#34; WORKDIR \u0026#34;/app\u0026#34; COPY main /app/ COPY config.ini /app/config/ ENTRYPOINT [\u0026#34;./main\u0026#34;] 在 Linux 下的 docker 打包构建镜像\nsudo docker image build --platform linux/amd64 -t juejin_blog:v2.2 . docker image ls sudo docker run -it -p 9000:9000 juejin_blog:v2.2 nginx docker pull nginx ;新建目录结构：nginx文件夹下新建conf.d文件夹，html文件夹 /docker |---juejin |----nginx |----conf.d |----html default.conf\nserver { listen 80; server_name 49.109.50.48; location / { root /usr/share/nginx/html; try_files $uri $uri/ /index.html; index index.html index.htm; } location /api/ { proxy_pass http://49.109.50.48:9000; proxy_redirect default; rewrite ^/api/(.*) /$1 break; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } run.sh\nsudo docker run -d -p 80:80 \\ --name nginx_v1.3 \\ -v /docker/juejin/nginx/conf.d:/etc/nginx/conf.d \\ -v /docker/juejin/nginx/html/dist:/usr/share/nginx/html \\ nginx:latest 先用 builder 构建再 run [sms] go dockerfile FROM golang:alpine as builder ENV GOPROXY=https://goproxy.cn,direct WORKDIR /home COPY . . RUN go mod tidy RUN go build -o sms main.go FROM alpine as runner ENV WORKDIR=/home WORKDIR $WORKDIR RUN apk add tzdata --no-cache \\ \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ \u0026amp;\u0026amp; echo \u0026#34;Asia/Shanghai\u0026#34; \u0026gt; /etc/timezone \\ \u0026amp;\u0026amp; apk del tzdata COPY --from=builder $WORKDIR/sms $WORKDIR CMD [\u0026#34;./sms\u0026#34;] nginx dockerfile └─frontend ├─conf.d └─html └─dist └─assets nginx.conf\nserver { listen 80; server_name 43.139.40.48; location / { root /usr/share/nginx/html; try_files $uri $uri/ /index.html; index index.html index.htm; } location /api/ { proxy_pass http://43.139.40.48:8082; proxy_redirect default; rewrite ^/api/(.*) /$1 break; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } # 使用 Nginx 作为基础镜像 FROM nginx:alpine # 将构建好的前端应用静态文件复制到 Nginx 的 HTML 目录 COPY ./html /usr/share/nginx/html COPY ./conf.d /etc/nginx/conf.d # 暴露端口，如果需要的话 EXPOSE 80 # Nginx 会自动启动，无需手动启动 Nginx 服务 docker-compose version: \u0026#39;3\u0026#39; services: backend: build: context: ./sms-backend dockerfile: ./Dockerfile image: smsbackend container_name: \u0026#34;smsbackend_container\u0026#34; ports: - \u0026#34;8082:8080\u0026#34; environment: - PG_USER=postgres - PG_PASSWORD=admin666 - PG_DBNAME=sms - PG_SSLMODE=disable - PG_HOST=43.139.40.48 - PG_PORT=5432 nginx: build: context: ./sms-frontend dockerfile: ./Dockerfile image: nginx:sms container_name: \u0026#34;smsnginx_container\u0026#34; ports: - \u0026#34;17000:80\u0026#34; - \u0026#34;443:443\u0026#34; volumes: - /sms-frontend/conf.d:/etc/nginx/conf.d - /sms-frontend/html:/usr/share/nginx/html restart: always other WSL2 Ubuntu22.04 安装 Docker ，发现 daemon 启动失败 root@LAPTOP-O0KBCH8Q:~# service docker start * Starting Docker: docker [ OK ] root@LAPTOP-O0KBCH8Q:~# docker version Client: Docker Engine - Community Version: 20.10.18 API version: 1.41 Go version: go1.18.6 Git commit: b40c2f6 Built: Thu Sep 8 23:11:43 2022 OS/Arch: linux/amd64 Context: default Experimental: true Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? root@LAPTOP-O0KBCH8Q:~# sudo systemctl enable docker Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install. Executing: /lib/systemd/systemd-sysv-install enable docker root@LAPTOP-O0KBCH8Q:~# /lib/systemd/systemd-sysv-install enable docker root@LAPTOP-O0KBCH8Q:~# dockerd \u0026amp; failed to start daemon: Error initializing network controller: error obtaining controller instance: unable to add return rule in DOCKER-ISOLATION-STAGE-1 chain: (iptables failed: iptables --wait -A DOCKER-ISOLATION-STAGE-1 -j RETURN: iptables v1.8.7 (nf_tables): RULE_APPEND failed (No such file or directory): rule in chain DOCKER-ISOLATION-STAGE-1 (exit status 4)) [1]+ Exit 1 dockerd root@LAPTOP-O0KBCH8Q:~# iptables -L -t nat # Warning: iptables-legacy tables present, use iptables-legacy to see them Chain PREROUTING (policy ACCEPT) target prot opt source destination Chain INPUT (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination Chain POSTROUTING (policy ACCEPT) target prot opt source destination Chain DOCKER (0 references) target prot opt source destination root@LAPTOP-O0KBCH8Q:~# sudo update-alternatives --config iptables There are 2 choices for the alternative iptables (providing /usr/sbin/iptables). Selection Path Priority Status ------------------------------------------------------------ * 0 /usr/sbin/iptables-nft 20 auto mode 1 /usr/sbin/iptables-legacy 10 manual mode 2 /usr/sbin/iptables-nft 20 manual mode Press \u0026lt;enter\u0026gt; to keep the current choice[*], or type selection number: 1 update-alternatives: using /usr/sbin/iptables-legacy to provide /usr/sbin/iptables (iptables) in manual mode root@LAPTOP-O0KBCH8Q:~# service docker start * Starting Docker: docker [ OK ] root@LAPTOP-O0KBCH8Q:~# service docker status * Docker is running root@LAPTOP-O0KBCH8Q:~# docker pull hello-world Using default tag: latest latest: Pulling from library/hello-world 2db29710123e: Pull complete Digest: sha256:62af9efd515a25f84961b70f973a798d2eca956b1b2b026d0a4a63a3b0b6a3f2 Status: Downloaded newer image for hello-world:latest docker.io/library/hello-world:latest root@LAPTOP-O0KBCH8Q:~# docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ docker: Error response from daemon: network qnear not found. 改成 bridge 。\n","permalink":"https://Bin-lin-rgb.github.io/posts/deploy/docker/","summary":"Docker 为什么使用Docker 企业环境中存在的某个痛点 企业使用一项技术是为了解决当前企业环境中存在的某个痛点。 目前整个软件行业存在着以下几个痛点。 1.软件更新发布及部署低效，过程烦琐且需要人工介入。 2.环境一致性难以保证。 3.不同环境之间迁移成本太高。 Docker能解决的问题 首先，Do","title":"Docker 基础"},{"content":"1. 介绍 scan命令的作用和keys *的作用类似，主要用于查找redis中的键，但是在正式的生产环境中一般不会直接使用keys *这个命令，因为他会返回所有的键，如果键的数量很多会导致查询时间很长，进而导致服务器阻塞，所以需要scan来进行更细致的查找\nscan总共有这几种命令：scan、sscan、hscan、zscan，分别用于迭代数据库中的：数据库中所有键、集合键、哈希键、有序集合键，命令具体结构如下：\nscan cursor [MATCH pattern] [COUNT count] [TYPE type] sscan key cursor [MATCH pattern] [COUNT count] hscan key cursor [MATCH pattern] [COUNT count] zscan key cursor [MATCH pattern] [COUNT count] 2. scan scan cursor [MATCH pattern] [COUNT count] [TYPE type]，cursor表示游标，指查询开始的位置，count默认为10，查询完后会返回下一个开始的游标，当返回0的时候表示所有键查询完了\n127.0.0.1:6379[2]\u0026gt; scan 0 1) \u0026#34;3\u0026#34; 2) 1) \u0026#34;mystring\u0026#34; 2) \u0026#34;myzadd\u0026#34; 3) \u0026#34;myhset\u0026#34; 4) \u0026#34;mylist\u0026#34; 5) \u0026#34;myset2\u0026#34; 6) \u0026#34;myset1\u0026#34; 7) \u0026#34;mystring1\u0026#34; 8) \u0026#34;mystring3\u0026#34; 9) \u0026#34;mystring4\u0026#34; 10) \u0026#34;myset\u0026#34; 127.0.0.1:6379[2]\u0026gt; scan 3 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;myzadd1\u0026#34; 2) \u0026#34;mystring2\u0026#34; 3) \u0026#34;mylist2\u0026#34; 4) \u0026#34;myhset1\u0026#34; 5) \u0026#34;mylist1\u0026#34; MATCH可以采用模糊匹配找出自己想要查找的键，这里的逻辑是先查出20个，再匹配，而不是先匹配再查询，这里加上count 20是因为默认查出的10个数中可能不能包含所有的相关项，所以把范围扩大到查20个，我这里测试的键总共有15个\n127.0.0.1:6379[2]\u0026gt; scan 0 match mylist* count 20 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;mylist\u0026#34; 2) \u0026#34;mylist2\u0026#34; 3) \u0026#34;mylist1\u0026#34; TYPE可以根据具体的结构类型来匹配该类型的键\n127.0.0.1:6379[2]\u0026gt; scan 0 count 20 type list 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;mylist\u0026#34; 2) \u0026#34;mylist2\u0026#34; 3) \u0026#34;mylist1\u0026#34; 3. sscan sscan key cursor [MATCH pattern] [COUNT count]，sscan的第一个参数总是集合类型的key\n127.0.0.1:6379[2]\u0026gt; sadd myset1 a b c d (integer) 4 127.0.0.1:6379[2]\u0026gt; smembers myset1 1) \u0026#34;d\u0026#34; 2) \u0026#34;a\u0026#34; 3) \u0026#34;c\u0026#34; 4) \u0026#34;b\u0026#34; 127.0.0.1:6379[2]\u0026gt; sscan myset1 0 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;d\u0026#34; 2) \u0026#34;c\u0026#34; 3) \u0026#34;b\u0026#34; 4) \u0026#34;a\u0026#34; 127.0.0.1:6379[2]\u0026gt; sscan myset1 0 match a 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;a\u0026#34; 4. hscan hscan key cursor [MATCH pattern] [COUNT count]，sscan的第一个参数总是哈希类型的key\n127.0.0.1:6379[2]\u0026gt; hset myhset1 kk1 vv1 kk2 vv2 kk3 vv3 (integer) 3 127.0.0.1:6379[2]\u0026gt; hgetall myhset1 1) \u0026#34;kk1\u0026#34; 2) \u0026#34;vv1\u0026#34; 3) \u0026#34;kk2\u0026#34; 4) \u0026#34;vv2\u0026#34; 5) \u0026#34;kk3\u0026#34; 6) \u0026#34;vv3\u0026#34; 127.0.0.1:6379[2]\u0026gt; hscan myhset1 0 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;kk1\u0026#34; 2) \u0026#34;vv1\u0026#34; 3) \u0026#34;kk2\u0026#34; 4) \u0026#34;vv2\u0026#34; 5) \u0026#34;kk3\u0026#34; 6) \u0026#34;vv3\u0026#34; 5. zscan zscan key cursor [MATCH pattern] [COUNT count]，sscan的第一个参数总是有序集合类型的key\n127.0.0.1:6379[2]\u0026gt; zadd myzadd1 1 zz1 2 zz2 3 zz3 (integer) 3 127.0.0.1:6379[2]\u0026gt; zrange myzadd1 0 -1 withscores 1) \u0026#34;zz1\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;zz2\u0026#34; 4) \u0026#34;2\u0026#34; 5) \u0026#34;zz3\u0026#34; 6) \u0026#34;3\u0026#34; 127.0.0.1:6379[2]\u0026gt; zscan myzadd1 0 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;zz1\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;zz2\u0026#34; 4) \u0026#34;2\u0026#34; 5) \u0026#34;zz3\u0026#34; 6) \u0026#34;3\u0026#34; ","permalink":"https://Bin-lin-rgb.github.io/posts/tech/tech/","summary":"1. 介绍 scan命令的作用和keys *的作用类似，主要用于查找redis中的键，但是在正式的生产环境中一般不会直接使用keys *这个命令，因为他会返回所有的键，如果键的数量很多会导致查询时间很长，进而导致服务器阻塞，所以需要scan来进行更细致的查找 scan总共有这几种命令：sca","title":"Redis scan命令学习"},{"content":"前言 zap 的使用。\n安装 运行下面的命令安装zap\ngo get -u go.uber.org/zap 实现 logger.go 文件 先在 logger 下新建一个文件\n具体内容如下：\npackage Logger import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;go.uber.org/zap/zapcore\u0026#34; \u0026#34;gopkg.in/natefinch/lumberjack.v2\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httputil\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime/debug\u0026#34; \u0026#34;server/Config\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) var lg *zap.Logger // InitLogger 初始化Logger func InitLogger(cfg *Config.LogConfig) (err error) { writeSyncer := getLogWriter(cfg.Filename, cfg.MaxSize, cfg.MaxBackups, cfg.MaxAge) encoder := getEncoder() var l = new(zapcore.Level) err = l.UnmarshalText([]byte(cfg.Level)) if err != nil { return } core := zapcore.NewCore(encoder, writeSyncer, l) lg = zap.New(core, zap.AddCaller()) zap.ReplaceGlobals(lg) // 替换zap包中全局的logger实例，后续在其他包中只需使用zap.L()调用即可 return } func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.TimeKey = \u0026#34;time\u0026#34; encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder encoderConfig.EncodeDuration = zapcore.SecondsDurationEncoder encoderConfig.EncodeCaller = zapcore.ShortCallerEncoder return zapcore.NewJSONEncoder(encoderConfig) } func getLogWriter(filename string, maxSize, maxBackup, maxAge int) zapcore.WriteSyncer { lumberJackLogger := \u0026amp;lumberjack.Logger{ Filename: filename, MaxSize: maxSize, MaxBackups: maxBackup, MaxAge: maxAge, } return zapcore.AddSync(lumberJackLogger) } // GinLogger 接收gin框架默认的日志 func GinLogger() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() path := c.Request.URL.Path query := c.Request.URL.RawQuery c.Next() cost := time.Since(start) lg.Info(path, zap.Int(\u0026#34;status\u0026#34;, c.Writer.Status()), zap.String(\u0026#34;method\u0026#34;, c.Request.Method), zap.String(\u0026#34;path\u0026#34;, path), zap.String(\u0026#34;query\u0026#34;, query), zap.String(\u0026#34;ip\u0026#34;, c.ClientIP()), zap.String(\u0026#34;user-agent\u0026#34;, c.Request.UserAgent()), zap.String(\u0026#34;errors\u0026#34;, c.Errors.ByType(gin.ErrorTypePrivate).String()), zap.Duration(\u0026#34;cost\u0026#34;, cost), ) } } // GinRecovery recover掉项目可能出现的panic，并使用zap记录相关日志 func GinRecovery(stack bool) gin.HandlerFunc { return func(c *gin.Context) { defer func() { if err := recover(); err != nil { // Check for a broken connection, as it is not really a // condition that warrants a panic stack trace. var brokenPipe bool if ne, ok := err.(*net.OpError); ok { if se, ok := ne.Err.(*os.SyscallError); ok { if strings.Contains(strings.ToLower(se.Error()), \u0026#34;broken pipe\u0026#34;) || strings.Contains(strings.ToLower(se.Error()), \u0026#34;connection reset by peer\u0026#34;) { brokenPipe = true } } } httpRequest, _ := httputil.DumpRequest(c.Request, false) if brokenPipe { lg.Error(c.Request.URL.Path, zap.Any(\u0026#34;error\u0026#34;, err), zap.String(\u0026#34;request\u0026#34;, string(httpRequest)), ) // If the connection is dead, we can\u0026#39;t write a status to it. c.Error(err.(error)) // nolint: errcheck c.Abort() return } if stack { lg.Error(\u0026#34;[Recovery from panic]\u0026#34;, zap.Any(\u0026#34;error\u0026#34;, err), zap.String(\u0026#34;request\u0026#34;, string(httpRequest)), zap.String(\u0026#34;stack\u0026#34;, string(debug.Stack())), ) } else { lg.Error(\u0026#34;[Recovery from panic]\u0026#34;, zap.Any(\u0026#34;error\u0026#34;, err), zap.String(\u0026#34;request\u0026#34;, string(httpRequest)), ) } c.AbortWithStatus(http.StatusInternalServerError) } }() c.Next() } } 配置 新建一个 config.go 用来， 定义日志相关的配置， 具体内容如下：\npackage Config import ( \u0026#34;encoding/json\u0026#34; \u0026#34;io/ioutil\u0026#34; ) // Config 整个项目的配置 type Config struct { Mode string `json:\u0026#34;mode\u0026#34;` Port int `json:\u0026#34;port\u0026#34;` *LogConfig `json:\u0026#34;log\u0026#34;` } // LogConfig 日志配置 type LogConfig struct { Level string `json:\u0026#34;level\u0026#34;` Filename string `json:\u0026#34;filename\u0026#34;` MaxSize int `json:\u0026#34;maxsize\u0026#34;` MaxAge int `json:\u0026#34;max_age\u0026#34;` MaxBackups int `json:\u0026#34;max_backups\u0026#34;` } // Conf 全局配置变量 var Conf = new(Config) // Init 初始化配置；从指定文件加载配置文件 func Init(filePath string) error { b, err := ioutil.ReadFile(filePath) if err != nil { return err } return json.Unmarshal(b, Conf) } config.json\n{ \u0026#34;mode\u0026#34;: \u0026#34;debug\u0026#34;, \u0026#34;port\u0026#34;: 8080, \u0026#34;log\u0026#34;: { \u0026#34;level\u0026#34;: \u0026#34;debug\u0026#34;, \u0026#34;filename\u0026#34;: \u0026#34;app.log\u0026#34;, \u0026#34;maxsize\u0026#34;: 200, \u0026#34;max_age\u0026#34;: 7, \u0026#34;max_backups\u0026#34;: 10 } } 可以看到 在 config.json 中 的 filename 为 app.log ，是log 输出文件。\nmain.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;server/Config\u0026#34; \u0026#34;server/Logger\u0026#34; \u0026#34;server/Router\u0026#34; \u0026#34;server/pkg/snowflake\u0026#34; ) func main() { r := gin.Default() // load config from config.json if len(os.Args) \u0026lt; 1 { return } if err := Config.Init(os.Args[1]); err != nil { panic(err) } // init logger if err := Logger.InitLogger(Config.Conf.LogConfig); err != nil { fmt.Printf(\u0026#34;init logger failed, err:%v\\n\u0026#34;, err) return } gin.SetMode(Config.Conf.Mode) Router.Start(r) // 注册zap相关中间件 r.Use(Logger.GinLogger(), Logger.GinRecovery(true)) err := r.Run() if err != nil { log.Println(\u0026#34;r.Run() Failed!\u0026#34;) } } 在项目中先从配置文件加载配置信息，再调用logger.InitLogger(config.Conf.LogConfig)即可完成logger实例的初识化。其中，通过r.Use(logger.GinLogger(), logger.GinRecovery(true))注册我们的中间件来使用zap接收gin框架自身的日志，在项目中需要的地方通过使用zap.L().Xxx()方法来记录自定义日志信息。\n使用 比如这里：\n使用到了 zap.Error() .\n查看官方文档，还有其他的形式。 文档：https://pkg.go.dev/go.uber.org/zap\n常用的：\n[Debug] func (log *Logger) Debug(msg string, fields ...Field) Debug logs a message at DebugLevel. The message includes any fields passed at the log site, as well as any fields accumulated on the logger.\n[Error] func (log *Logger) Error(msg string, fields ...Field) Error logs a message at ErrorLevel. The message includes any fields passed at the log site, as well as any fields accumulated on the logger.\n[Fatal] func (log *Logger) Fatal(msg string, fields ...Field) Fatal logs a message at FatalLevel. The message includes any fields passed at the log site, as well as any fields accumulated on the logger.\nThe logger then calls os.Exit(1), even if logging at FatalLevel is disabled.\n[Info] func (log *Logger) Info(msg string, fields ...Field) Info logs a message at InfoLevel. The message includes any fields passed at the log site, as well as any fields accumulated on the logger.\n总结 日志是用来记录，用户操作，系统状态，错误信息等等内容的文件，是一个软件系统的重要组成部分。一个良好的日志规范，对于系统运行状态的分析，以及线上问题的解决具有重大的意义。\n重要功能日志尽可能的完善。 不要随意打印无用的日志，过多无用的日志会增加分析日志的难度。 日志要区分等级 如 debug，warn，info，error 等。 捕获到未处理错误时最好打印错误堆栈信息 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/zap%E6%97%A5%E5%BF%97%E5%BA%93/","summary":"前言 zap 的使用。 安装 运行下面的命令安装zap go get -u go.uber.org/zap 实现 logger.go 文件 先在 logger 下新建一个文件 具体内容如下： package Logger import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;go.uber.org/zap/zapcore\u0026#34; \u0026#34;gopkg.in/natefinch/lumberjack.v2\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httputil\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime/debug\u0026#34; \u0026#34;server/Config\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) var lg *zap.Logger // InitLogger 初始化Logger func InitLogger(cfg *Config.LogConfig) (err error) { writeSyncer := getLogWriter(cfg.Filename, cfg.MaxSize, cfg.MaxBackups, cfg.MaxAge) encoder := getEncoder() var l = new(zapcore.Level) err = l.UnmarshalText([]byte(cfg.Level)) if err != nil { return } core := zapcore.NewCore(encoder, writeSyncer, l) lg = zap.New(core, zap.AddCaller()) zap.ReplaceGlobals(lg) // 替换zap包中全局的logger实例，后续在","title":"Zap日志库"},{"content":"gorm基础使用及解决部分疑惑 这是我参与「第三届青训营 -后端场」笔记创作活动的第4篇笔记。\n01 简介 本文主要介绍在项目中集成 gorm 的大致方法、一些错误的解决方法、规范包及目录。\n02 规范包及目录 这只是其中的一种分包方式，具体使用哪种可以根据自己需求。\ncontroller //处理函数 ​ dao //数据库相关，gorm相关接口 ​ router //路由 ​ model //生成数据表相关的结构体 ​ assets //静态资源 ​ templates //模板文件、HTML 03 集成gorm 这里分两种情况：\n如果还未建表，可以先声明结构体数据之后再使用 gorm 自动建表功能。 若已经建好表了，则可以使用一些便捷的网站快速生成相应的结构体，然后再根据实际需求更改（比如外键）。 1.自动建表 1、go get 一下\n我这里使用 mysql 所以执行go get -u gorm.io/driver/mysql.\n如果你们使用其他数据库可以参考gorm官方文档：GORM 指南 | GORM - The fantastic ORM library for Golang, aims to be developer friendly.\ngo get -u gorm.io/gorm go get -u gorm.io/driver/mysql 2、声明结构体\n在这一个案例中是还没有建表的。这里后面的字段不需要指定数据库列。后边使用 db.AutoMigrate(\u0026amp;model.User{}) 就可以自动建表\nmodel.go package model ​ import \u0026#34;gorm.io/gorm\u0026#34; ​ type User struct { gorm.Model Username string `json:\u0026#34;username\u0026#34;` Password string `json:\u0026#34;password\u0026#34;` } 在dsn记得换上自己的 数据库密码 。\ndao.go package dao ​ import ( \u0026#34;blog/model\u0026#34; \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;log\u0026#34; ) ​ type Manager interface { AddUser(user *model.User) } ​ type manager struct { db *gorm.DB } ​ func (mgr manager) AddUser(user *model.User) { mgr.db.Create(user) } ​ var Mgr Manager ​ func init() { // 在dsn记得换上自己的 数据库密码 dsn := \u0026#34;root:xxxxxx@tcp(127.0.0.1:3306)/golang_blog?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { log.Fatal(\u0026#34;Failed to init db:\u0026#34;, err) } Mgr = \u0026amp;manager{db: db} err1 := db.AutoMigrate(\u0026amp;model.User{}) if err1 != nil { log.Fatal(err1) } } main.go package main ​ import ( \u0026#34;blog/dao\u0026#34; \u0026#34;blog/model\u0026#34; ) ​ func main() { user := model.User{ Username: \u0026#34;tom\u0026#34;, Password: \u0026#34;123456\u0026#34;, } dao.Mgr.AddUser(\u0026amp;user) } 测试 测试AddUser是否成功\nmysql\u0026gt; use golang_blog Database changed mysql\u0026gt; show tables; +-----------------------+ | Tables_in_golang_blog | +-----------------------+ | users | +-----------------------+ 1 row in set (0.00 sec) ​ mysql\u0026gt; select * from users; +----+-------------------------+-------------------------+------------+----------+----------+ | id | created_at | updated_at | deleted_at | username | password | +----+-------------------------+-------------------------+------------+----------+----------+ | 1 | 2022-05-22 09:13:22.688 | 2022-05-22 09:13:22.688 | NULL | tom | 123456 | +----+-------------------------+-------------------------+------------+----------+----------+ 1 row in set (0.00 sec) 2.手动建表 这种情况先把SQL建表语句复制到这个网站：在线sql转go, json转go - 球儿工具 (qetool.com)\n然后就可以愉快根据需要转成相应的结构体。\nSQL转struct 1、Navicat 直接粘贴过来的 t_video 表的SQL :\nCREATE TABLE `t_video` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;视频id\u0026#39;, `author_id` int(11) NOT NULL COMMENT \u0026#39;作者id\u0026#39;, `play_url` varchar(512) NOT NULL COMMENT \u0026#39;视频播放地址\u0026#39;, `cover_url` varchar(255) NOT NULL COMMENT \u0026#39;视频封面地址\u0026#39;, `favorite_count` int(11) unsigned DEFAULT NULL COMMENT \u0026#39;视频的点赞总数\u0026#39;, `comment_count` int(11) unsigned DEFAULT NULL COMMENT \u0026#39;视频的评论总数\u0026#39;, `title` varchar(255) CHARACTER SET utf8 NOT NULL COMMENT \u0026#39;视频标题\u0026#39;, `created_at` datetime DEFAULT NULL COMMENT \u0026#39;投稿时间\u0026#39;, `deleted_at` datetime DEFAULT NULL COMMENT \u0026#39;删除时间\u0026#39;, `updated_at` datetime DEFAULT NULL COMMENT \u0026#39;更新时间\u0026#39;, `is_favorite` tinyint(1) DEFAULT NULL, PRIMARY KEY (`id`), KEY `author_id` (`author_id`), KEY `normal_favorite_count` (`favorite_count`) USING BTREE, CONSTRAINT `author_id` FOREIGN KEY (`author_id`) REFERENCES `t_userinfo` (`id`) ) 2、然后在网站勾选 json 、gorm ，就出现了：\ntype Video struct { ID int64 `gorm:\u0026#34;column:id\u0026#34; json:\u0026#34;id\u0026#34;` // 视频id AuthorId int64 `gorm:\u0026#34;column:author_id\u0026#34; json:\u0026#34;author_id\u0026#34;` // 作者id PlayUrl string `gorm:\u0026#34;column:play_url\u0026#34; json:\u0026#34;play_url\u0026#34;` // 视频播放地址 CoverUrl string `gorm:\u0026#34;column:cover_url\u0026#34; json:\u0026#34;cover_url\u0026#34;` // 视频封面地址 FavoriteCount int64 `gorm:\u0026#34;column:favorite_count\u0026#34; json:\u0026#34;favorite_count\u0026#34;` // 视频的点赞总数 CommentCount int64 `gorm:\u0026#34;column:comment_count\u0026#34; json:\u0026#34;comment_count\u0026#34;` // 视频的评论总数 Title string `gorm:\u0026#34;column:title\u0026#34; json:\u0026#34;title\u0026#34;` // 视频标题 CreatedAt time.Time `gorm:\u0026#34;column:created_at\u0026#34; json:\u0026#34;created_at\u0026#34;` // 投稿时间 DeletedAt time.Time `gorm:\u0026#34;column:deleted_at\u0026#34; json:\u0026#34;deleted_at\u0026#34;` // 删除时间 UpdatedAt time.Time `gorm:\u0026#34;column:updated_at\u0026#34; json:\u0026#34;updated_at\u0026#34;` // 更新时间 IsFavorite int64 `gorm:\u0026#34;column:is_favorite\u0026#34; json:\u0026#34;is_favorite\u0026#34;` } 3、修改\n比如这里的需求是 t_video 表中需要携带作者 userinfo 的数据。\n这里新增 Author Userinfo 连接 Userinfo 结构体，并声明 gorm 字段为 \u0026quot;foreignKey:AuthorId;\u0026quot; 。 把UpdatedAt、DeletedAt、CreatedAt字段删掉，新增 gorm.Model ，因为它自带这些参数。 type Video struct { gorm.Model ID int64 `gorm:\u0026#34;column:id\u0026#34; json:\u0026#34;id\u0026#34;` // 视频id Author Userinfo `json:\u0026#34;author\u0026#34; gorm:\u0026#34;foreignKey:AuthorId;\u0026#34;` // -新增- AuthorId int64 `gorm:\u0026#34;column:author_id\u0026#34; json:\u0026#34;author_id\u0026#34;` // 作者id PlayUrl string `gorm:\u0026#34;column:play_url\u0026#34; json:\u0026#34;play_url\u0026#34;` // 视频播放地址 CoverUrl string `gorm:\u0026#34;column:cover_url\u0026#34; json:\u0026#34;cover_url\u0026#34;` // 视频封面地址 FavoriteCount int64 `gorm:\u0026#34;column:favorite_count\u0026#34; json:\u0026#34;favorite_count\u0026#34;` // 视频的点赞总数 CommentCount int64 `gorm:\u0026#34;column:comment_count\u0026#34; json:\u0026#34;comment_count\u0026#34;` // 视频的评论总数 Title string `gorm:\u0026#34;column:title\u0026#34; json:\u0026#34;title\u0026#34;` // 视频标题 // CreatedAt time.Time `gorm:\u0026#34;column:created_at\u0026#34; json:\u0026#34;created_at\u0026#34;` // 投稿时间 // DeletedAt time.Time `gorm:\u0026#34;column:deleted_at\u0026#34; json:\u0026#34;deleted_at\u0026#34;` // 删除时间 // UpdatedAt time.Time `gorm:\u0026#34;column:updated_at\u0026#34; json:\u0026#34;updated_at\u0026#34;` // 更新时间 IsFavorite int64 `gorm:\u0026#34;column:is_favorite\u0026#34; json:\u0026#34;is_favorite\u0026#34;` } ​ 注意的问题 1、比如使用 Navicat 建表的表名是 t_video ，但是想关联的结构体名是 Video ， 那 gorm 怎么知道关联想要的东西呢？\n这里需要在连接数据库时进行一些配置，这里只需要使用前两个：\ndsn := \u0026#34;root:xxxxxx@tcp(127.0.0.1:3306)/golang_blog?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(\u0026#34;gorm.db\u0026#34;), \u0026amp;gorm.Config{ NamingStrategy: schema.NamingStrategy{ TablePrefix: \u0026#34;t_\u0026#34;, // table name prefix, table for `User` would be `t_users` SingularTable: true, // use singular table name, table for `User` would be `user` with this option enabled //NoLowerCase: true, // skip the snake_casing of names //NameReplacer: strings.NewReplacer(\u0026#34;CID\u0026#34;, \u0026#34;Cid\u0026#34;), // use name replacer to change struct/field name before convert it to db name }, }) 2、若需要的字段可能有中文，为了避免报错，建表时设置该字段的字符集为utf8，排序规则为utf8_general_ci。\n3.Preload 预加载 在上述嵌套的情况下，此时直接查询返回一个 video 是没有 Userinfo 的信息的，需要使用 Preload 。\nGORM 允许在 Preload 的其它 SQL 中直接加载关系。\n比如：直接链式添加 .Preload(\u0026quot;Author\u0026quot;) ：\nfunc (mgr manager) GetAllVideo(latestTime int64) ([]model.Video, error) { var videos []model.Video timeLayout := \u0026#34;2006-01-02 15:04:05\u0026#34; result := mgr.db.Model(\u0026amp;model.Video{}).Where(\u0026#34;created_at \u0026lt;= ?\u0026#34;, time.Unix(latestTime, 0).Format(timeLayout)). Order(\u0026#34;created_at DESC\u0026#34;).Preload(\u0026#34;Author\u0026#34;).Limit(30).Count(\u0026amp;count).Find(\u0026amp;videos) ​ return videos, result.Error } 04 总结 gorm使用下来是比较方便的orm工具，建议读者如果出问题了多看看官方文档。\n参考资料：\ngorm官方文档：GORM 指南 | GORM - The fantastic ORM library for Golang, aims to be developer friendly.\n","permalink":"https://Bin-lin-rgb.github.io/posts/go/golang%E9%9B%86%E6%88%90gorm/","summary":"gorm基础使用及解决部分疑惑 这是我参与「第三届青训营 -后端场」笔记创作活动的第4篇笔记。 01 简介 本文主要介绍在项目中集成 gorm 的大致方法、一些错误的解决方法、规范包及目录。 02 规范包及目录 这只是其中的一种分包方式，具体使用哪种可以根据自己需求。 controller //处理函数 ​ dao //数据库相关，gorm","title":"Golang集成gorm"},{"content":"运行准备 由于需要使用 FFmpeg 第三方工具来完成视频截取第一帧作为封面并存储到本机，\n所以运行之前需要预先安装 FFmpeg 到本机并配置好环境变量。\n我这里使用的是 ffmpeg version 5.0.1-full_build 版本。\n参考链接：FFmpeg\n项目结构 假设有这样一个案例：assets 文件夹中是专门存放视频的，现在的要求就是将该视频的第一帧截取为图片并保存。\nD:. │ go.mod │ go.sum │ ├─.idea │ .gitignore │ modules.xml │ testvideo.iml │ thriftCompiler.xml │ workspace.xml │ ├─assets │ test.mp4 │ └─controller main.go 主要是调用 GetSnapshot() 函数\n第一个参数是 视频的相对地址，第二个参数是截出来的图片的名称，返回值是图片的相对路径\nfunc GetSnapshot(videoPath, snapshotPath string) (snapshotName string, err error)\nmain.go package main ​ import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/disintegration/imaging\u0026#34; ffmpeg \u0026#34;github.com/u2takey/ffmpeg-go\u0026#34; ) ​ func GetSnapshot(videoPath, snapshotPath string, frameNum int) (snapshotName string, err error) { snapshotPath = \u0026#34;./assets/\u0026#34; + snapshotPath buf := bytes.NewBuffer(nil) err = ffmpeg.Input(videoPath). Filter(\u0026#34;select\u0026#34;, ffmpeg.Args{fmt.Sprintf(\u0026#34;gte(n,%d)\u0026#34;, frameNum)}). Output(\u0026#34;pipe:\u0026#34;, ffmpeg.KwArgs{\u0026#34;vframes\u0026#34;: 1, \u0026#34;format\u0026#34;: \u0026#34;image2\u0026#34;, \u0026#34;vcodec\u0026#34;: \u0026#34;mjpeg\u0026#34;}). WithOutput(buf, os.Stdout). Run() if err != nil { log.Fatal(\u0026#34;生成缩略图失败：\u0026#34;, err) return \u0026#34;\u0026#34;, err } ​ img, err := imaging.Decode(buf) if err != nil { log.Fatal(\u0026#34;生成缩略图失败：\u0026#34;, err) return \u0026#34;\u0026#34;, err } ​ err = imaging.Save(img, snapshotPath+\u0026#34;.png\u0026#34;) if err != nil { log.Fatal(\u0026#34;生成缩略图失败：\u0026#34;, err) return \u0026#34;\u0026#34;, err } ​ fmt.Println(\u0026#34;--snapshotPath--\u0026#34;, snapshotPath) // --snapshotPath-- ./assets/testImage ​ names := strings.Split(snapshotPath, \u0026#34;\\\u0026#34;) fmt.Println(\u0026#34;----names----\u0026#34;, names) // ----names---- [./assets/testImage] // 这里把 snapshotPath 的 string 类型转换成 []string ​ snapshotName = names[len(names)-1] + \u0026#34;.png\u0026#34; fmt.Println(\u0026#34;----snapshotName----\u0026#34;, snapshotName) // ----snapshotName---- ./assets/testImage.png ​ return snapshotName, nil } ​ func main() { name, err := GetSnapshot(\u0026#34;./assets/test.mp4\u0026#34;, \u0026#34;testImage\u0026#34;, 1) if err != nil { log.Fatal(err) return } fmt.Println(\u0026#34;return:\u0026#34;, name) } ​ 完成之后发现项目的 assets 已经多了一个 testImage.png 文件，说明已经成功了！\nD:. │ go.mod │ go.sum │ ├─.idea │ .gitignore │ modules.xml │ testvideo.iml │ thriftCompiler.xml │ workspace.xml │ ├─assets │ test.mp4 │ testImage.png │ └─controller main.go 解决方法 若生成失败，可能存在的问题：\n1、安装 FFmpeg 之后，没有配置环境变量。可以使用 cmd 输入 ffmpeg -version 验证是否配置成功。\n2、可以尝试以管理员身份运行 goland\n","permalink":"https://Bin-lin-rgb.github.io/posts/go/%E4%BD%BF%E7%94%A8ffmpeg/","summary":"运行准备 由于需要使用 FFmpeg 第三方工具来完成视频截取第一帧作为封面并存储到本机， 所以运行之前需要预先安装 FFmpeg 到本机并配置好环境变量。 我这里使用的是 ffmpeg version 5.0.1-full_build 版本。 参考链接：FFmpeg 项目结构 假设有这样一个案例：assets 文件夹中是专门存放视频的，现在的要求就是将该视频的第一帧截取为图片并","title":"使用 FFmpeg 截取视频第一帧并保存案例"},{"content":"omitempty 关键字 用法 熟悉 Golang 的朋友对于 json 和 struct 之间的转换一定不陌生，为了将代码中的结构体与 json 数据解耦，通常我们会在结构体的 field 类型后加上解释说明，例如在表示一个地址的时候， json 数据如下所示\n{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; } 与之相对应的 Golang 结构体表示定义如下\ntype address struct { Street string `json:\u0026#34;street\u0026#34;` // 街道 Ste string `json:\u0026#34;suite\u0026#34;` // 单元（可以不存在） City string `json:\u0026#34;city\u0026#34;` // 城市 State string `json:\u0026#34;state\u0026#34;` // 州/省 Zipcode string `json:\u0026#34;zipcode\u0026#34;` // 邮编 } 这样无论代码中的变量如何改变，我们都能成功将 json 数据解析出来，获得正确的街道，城市等信息，到目前为止一切正常。但如果我们想要将地址结构体恢复成 json 格式时，问题就来了。比方说我们用下面这段代码读取了地址 json ，然后根据业务逻辑处理了之后恢复成正常的 json 打印出来\nfunc main() { data := `{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; }` addr := new(address) json.Unmarshal([]byte(data), \u0026amp;addr) // 处理了一番 addr 变量... addressBytes, _ := json.MarshalIndent(addr, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;) fmt.Printf(\u0026#34;%s\\n\u0026#34;, string(addressBytes)) } 可以得到运行结果\n{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;suite\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; } 多了一行 \u0026quot;suite\u0026quot;: \u0026quot;\u0026quot;, ，而这则信息在原本的 json 数据中是没有的（在美国的地址中，如果不是群租公寓或者共享办公楼， suite 这一条不存在很正常，人们直接用街道门牌号来表示地址就足够了），但我们更希望的是，在一个地址有 suite 号码的时候输出，不存在 suite 的时候就不输出，幸运的是，我们可以在 Golang 的结构体定义中添加 omitempty 关键字，来表示这条信息如果没有提供，在序列化成 json 的时候就不要包含其默认值。稍作修改，地址结构体就变成了\ntype address struct { Street string `json:\u0026#34;street\u0026#34;` Ste string `json:\u0026#34;suite,omitempty\u0026#34;` City string `json:\u0026#34;city\u0026#34;` State string `json:\u0026#34;state\u0026#34;` Zipcode string `json:\u0026#34;zipcode\u0026#34;` } 重新运行，即可得到正确的结果。\n陷阱 带来方便的同时，使用 omitempty 也有些小陷阱，一个是该关键字无法忽略掉嵌套结构体。还是拿地址类型说事，这回我们想要往地址结构体中加一个新 field 来表示经纬度，如果缺乏相关的数据，暂时可以忽略。新的结构体定义如下所示\ntype address struct { Street string `json:\u0026#34;street\u0026#34;` Ste string `json:\u0026#34;suite,omitempty\u0026#34;` City string `json:\u0026#34;city\u0026#34;` State string `json:\u0026#34;state\u0026#34;` Zipcode string `json:\u0026#34;zipcode\u0026#34;` Coordinate coordinate `json:\u0026#34;coordinate,omitempty\u0026#34;` } type coordinate struct { Lat float64 `json:\u0026#34;latitude\u0026#34;` Lng float64 `json:\u0026#34;longitude\u0026#34;` } 读入原来的地址数据，处理后序列化输出，我们就会发现即使加上了 omitempty 关键字，输出的 json 还是带上了一个空的坐标信息\n{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34;, \u0026#34;coordinate\u0026#34;: { \u0026#34;latitude\u0026#34;: 0, \u0026#34;longitude\u0026#34;: 0 } } 为了达到我们想要的效果，可以把坐标定义为指针类型，这样 Golang 就能知道一个指针的“空值”是多少了，否则面对一个我们自定义的结构， Golang 是猜不出我们想要的空值的。于是有了如下的结构体定义\ntype address struct { Street string `json:\u0026#34;street\u0026#34;` Ste string `json:\u0026#34;suite,omitempty\u0026#34;` City string `json:\u0026#34;city\u0026#34;` State string `json:\u0026#34;state\u0026#34;` Zipcode string `json:\u0026#34;zipcode\u0026#34;` Coordinate *coordinate `json:\u0026#34;coordinate,omitempty\u0026#34;` } type coordinate struct { Lat float64 `json:\u0026#34;latitude\u0026#34;` Lng float64 `json:\u0026#34;longitude\u0026#34;` } 相应的输出为\n{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; } 另一个“陷阱”是，对于用 omitempty 定义的 field ，如果给它赋的值恰好等于默认空值的话，在转为 json 之后也不会输出这个 field 。比如说上面定义的经纬度坐标结构体，如果我们将经纬度两个 field 都加上 omitempty\ntype coordinate struct { Lat float64 `json:\u0026#34;latitude,omitempty\u0026#34;` Lng float64 `json:\u0026#34;longitude,omitempty\u0026#34;` } 然后我们对非洲几内亚湾的“原点坐标”非常感兴趣，于是编写了如下代码\nfunc main() { cData := `{ \u0026#34;latitude\u0026#34;: 0.0, \u0026#34;longitude\u0026#34;: 0.0 }` c := new(coordinate) json.Unmarshal([]byte(cData), \u0026amp;c) // 具体处理逻辑... coordinateBytes, _ := json.MarshalIndent(c, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;) fmt.Printf(\u0026#34;%s\\n\u0026#34;, string(coordinateBytes)) } 最终我们得到了一个\n{} 这个坐标消失不见了！但我们的设想是，如果一个地点没有经纬度信息，则悬空，这没有问题，但对于“原点坐标”，我们在确切知道它的经纬度的情况下，（0.0, 0.0）仍然被忽略了。正确的写法也是将结构体内的定义改为指针\ntype coordinate struct { Lat *float64 `json:\u0026#34;latitude,omitempty\u0026#34;` Lng *float64 `json:\u0026#34;longitude,omitempty\u0026#34;` } 这样空值就从 float64 的 0.0 变为了指针类型的 nil ，我们就能看到正确的经纬度输出。\n{ \u0026#34;latitude\u0026#34;: 0, \u0026#34;longitude\u0026#34;: 0 } ","permalink":"https://Bin-lin-rgb.github.io/posts/go/omitempty/","summary":"omitempty 关键字 用法 熟悉 Golang 的朋友对于 json 和 struct 之间的转换一定不陌生，为了将代码中的结构体与 json 数据解耦，通常我们会在结构体的 field 类型后加上解释说明，例如在表示一个地址的时候， json 数据如下所示 { \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; } 与之相对应的 Golang 结构体表示定义如下 type address struct { Street string `json:\u0026#34;street\u0026#34;` // 街道 Ste string `json:\u0026#34;suite\u0026#34;` // 单元（可以不存在） City string","title":"omitempty 关键字"},{"content":"","permalink":"https://Bin-lin-rgb.github.io/posts/life/life/","summary":"","title":"Life"},{"content":"\rBlaine\u0026#39;s Blog\r一个记录技术、阅读、生活的博客\r👉友链格式\r名称： Blaine\u0026rsquo;s Blog 网址： https://bin-lin-rgb.github.io/ 图标： https://bin-lin-rgb.github.io/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求\r秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内\n","permalink":"https://Bin-lin-rgb.github.io/links/","summary":"Blaine\u0026#39;s Blog 一个记录技术、阅读、生活的博客 👉友链格式 名称： Blaine\u0026rsquo;s Blog 网址： https://bin-lin-rgb.github.io/ 图标： https://bin-lin-rgb.github.io/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内","title":"🤝友链"},{"content":"关于我\n英文名: Blaine 职业: 程序员 运动: 跑步、乒乓球 ","permalink":"https://Bin-lin-rgb.github.io/about/","summary":"关于我 英文名: Blaine 职业: 程序员 运动: 跑步、乒乓球","title":"🙋🏻‍♂️关于"},{"content":"使用 hugo + GitHub Pages + twikoo 完成\n","permalink":"https://Bin-lin-rgb.github.io/posts/tech/blog/","summary":"使用 hugo + GitHub Pages + twikoo 完成","title":"Blog"}]