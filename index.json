[{"content":"Base\ngo 常用命令 build: 编译包和依赖 clean: 移除对象文件 doc: 显示包或者符号的文档 env: 打印go的环境信息 bug: 启动错误报告 fix: 运行go tool fix fmt: 运行gofmt进行格式化 generate: 从processing source生成go文件 get: 下载并安装包和依赖 install: 编译并安装包和依赖 list: 列出包 run: 编译并运行go程序 test: 运行测试 tool: 运行go提供的工具 version: 显示go的版本 vet: 运行go tool vet 标识符的组成 1.标识符由数字、字母和下划线 (_) 组成。\n2.只能以字母和下划线 (_) 开头。\n3.标识符区分大小写。\nGo是一门区分大小写的语言 命名规则涉及变量、常量、全局函数、结构、接口、方法等的命名。\nGO语言从语法层面进行了以下限定：\n任何需要对外暴露的名字必须以大写字母开头，\n不需要对外暴露的则应该以小写字母开头。\n短变量声明只能在函数里使用。\n包名称 保持packāge的名字和目录保持一致，尽量采取有意义的包名，简短，有意义，尽量和标准库不要冲突。==包名应该为小写单词==，不要使用下线或者混合大小写。\npackage dao package service 文件命名 尽量采取有意义的文件名，简短，有意义，==应该为小写单词==，使用下划线分隔各个单词。\ncustomer_dao.go 结构体命名 ==采用驼峰命名法==，首字母根据访问控制大写或者小写\nstruct申明和初始化格式采用多行，例如下面：\ntype Customerorder struct{ Name string Address string } order:=CustomerOrder{\u0026#34;tom\u0026#34;,\u0026#34;北京海淀\u0026#34;} 错误处理 错误处理的原则就是不能丢弃任何有返回 err 的调用，不要使用_丢弃，必须全部处理。\n接收到错误，\n要么返回 err, 或者使用 log 记录下来尽早return , 一旦有错误发生，马上返回 尽量不要使用 panic ,除非你知道你在做什么， 错误描述如果是英文必须为小写，不需要标点结尾，采用独立的错误流进行处理. //正确写法 if err != nil{ //错误处理 return } //正常代码 单元测试 单元测试文件名命名规范为example_test.go测试用例的函数名称必须以Test开头，例如：TestExample\n每个重要的函数都要首先编写测试用例，测试用例和正规代码一起提交方便进行回归测试。\n常量 定义常量的语法\n定义一个常量使用const关键字，语法格式如下：\nconst constantName [type]=value\nconst: 定义常量关键字 constantName: 常量名称 type: 常量类型 value: 常量的值 iota iota比较特殊，可以被认为是一个可被编译器修改的常量，它默认开始值是g,每调用一次加1。遇到const关键字时被重置为0。 实例\npackage Base import \u0026#34;fmt\u0026#34; func Iota() { const ( a1 = iota a2 = iota a3 = iota ) fmt.Printf(\u0026#34;a1:%v\\n\u0026#34;, a1) fmt.Printf(\u0026#34;a2:%v\\n\u0026#34;, a2) fmt.Printf(\u0026#34;a3:%v\\n\u0026#34;, a3) } ======== a1:0 a2:1 a3:2 跳过1 func Iota() { const ( a1 = iota _ a3 = iota ) fmt.Printf(\u0026#34;a1:%v\\n\u0026#34;, a1) fmt.Printf(\u0026#34;a3:%v\\n\u0026#34;, a3) } ====== a1:0 a3:2 跳过2 func Iota() { const ( a1 = iota a2 = 100 a3 = iota ) fmt.Printf(\u0026#34;a1:%v\\n\u0026#34;, a1) fmt.Printf(\u0026#34;a2:%v\\n\u0026#34;, a2) fmt.Printf(\u0026#34;a3:%v\\n\u0026#34;, a3) } ====== a1:0 a2:100 a3:2 数据类型 指针、数组、切片类型\nfunc DataType() { num := 200 p := \u0026amp;num fmt.Printf(\u0026#34;%T\\n\u0026#34;, p) //\t*int 指针 arr := [3]int{1, 2, 3} fmt.Printf(\u0026#34;%T\\n\u0026#34;, arr) //[3]int 数组 arr1 := []int{1, 2, 3} fmt.Printf(\u0026#34;%T\\n\u0026#34;, arr1) //[]int 切片 } bool 类型 bool 类型：不能使用 0 和 非0 表示真假\n//\tBool b := 0 if b { //失败！ fmt.Println(b) } 数字类型 go 语言支持整型和浮点型数字，并且原生支持复数，其中位的运算采用补码。\n有基于架构的类型，例如：int、uint和uintptr。 这些类型的长度都是根据运行程序所在的操作系统类型所决定的：\nint和uint在32位操作系统上，它们均使用32位(4个字节)，在64位操作系统上，它们均使用64位(8个字节)。\nuintptr的长度被设定为足够存放一个指针即可。\ngo语言中没有float类型。(Go语言中只有float32和float64)\n没有 double 类型。\n与操作系统架构无关的类型都有固定的大小，并在类型的名称中就可以看出来。\n挺多的就不一一测了。\n//\t数字类型 var i8 int8 fmt.Printf(\u0026#34;%T %db %v~%v\\n\u0026#34;, i8, unsafe.Sizeof(i8), math.MinInt8, math.MaxInt8) //int8 1b -128~127 var i int fmt.Printf(\u0026#34;%T %db %v~%v\\n\u0026#34;, i, unsafe.Sizeof(i), math.MinInt, math.MaxInt) //int 8b -9223372036854775808~9223372036854775807 字符串 反引号可换行\n字符串连接 加号 使用 fmt.Sprintf() 使用 strings.Join() 使用 buffer.WriteString() //\tString str1 := \u0026#34;Hello,\u0026#34; str2 := \u0026#34;Tom\u0026#34; sprintf := fmt.Sprintf(\u0026#34;%s%s\u0026#34;, str1, str2) fmt.Println(sprintf) //\tstrings.Join join := strings.Join([]string{\u0026#34;Hello\u0026#34;, \u0026#34;Amy\u0026#34;}, \u0026#34;,\u0026#34;) fmt.Println(join)\t//\tbuffer.WriteString var buffer bytes.Buffer buffer.WriteString(\u0026#34;Hello\u0026#34;) buffer.WriteString(\u0026#34;,\u0026#34;) buffer.WriteString(\u0026#34;DaMing\u0026#34;) fmt.Printf(\u0026#34;%v\\n\u0026#34;, buffer.String()) 1、golang里面的字符串都是不可变的，每次运算都会产生一个新的字符串，所以会产生很多临时的无用的字符串，不仅没有用，还会给带来额外的负担，所以性能比较差。\n2、内部使用[]byte实现，不像直接运算符这种会产生很多临时的字符串，但是内部的逻辑比较复杂，有很多额外的判断，还用到了interface，所以性能也不是很好\n3、join会先根据字符串数组的内容，计算出一个拼接之后的长度，然后申请对应大小的内存，一个一个字符串填入，在已有一个数组的情况下，这种效率会很高，但是本来没有，去构造这个数据的代价也不小。\n4、这个比较理想，可以当成可变字符使用，对内存的增长也有优化，如果能预估字符串的长度，还可以用buffer.Grow()接口来设置capacity\n字符串切片操作 // 字符切片 str3 := \u0026#34;Hello world!\u0026#34; m, n := 3, 6 println(str3[m]) println(str3[:m]) // [0,3) println(str3[m:n]) println(str3[:n]) 字符串函数 格式化输出 https://pkg.go.dev/fmt?utm_source=godoc\nhttps://www.cnblogs.com/yinzhengjie/p/7680829.html\n通用：\n1 %v 值的默认格式表示。当输出结构体时，扩展标志（%+v）会添加字段名 2 %#v 值的Go语法表示 3 %T 值的类型的Go语法表示 4 %% 百分号 //\t格式化输出 user := User{ Name: \u0026#34;David\u0026#34;, Age: 20, Gender: \u0026#34;male\u0026#34;, } fmt.Printf(\u0026#34;%v\\n\u0026#34;, user) // {David 20 male} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, user) // Base.User{Name:\u0026#34;David\u0026#34;, Age:20, Gender:\u0026#34;male\u0026#34;} 布尔值：\n%t 单词true或false 整数：\n1 %b 表示为二进制 2 %c 该值对应的unicode码值[char] 3 %d 表示为十进制 4 %o 表示为八进制 5 %q 该值对应的单引号括起来的go语法字符字面值，必要时会采用安全的转义表示 6 %x 表示为十六进制，使用a-f 7 %X 表示为十六进制，使用A-F 8 %U 表示为Unicode格式：U+1234，等价于\u0026#34;U+%04X\u0026#34; 浮点数、复数的两个组分：\n1 %b 无小数部分、二进制指数的科学计数法，如-123456p-78；参见strconv.FormatFloat %e 科学计数法，如-1234.456e+78 %E 科学计数法，如-1234.456E+78 %f 有小数部分但无指数部分，如123.456 %F 等价于%f %g 根据实际情况采用%e或%f格式（以获得更简洁、准确的输出） 2 %G 根据实际情况采用%E或%F格式（以获得更简洁、准确的输出） 字符串和[]byte：\n%s 直接输出字符串或者[]byte %q 该值对应的双引号括起来的go语法字符串字面值，必要时会采用安全的转义表示 %x 每个字节用两字符十六进制数表示（使用a-f） %X 每个字节用两字符十六进制数表示（使用A-F） 指针：\n%p 表示为十六进制，并加上前导的0x 没有verb %u。整数如果是无符号类型自然输出也是无符号的。类似的，也没有必要指定操作数的尺寸（int8，int64）。\n宽度通过一个紧跟在百分号后面的十进制数指定，如果未指定宽度，则表示值时除必需之外不作填充。精度通过（可能有的）宽度后跟点号后跟的十进制数指定。如果未指定精度，会使用默认精度；如果点号后没有跟数字，表示精度为0。举例如下：\n%f: 默认宽度，默认精度 %9f 宽度9，默认精度 %.2f 默认宽度，精度2 %9.2f 宽度9，精度2 %9.f 宽度9，精度0 宽度和精度格式化控制的是Unicode码值的数量（不同于C的printf，它的这两个因数指的是字节的数量）。两者任一个或两个都可以使用\u0026rsquo;\u0026lsquo;号取代，此时它们的值将被对应的参数（按\u0026rsquo;\u0026lsquo;号和verb出现的顺序，即控制其值的参数会出现在要表示的值前面）控制，这个操作数必须是int类型。\n对于大多数类型的值，宽度是输出的最小字符数，如果必要是会用空格填充。对于字符串，宽度是输出字符数目的最低数量，如果必要会截断字符串。\n对于整数，宽度和精度都设置输出总长度。采用精度时表示右对齐并用0填充，而宽度默认表示用空格填充。\n对于浮点数，宽度设置输出总长度；精度设置小数部分长度（如果有的话），除了%g/%G，此时精度设置总的数字个数。例如，对数字123.45，格式%6.2f 输出123.45；格式%.4g输出123.5。%e和%f的默认精度是6，%g的默认精度是可以将该值区分出来需要的最小数字个数。\n对复数，宽度和精度会分别用于实部和虚部，结果用小括号包裹。因此%f用于1.2+3.4i输出(1.200000+3.400000i)。\n其它flag：\n1 + 总是输出数值的正负号；对%q（%+q）会生成全部是ASCII字符的输出（通过转义）； 2 - 在输出右边填充空白而不是默认的左边（即从默认的右对齐切换为左对齐）； 3 # 切换格式： 4 八进制数前加0（%#o），十六进制数前加0x（%#x）或0X（%#X），指针去掉前面的0x（%#p）； 5 对%q（%#q），如果strconv.CanBackquote返回真会输出反引号括起来的未转义字符串； 6 对%U（%#U），如果字符是可打印的，会在输出Unicode格式、空格、单引号括起来的go字面值； 7 \u0026#39; \u0026#39; 对数值，正数前加空格而负数前加负号； 8 对字符串采用%x或%X时（% x或% X）会给各打印的字节之间加空格； 9 0 使用0而不是空格填充，对于数值类型会把填充的0放在正负号后面； verb会忽略不支持的flag。例如，因为没有十进制切换模式，所以%#d和%d的输出是相同的。\n对每一个类似Printf的函数，都有对应的Print型函数，该函数不接受格式字符串，就效果上等价于对每一个参数都是用verb %v。另一个变体Println型函数会在各个操作数的输出之间加空格并在最后换行。\n不管verb如何，如果操作数是一个接口值，那么会使用接口内部保管的值，而不是接口，因此：\n1 /* 2 #!/usr/bin/env gorun 3 @author :yinzhengjie 4 Blog:http://www.cnblogs.com/yinzhengjie/tag/GO%E8%AF%AD%E8%A8%80%E7%9A%84%E8%BF%9B%E9%98%B6%E4%B9%8B%E8%B7%AF/ 5 EMAIL:y1053419035@qq.com 6 */ 7 8 package main 9 10 import \u0026#34;fmt\u0026#34; 11 12 func main() { 13 var name interface{} = \u0026#34;yinzhengjie\u0026#34; 14 fmt.Printf(\u0026#34;My name is %v !\\n\u0026#34;, name) 15 var age interface{} = 18 16 fmt.Printf(\u0026#34;I am [%d] years old。\u0026#34;,age) 17 } 18 19 20 21 #以上代码执行结果如下： 22 My name is yinzhengjie ! 23 I am [18] years old。 除了verb %T和%p之外；对实现了特定接口的操作数会考虑采用特殊的格式化技巧。按应用优先级如下：\n\\1. 如果操作数实现了Formatter接口，会调用该接口的方法。Formatter提供了格式化的控制。\n\\2. 如果verb %v配合flag #使用（%#v），且操作数实现了GoStringer接口，会调用该接口。\n如果操作数满足如下两条任一条，对于%s、%q、%v、%x、%X五个verb，将考虑：\n\\3. 如果操作数实现了error接口，Error方法会用来生成字符串，随后将按给出的flag（如果有）和verb格式化。\n\\4. 如果操作数具有String方法，这个方法将被用来生成字符串，然后将按给出的flag（如果有）和verb格式化。\n复合类型的操作数，如切片和结构体，格式化动verb递归地应用于其每一个成员，而不是作为整体一个操作数使用。因此%q会将[]string的每一个成员括起来，%6.2f会控制浮点数组的每一个元素的格式化。\n为了避免可能出现的无穷递归，如：\n1 type X string 2 func (x X) String() string { return Sprintf(\u0026#34;\u0026lt;%s\u0026gt;\u0026#34;, x) } 应在递归之前转换值的类型：\n1 func (x X) String() string { return Sprintf(\u0026#34;\u0026lt;%s\u0026gt;\u0026#34;, string(x)) } 显式指定参数索引：\n在Printf、Sprintf、Fprintf三个函数中，默认的行为是对每一个格式化verb依次对应调用时成功传递进来的参数。但是，紧跟在verb之前的[n]符号表示应格式化第n个参数（索引从1开始）。同样的在\u0026rsquo;*\u0026lsquo;之前的[n]符号表示采用第n个参数的值作为宽度或精度。在处理完方括号表达式[n]后，除非另有指示，会接着处理参数n+1，n+2……（就是说移动了当前处理位置）。例如：\n1 fmt.Sprintf(\u0026#34;%[2]d %[1]d\\n\u0026#34;, 11, 22) 会生成\u0026quot;22 11\u0026quot;，而：\n1 fmt.Sprintf(\u0026#34;%[3]*.[2]*[1]f\u0026#34;, 12.0, 2, 6), 等价于：\n1 fmt.Sprintf(\u0026#34;%6.2f\u0026#34;, 12.0), 会生成\u0026quot; 12.00\u0026quot;。因为显式的索引会影响随后的verb，这种符号可以通过重设索引用于多次打印同一个值：\n1 fmt.Sprintf(\u0026#34;%d %d %#[1]x %#x\u0026#34;, 16, 17) 会生成\u0026quot;16 17 0x10 0x11\u0026quot;\n格式化错误：\n如果给某个verb提供了非法的参数，如给%d提供了一个字符串，生成的字符串会包含该问题的描述，如下所例：\n1 错误的类型或未知的verb：%!verb(type=value) 2 Printf(\u0026#34;%d\u0026#34;, hi): %!d(string=hi) 3 太多参数（采用索引时会失效）：%!(EXTRA type=value) 4 Printf(\u0026#34;hi\u0026#34;, \u0026#34;guys\u0026#34;): hi%!(EXTRA string=guys) 5 太少参数: %!verb(MISSING) 6 Printf(\u0026#34;hi%d\u0026#34;): hi %!d(MISSING) 7 宽度/精度不是整数值：%!(BADWIDTH) or %!(BADPREC) 9 Printf(\u0026#34;%.*s\u0026#34;, 4.5, \u0026#34;hi\u0026#34;): %!(BADPREC)hi 10 没有索引指向的参数：%!(BADINDEX) 11 Printf(\u0026#34;%*[2]d\u0026#34;, 7): %!d(BADINDEX) 12 Printf(\u0026#34;%.[2]d\u0026#34;, 7): %!d(BADINDEX) 所有的错误都以字符串\u0026quot;%!\u0026ldquo;开始，有时会后跟单个字符（verb标识符），并以加小括弧的描述结束。\n如果被print系列函数调用时，Error或String方法触发了panic，fmt包会根据panic重建错误信息，用一个字符串说明该panic经过了fmt包。例如，一个String方法调用了panic(\u0026ldquo;bad\u0026rdquo;)，生成的格式化信息差不多是这样的：\n%!s(PANIC=bad) %!s指示表示错误（panic）出现时的使用的verb。\n运算符 自增 \u0026amp; 自减 不用于 表达式中。\n//num2:=num++ + 5 num3:=num + 5 fmt.Println(num3) 流程控制 if switch case ==可以多个、可以是表达式==\ncase 里面不需要 break ，若想继续下去 加 fallthrough\nfunc Control() { str := \u0026#34;b\u0026#34; checkGrade(str) } func checkGrade(grade string) { //\tswitch switch grade { case \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;: fmt.Printf(\u0026#34;Very Good\u0026#34;) case \u0026#34;c\u0026#34;: fmt.Printf(\u0026#34;Good\u0026#34;) default: fmt.Println(\u0026#34;normal\u0026#34;) } } 循环 for range 可以使用for range遍历数组、切片、字符串、map及通道(channel)。\n通过for range遍历的返回值有以下规律：\n1.数组、切片、字符串返回索引和值。 2.map返回键和值。 3.通道(channel)只返回通道内的值。\narr := [...]int{1, 2, 3} //[3]int //arr := []int{1, 2, 3} //[]int for i, v := range arr { fmt.Printf(\u0026#34;%v:%v\\n\u0026#34;, i, v) } fmt.Printf(\u0026#34;%T\\n\u0026#34;, arr) break：在循环中，跳出一层循环\ncontinue\ngoto\n数组 package Base import \u0026#34;fmt\u0026#34; func Array() { //\t数组列表初始化 var arr = [5]int{4, 5, 6, 7, 8} fmt.Println(arr) //\t使用 ... , 让他自行推断长度 var arr1 = [...]int{4, 5, 6, 7, 8, 9, 10} fmt.Println(arr1) //\t指定索引值的方式初始化 var arr2 = [...]int{0: 1, 2: 2, 3: 4} fmt.Println(arr2) } 切片 前面我们学习了数组，数组是固定长度，可以容纳相同数据类型的元素的集合。当长度固定时，使用还是带来一些限制，比如：我们申请的长度太大浪费内存，太小又不够用。\n鉴于上述原因，我们有了go语言的切片，可以把切片理解为，可变长度的数组，其实它底层就是使用数组实现的，增加了自动扩容功能。切片 (slice) 是一个拥有相同类型元素的可变长度的序列。\nfunc Slice() { //\t数组 var arr = [...]int{3, 4, 5, 6} fmt.Println(arr) //\t切片 var slice = []int{3, 4, 5, 6} fmt.Println(slice) // 通过 make var sliceByMake = make([]int, 5) fmt.Println(sliceByMake) println(\u0026#34;len\u0026#34;, len(sliceByMake)) println(\u0026#34;cap\u0026#34;, cap(sliceByMake)) } tips headNum := 6 // 这里创建了 6 个 0 var UidIntArr = make([]int, headNum) // right var UidIntArr = make([]int, 0, headNum) 添加、删除、Copy 删除：连续容器的元素删除无论在任何语言中，都要将删除点前后的元素移动到新的位置，随着元素的增加，这个过程将会变得极为耗时，因此，当业务需要大量、频繁地从一个切片中删除元素时，如果对性能要求较高的话，就需要考虑更换其他的容器了（如双链表等能快速从删除点删除元素）。\n//\tadd var slice1 = []int{1, 2, 3, 4, 5} fmt.Println(\u0026#34;before add\u0026#34;, slice1) slice1 = append(slice1, 6) slice1 = append(slice1, 6) slice1 = append(slice1, 6) fmt.Println(\u0026#34;after add\u0026#34;, slice1) //before add [1 2 3 4 5] //after add [1 2 3 4 5 6 6 6] //\tdelete fmt.Println(\u0026#34;before delete\u0026#34;, slice1) // 假设想删除 下标为 4 的元素 slice1 = append(slice1[:4], slice1[5:]...) //\u0026lt;======= fmt.Println(\u0026#34;after delete\u0026#34;, slice1) //\tcopy var slice3 = []int{1, 2, 3, 4, 5} var slice4 []int copy(slice4, slice3) fmt.Println(\u0026#34;slice4\u0026#34;, slice1) map map是一种key:value键值对的数据结构容器。map内部实现是哈希表(hash)。 map最重要的一点是通过key来快速检索数据，key类似于索引，指向数据的值。 map是引用类型的。\n初始化 func MapInit() { map1 := map[string]string{ \u0026#34;name\u0026#34;: \u0026#34;Tom\u0026#34;, \u0026#34;age\u0026#34;: \u0026#34;12\u0026#34;, \u0026#34;gender\u0026#34;: \u0026#34;male\u0026#34;, } fmt.Println(map1) //map[age:12 gender:male name:Tom] map2 := make(map[string]string, 5) map2[\u0026#34;name\u0026#34;] = \u0026#34;Amy\u0026#34; map2[\u0026#34;age\u0026#34;] = \u0026#34;13\u0026#34; map2[\u0026#34;gender\u0026#34;] = \u0026#34;female\u0026#34; fmt.Println(map2) //map[age:13 gender:female name:Amy] } 取值、遍历 //\t通过 key 取值 key := \u0026#34;name\u0026#34; value := map2[key] fmt.Println(\u0026#34;key = name , value = \u0026#34;, value) //key = name , value = Amy //\t判断一个map是否含有某个 key 值 value1, ok := map2[key] fmt.Printf(\u0026#34;key = name , isExist = %t , value = %v\\n\u0026#34;, ok, value1) //key = name , isExist = true , value = Amy //\t遍历 for k, v := range map2 { fmt.Printf(\u0026#34;%v:%v\\n\u0026#34;, k, v) } //name:Amy //age:13 //gender:female function go语言中函数特性\n1.go语言中有3种函数：普通函数、匿名函数（没有名称的函数）、方法（定义在struct上的函数）。\n2.go语言中不允许函数重载(overload),也就是说不允许函数同名。\n3.go语言中的函数不能嵌套函数，但可以嵌套匿名函数。\n4.函数是一个值，可以将函数赋值给变量，使得这个变量也成为函数。\n5.函数可以作为参数传递给另一个函数。\n6.函数的返回值可以是一个函数。\n7.函数调用的时候，如果有参数传递给函数，则先拷贝参数的副本，再将副本传递给函数。\n8.函数参数可以没有名称。\n返回值 1,return关键字中指定了参数时，返回值可以不用名称。如果return省略参数，则返回值部分必须带名称\n2.当返回值有名称时，必须使用括号包围，逗号分隔，即使只有一个返回值\n3.但即使返回值命名了，return中也可以强制指定其它返回值的名称，也就是说return的优先级更高\n4.命名的返回值是预先声明好的，在函数内部可以直接使用，无需再次声明。命名返回值的名称不能和函数参 数名称相同，否则报错提示变量重复定义\n5.return中可以有表达式，但不能出现赋值表达式，这和其它语言可能有所不同。例如return a+b是正确 的，但return c=a+b是错误的。\nfunc Function() { name, age := fun1() fmt.Printf(\u0026#34;name:%v,age:%v\\n\u0026#34;, name, age) } func fun1() (name string, age int) { name = \u0026#34;Amy\u0026#34; age = 19 return //\t等价于 ==\u0026gt; return name, age } 参数 值传递 【因为会创建函数副本】\n注意 ：map、slice、interface、channel这些数据类型本身就是指针类型的，所以就算是拷贝传值也是拷贝的指针，拷贝后的参数仍然指向底层数据结构，所以修改它们可能会影响外部数据结构的值。\nfunc Function() { a := []int{1, 2} fun2(a) fmt.Println(a[0]) // 100 } func fun2(a []int) { a[0] = 100 } 变长参数 func Function() { fun3(\u0026#34;Amy\u0026#34;, \u0026#34;Beijing\u0026#34;, \u0026#34;23\u0026#34;) } func fun3(args ...string) { for i, arg := range args { fmt.Printf(\u0026#34;%v:%v\\n\u0026#34;, i, arg) } } 0:Amy 1:Beijing 2:23 高阶函数 函数可以作为一个函数的参数、返回值。\n匿名函数 闭包 闭包可以理解成定义在一个函数内部的函数。在本质上，闭包是将函数内部和函数外部连接起来的桥梁。或者说是函数和其引用环境的组合体。 闭包指的是一个函数和与其相关的引用环境组合而成的实体。简单来说，==闭包=函数+引用环境==。\n变量f是一个函数并且它引用了其外部作用域中的x变量，此时f就是一个闭包。在f的生命周期内，变量x也一直有效。\nfunc Closure() { f := add() println(f(10)) println(f(20)) println(f(30)) // 10 // 30 // 60 //\t变量逃逸，从栈去到堆 } func add() func(int) int { var x int return func(y int) int { x += y return x } } 递归 函数内部调用函数自身的函数称为递归函数。 使用递归函数最重要的三点：\n1.递归就是自己调用自己。 2.必须先定义函数的退出条件，没有退出条件，递归将成为死循环。 3.go语言递归函数很可能会产生一大堆的goroutine,也很可能会出现栈空间内存谥出问题。\ndefer go语言中的defer语句会将其后面跟随的语句进行延迟处理。\n在defer归属的函数即将返回时，将延迟处理的语句按defer定义的逆序进行执行，\n也就是说，先被defer的语句最后被执行，最后被defer的语句，最先被执行。\ndefer\u0026rsquo;特性\n1.关键字defer用于注册延迟调用。 2.这些调用直到return前才被执。因此，可以用来做资源清理。 3.多个defer语句，按先进后出的方式执行。 4.defer语句中的变量，在defer声明时就决定了。\ndefer用途 1.关闭文件句柄 2.锁资源释放 3.数据库连接释放\ninit函数 golang有一个特殊的函数init函数，先于main函数执行，实现包级别的一些初始化操作。\ninit函数的主要特点 ·init函数先于main函数==自动执行==，不能被其他函数调用： ·init函数没有输入参数、返回值： ·每个包可以有多个init函数： ·包的每个源文件也可以有多个init函数，这点比较特殊： ·同一个包的init执行顺序，golang没有明确定义，编程时要注意程序不要依赖这个执行顺序。 ·不同包的it函数按照包，导入的依赖关系决定执行顺序。 golang初始化顺序 初始化顺序：变量初始化-\u0026gt;init()-\u0026gt;main()\n指针 G0语言中的函数传参都是值拷贝，当我们想要修改某个变量的时候，我们可以创建一个指向该变量地址的指针变 量。传递数据使用指针，而无须拷贝数据。\n类型指针不能进行偏移和运算。\nG0语言中的指针操作非常简单，只需要记住两个符号：\u0026amp;（取地址）和 *（根据地址取值）。\n指针地址和指针类型 每个变量在运行时都拥有一个地址，这个地址代表变量在内存中的位置。\nGo语言中使用\u0026amp;字符放在变量前面对变量进行取地址操作。\nGo语言中的值类型(int、float、bool、string、array、struct)都有对应的指针类型，如：*int、*int64、*string等。\n指针语法 一个指针变量指向了一个值的内存地址。\n(也就是我们声明了一个指针之后，可以像变量赋值一样，把一个值的内存地址放入到指针当中。)\n类似于变量和常量，在使用指针前你需要声明指针。指针声明格式如下：\nvar var_name *var-type var-type: 为指针类型 var-name: 为指针变量名 *：用于指定变量是作为一个指针 指针数组 表示数组里面的元素的类型是指针类型\n定义语法\nvar ptr [MAX]*int; 例子\nfunc Pointer() { var arr = [3]int{1, 2, 3} var pArr [3]*int for i := 0; i \u0026lt; len(arr); i++ { pArr[i] = \u0026amp;arr[i] } for i := 0; i \u0026lt; len(arr); i++ { println(pArr[i]) } //0xc000143f38 //0xc000143f40 //0xc000143f48 } 类型定义和类型别名 在介绍结构体之前，我们先来看看什么是类型定义和类型别名。\ngo语言类型定义 类型定义的语法\ntype NewType Type 实例\n//类型定义 type MyInt int //i为MyInt类型 var i MyInt i = 100 fmt.Printf(\u0026#34;i:%v i:%T\\n\u0026#34;, i, i) //\ti:100 i:Base.MyInt 类型别名 //类型别名 type MyInt1 = int var i1 MyInt1 i1 = 100 fmt.Printf(\u0026#34;i:%v i:%T\\n\u0026#34;, i1, i1) //\ti:100 i:int 结构体 go语言没有面向对象的概念了，但是可以使用结构体来实现面向对象编程的一些特性，例如：继承、组合等特 性。\n结构体的定义 结构体的定义和类型定义类似，只不过多了一个struct关键字：\ntype Person struct { id int name string age int email string } func Struct() { // 初始化 person1 := Person{ 2, \u0026#34;Amy\u0026#34;, 23, \u0026#34;hello@qq.com\u0026#34;, } person2 := Person{ id: 3, name: \u0026#34;Tom\u0026#34;, age: 20, email: \u0026#34;world@qq.com\u0026#34;, } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, person1) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, person2) } 结构体指针 var p1Point *Person p1Point = \u0026amp;person1 fmt.Printf(\u0026#34;%p\\n\u0026#34;, p1Point) // 通过 new var p2Point = new(Person) fmt.Printf(\u0026#34;%p\\n\u0026#34;, p2Point) 结构体作为函数参数 go结构体可以像普通变量一样，作为函数的参数，传递给函数，这里分为两种情况：\n直接传递结构体，这是是一个副本（拷贝），在函数内部不会改变外面结构体内容。 传递结构体指针，这时在函数内部，能够改变外部结构体内容。 直接传递结构体 这是值传递，将拷贝一份，不会改变原来的数据\n传递结构体指针 这就会修改原来的数据了\ntype Person struct { id int name string age int email string } func Struct() { // 初始化 person1 := Person{ 2, \u0026#34;Amy\u0026#34;, 23, \u0026#34;hello@qq.com\u0026#34;, } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, person1) showPerson(\u0026amp;person1) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, person1) //Base.Person{id:2, name:\u0026#34;Amy\u0026#34;, age:23, email:\u0026#34;hello@qq.com\u0026#34;} //Base.Person{id:2, name:\u0026#34;Amy\u0026#34;, age:1000, email:\u0026#34;hello@qq.com\u0026#34;} } func showPerson(person *Person) { person.age = 1000 } 嵌套结构体 go语言没有面向对象编程思想，也没有继承关系，但是可以通过结构体嵌套来实现这种效果。\n下面通过实例演示如何实现结构体嵌套，加入有一个人Person结构体，这个人还养了一个宠物Dog结构体。\ntype Dog struct { name string color string age int } type Person struct { dog Dog name string age int } 方法 gp语言没有面向对象的特性，也没有类对象的概念。\n但是，可以使用结构体来模拟这些特性，我们都知道面向对象里面有类方法等概念。\n我们也可以声明一些方法，属于某个结构体。\n方法的语法 Go中的方法，是一种特殊的函数，定义于struct之上（与struct关联、绑定），被称为struct的接受者(receiver))。\n通俗的讲，方法就是有接收者的函数。\n一个方法和一个函数非常相似，多了一个接受类型。\n语法格式如下： type mytype struct{} func (recv mytype)my_method(para)return_type {} func (recv *mytype)my_method(para)return_type {} mytype:定义一个结构体 recv:接受该方法的结构体(receiver) my-method:方法名称 para:参数列表 return-type:返回值类型 实例\ntype Person struct { name string age int } func (p Person) eat() { fmt.Printf(\u0026#34;%v is eating.\\n\u0026#34;, p.name) } func (p Person) sleep() { fmt.Printf(\u0026#34;%v is sleepy.\\n\u0026#34;, p.name) } func Struct() { person := Person{ name: \u0026#34;Tom\u0026#34;, age: 43, } person.eat() person.sleep() } 方法的注意事项 方法的receiver type并非一定要是struct类型，type定义的类型别名、slice、.map、channel、.func类型等都可 以。 struct结合它的方法就等价于面向对象中的类。只不过struct可以和它的方法分开，并非一定要属于同一个文 件，但必须属于同一个包。 方法有两种接收类型：(T Type)和(T*Type),它们之间有区别。 方法就是函数，所以Go中没有方法重载(overload)的说法，也就是说同一个类型中的所有方法名必须都唯一。 如果receiver是一个指针类型，则会自动解除引用。 方法和type是分开的，意味着实例的行为(behavior)和数据存储(field)是分开的，但是它们通过receiver建立起 关联关系。 方法接收者类型 结构体实例，有值类型和指针类型，那么方法的接收者是结构体，那么也有值类型和指针类型。\n区别就是接收者是否复制结构体副本。==值类型复制，指针类型不复制。==\npackage Base import \u0026#34;fmt\u0026#34; type Person struct { name string age int } func (p Person) modifyName() { p.name = \u0026#34;hello\u0026#34; } func (p *Person) modifyName1() { p.name = \u0026#34;hello\u0026#34; } func Struct() { person := Person{ name: \u0026#34;Tom\u0026#34;, age: 43, } fmt.Println(person) person.modifyName() fmt.Println(person) person.modifyName1() fmt.Println(person) //{Tom 43} //{Tom 43} //{hello 43} } 接口 接口像是一个公司里面的领导，他会定义一些通用规范，只设计规范，而不实现规范。\ngo语言的接口，是一种新的类型定义，它把所有的具有共性的方法定义在一起，任何其他类型只要实现了这些方 法就是实现了这个接口。\n语法格式和方法非常类似。\ndb_init package Dao import ( \u0026#34;log\u0026#34; \u0026#34;server/Model\u0026#34; \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/gorm/schema\u0026#34; ) type Manager interface { Register(userinfo Model.User) error GetUser(userId uint64) (Model.User, error) IsExist(username string) (Model.User, error) GetPostListByUserId(userId uint64) ([]Model.Post, error) UpdateProfileById(userId uint64, data *Model.User) error GetCommunityList() ([]Model.Community, error) StoreArticle(postInfo Model.Post) error GetList(latestTime int64) ([]Model.Post, error) GetPostById(postId int64) (Model.Post, error) GetUsernameById(AuthorId uint64) (author string, err error) GetCommunityNameById(CommunityId uint64) (CommunityName string, err error) DeletePostById(postId int64) error AddComment(comment *Model.Comment) } type manager struct { db *gorm.DB } var Mgr Manager func init() { dsn := \u0026#34;root:Admin666@tcp(127.0.0.1:3306)/blogserver?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{ NamingStrategy: schema.NamingStrategy{ SingularTable: true, }, }) if err != nil { log.Fatal(\u0026#34;Failed to init db:\u0026#34;, err) } Mgr = \u0026amp;manager{db: db} if err := db.AutoMigrate(\u0026amp;Model.Post{}); err != nil { log.Fatal(err) } } dao.user package Dao import ( \u0026#34;server/Model\u0026#34; ) func (mgr manager) Register(userinfo Model.User) error { result := mgr.db.Create(\u0026amp;userinfo) return result.Error } func (mgr manager) GetUser(userId uint64) (Model.User, error) { var user Model.User if err := mgr.db.Select(\u0026#34;user_id\u0026#34;, \u0026#34;username\u0026#34;, \u0026#34;company\u0026#34;, \u0026#34;user_page\u0026#34;, \u0026#34;user_introduce\u0026#34;, \u0026#34;position\u0026#34;, \u0026#34;created_at\u0026#34;). Where(\u0026#34;user_id=?\u0026#34;, userId).Find(\u0026amp;user).Error; err != nil { return user, err } return user, nil } func (mgr manager) IsExist(username string) (Model.User, error) { var userinfo Model.User result := mgr.db.Where(\u0026#34;username=?\u0026#34;, username).Find(\u0026amp;userinfo) return userinfo, result.Error } func (mgr manager) UpdateProfileById(userId uint64, data *Model.User) error { var userinfo Model.User var maps = make(map[string]interface{}) maps[\u0026#34;username\u0026#34;] = data.Username maps[\u0026#34;user_page\u0026#34;] = data.UserPage maps[\u0026#34;company\u0026#34;] = data.Company maps[\u0026#34;user_introduce\u0026#34;] = data.UserIntroduce maps[\u0026#34;position\u0026#34;] = data.Position err := mgr.db.Model(\u0026amp;userinfo).Where(\u0026#34;user_id = ? \u0026#34;, userId).Updates(maps).Error return err } 接口和类型的关系 1.一个类型可以实现多个接口 2.多个类型可以实现同一个接口（多态）\n一个类型实现多个接口\n例如：有一个Player接口可以播放音乐，有一个Video接口可以播放视频，\n一个手机Mobile实现这两个接口，既可以播放音乐，又可以播放视频。\n接口嵌套 package Base import \u0026#34;fmt\u0026#34; type Fly interface { FlyFunc() } type Swim interface { SwimFunc() } type FlyFish interface { Fly Swim } type Fish struct { } func (f Fish) FlyFunc() { fmt.Println(\u0026#34;Fish is flying.\u0026#34;) } func (f Fish) SwimFunc() { fmt.Println(\u0026#34;Fish is swimming.\u0026#34;) } func Interface() { var ff FlyFish // 此处如果不实现方法会报错 ff = Fish{} ff.SwimFunc() ff.FlyFunc() } 通过接口实现OCP设计原则 面向对象的可复用设计的第一块基石，便是所谓的”开-闭“原则(Open-Closed Principle,常缩写为OCP)。\n虽然，go不是面向对象语言，但是也可以模拟实现这个原则。\n实例 接口:\n特殊的数据类型\n方法定义的集合\n方法名(形参类型)返回值类型\n提高代码的复用率\n接口本身不能绑定方法\n保存的是：值+原始类型\n5.2.2 实现\n一个类型实现了接口的所有方法\n即实现了该接口\ngo中无需“implements”关键字\n5.2.3 类型选择\nswitch…case + interface.(type)\n.(type)不能在 switch…case 外使用\n5.2.4 类型断言\n还原为原始类型 interface.(Type)\n如果接口没有保存类型，则会报错\n可返回两个值\nvalue, ok := interface.(Type)\n5.2.5 空接口\ninterface{}\n空接口可保存任何类型\n5.2.6 nil问题\nnil 值：有类型没有值，接口本身并不是 nil，可以处理\nnil 接口：即没有保存值，也没有保存类型，使用时会报错\n//5.2 接口 type textMes struct { Type string Text string } func (tm *textMes) setText() { tm.Text = \u0026#34;hello\u0026#34; } type imgMes struct { Type string Img string } func (im *imgMes) setImg() { im.Img = \u0026#34;清明上河图\u0026#34; } type Mes interface { setType() } func (tm *textMes) setType() { tm.Type = \u0026#34;文字消息\u0026#34; } func (im *imgMes) setType() { im.Type = \u0026#34;图片消息\u0026#34; } func SendMes(m Mes) { m.setType() switch mptr := m.(type) { case *textMes: mptr.setText() case *imgMes: mptr.setImg() } fmt.Println(\u0026#34;m=\u0026#34;, m) } func Interface() { tm := textMes{} SendMes(\u0026amp;tm) im := imgMes{} SendMes(\u0026amp;im) var n1 int = 1 n1interface := interface{}(n1) n2, ok := n1interface.(int) if ok { fmt.Println(\u0026#34;n2=\u0026#34;, n2) } else { fmt.Println(\u0026#34;类型断言失败\u0026#34;) } } 继承 golang本质上没有ocp的概念，也没有继承的概念，但是可以通过结构体嵌套实现这个特性。\ngolang 中的继承是通过结构体中的==匿名字段==来实现\n例：定义一个 BaseNum 对象 (结构体)，作为父类，Add 和Sub 对象(结构体)中包含了BaseNum 匿名字段， 此时 Add 和Sub 就是BaseNum的子类\ntype BaseNum struct { num1 int num2 int } // BaseNum 即为父类型名称 type Add struct { BaseNum } //加法子类, 定义加法子类的主要目的, 是为了定义对应子类的方法 type Sub struct { BaseNum } //减法子类 构造函数 golang没有构造函数的概念，可以使用函数来模拟构造函数的的功能。\npackage Base import \u0026#34;fmt\u0026#34; type Person1 struct { name string age int } func NewPerson(name string, age int) (*Person1, error) { if name == \u0026#34;\u0026#34; { return nil, fmt.Errorf(\u0026#34;name不能为空\u0026#34;) } if age \u0026lt; 0 { return nil, fmt.Errorf(\u0026#34;age不能小于g\u0026#34;) } return \u0026amp;Person1{name: name, age: age}, nil } func Constructor() { person, err := NewPerson(\u0026#34;tom\u0026#34;, 20) if err != nil { fmt.Printf(\u0026#34;err:%v\\n\u0026#34;, err) } fmt.Printf(\u0026#34;person:%v\\n\u0026#34;, *person) } 包管理工具go module go modules是golang1.11新加的特性，用来管理模块中包的依赖关系。\ngo mod使用方法\n初始化模块\tgo mod init\u0026lt;项目模块名称\u0026gt;\n依赖关系处理，根据go.mod文件\tgo mod tidy\n将依赖包复制到项目下的vendor目录\tgo mod vendor\n如果包被屏蔽（墙），可以使用这个命令，随后使用go build-mod=vendor编译\n显示依赖关系\tgo list -m all\n显示详细依赖关系\tgo list -m -json all\n下载依赖\tgo mod download [path@version] [path@version]是非必写的\n并发编程-\u0026gt;协程 Golang中的并发是函数相互独立运行的能力。Goroutines是并发运行的函数。\nGolang提供了Goroutines作为并发处理操作的一种方式。\n创建一个协程非常简单，就是在一个任务函数前面添加一个go关键字：\ngo task() Q1 select …… case //5.3 协程 var ( c int lock sync.Mutex ) func PrimeNum(n int) { for i := 2; i \u0026lt; n; i++ { if n%i == 0 { return } } fmt.Printf(\u0026#34;%v\\t\u0026#34;, n) lock.Lock() c++ lock.Unlock() } func Goroutine() { for i := 2; i \u0026lt; 100001; i++ { go PrimeNum(i) } var key string fmt.Scanln(\u0026amp;key) fmt.Printf(\u0026#34;\\n共找到%v个素数\\n\u0026#34;, c) } //5.4 channel func pushNum(c chan int) { for i := 0; i \u0026lt; 100; i++ { c \u0026lt;- i } close(c) } func pushPrimeNum(n int, c chan int) { for i := 2; i \u0026lt; n; i++ { if n%i == 0 { return } } c \u0026lt;- n } func Channel() { var c1 chan int = make(chan int) go pushNum(c1) // for { // v, ok := \u0026lt;-c1 // if ok { // fmt.Printf(\u0026#34;%v\\t\u0026#34;, v) // } else { // break // } // } for v := range c1 { fmt.Printf(\u0026#34;%v\\t\u0026#34;, v) } var c2 chan int = make(chan int, 100) for i := 2; i \u0026lt; 100001; i++ { go pushPrimeNum(i, c2) } Print: for { select { case v := \u0026lt;-c2: fmt.Printf(\u0026#34;%v\\t\u0026#34;, v) default: fmt.Println(\u0026#34;所有素数已经找到\u0026#34;) break Print } } } 在 Go 编程语言中，select 语句用于在多个通道操作中进行选择。它可以在多个通道上等待数据到达或操作完成，并根据情况执行相应的操作。select 的结构如下：\nselect { case \u0026lt;-channel1: // 执行 channel1 数据到达时的操作 case data := \u0026lt;-channel2: // 执行 channel2 数据到达时的操作，并将数据存储在 data 变量中 case channel3 \u0026lt;- data: // 执行将 data 发送到 channel3 的操作 default: // 当没有任何通道操作准备就绪时执行的操作 } 在您提供的代码中，您使用了 select 来从通道 c2 中接收数据，同时还设置了一个 default 分支。让我对您的代码进行解释：\n首先，您创建了一个缓冲通道 c2，并启动了一系列 goroutine，每个 goroutine 负责将素数推送到 c2 通道。 然后，使用一个无限循环，不断地执行 select 语句。 在 select 语句中，您使用了一个 case 分支，该分支尝试从 c2 通道接收一个整数。如果 c2 通道中有数据，它会执行相应的操作，将接收到的整数打印出来。 您还使用了一个 default 分支，这是当没有通道操作准备就绪时执行的分支。在这种情况下，它会输出 \u0026ldquo;所有素数已经找到\u0026rdquo;，并通过 break Print 语句跳出 for 循环。 总结来说，您的代码通过多个并发的 goroutine 计算素数并推送到通道中，然后使用 select 语句从通道中接收数据并进行处理。select 的作用在于允许您同时等待多个通道的数据到达，哪个通道有数据，就执行相应的操作。\n那这段代码没有 select case 可以吗？\n当您使用 select 时，是因为您希望能够同时监视多个通道，并在其中任何一个通道就绪时执行相应的操作。在您的代码示例中，您使用 select 来从通道 c2 接收数据，并在没有数据可接收时输出提示。\n如果您不需要同时监视多个通道，而只是希望从单个通道中接收数据并执行相应的操作，那么是可以省略 select 的。您可以直接使用通道的阻塞接收操作，例如：\nfor { v, ok := \u0026lt;-c2 if !ok { fmt.Println(\u0026#34;所有素数已经找到\u0026#34;) break } fmt.Printf(\u0026#34;%v\\t\u0026#34;, v) } 在这个循环中，v, ok := \u0026lt;-c2 将从通道 c2 接收数据，并将数据存储在变量 v 中。同时，ok 表示通道是否关闭，如果通道关闭了，就不再有数据可以接收了。\n然后，您可以检查 ok 的值，如果为 false，就输出提示信息并跳出循环。否则，继续执行打印操作。\n所以，您可以根据自己的需求，选择使用带有 select 的并发操作，或者直接使用通道的阻塞接收操作。\n并发编程-\u0026gt;通道channel Go提供了一种称为通道的机制，用于在==goroutine之间==共享数据。\n当您作为goroutine执行并发活动时，需要在goroutine之间共享资源或数据，通道充当goroutine之间的管道（管道）并提供一种机制来保证同步交换。需要在声明通道时指定数据类型。我们可以共享内置、命名、结构和引用类型的值和指针。数据在通道上传递：在 任何给定时间只有一个goroutine可以访问数据项：因此按照设计不会发生数据竞争。\n根据数据交换的行为，有两种类型的通道：无缓冲通道和缓冲通道。\n无缓冲通道用于执行goroutine之间的同步通信，而缓冲通道用于执行异步通信。\n无缓冲通道保证在发送和接收发生的瞬间执行两个goroutine之间的交换。缓冲通道没有这样的保证。\n无缓冲通道（Unbuffered Channel）和缓冲通道（Buffered Channel）是 Go 语言中的两种通道类型，它们在使用方式和适用场景上有一些区别。\n无缓冲通道：\n无缓冲通道是指在发送数据到通道时，发送方会被阻塞直到接收方接收数据。同样，在接收数据时，接收方会被阻塞直到发送方发送数据。这种通道保证了数据的同步传输，发送和接收是紧密耦合的。无缓冲通道的声明方式为 make(chan T)。\n适用场景：\n在并发编程中，用于协调两个 goroutine 之间的同步操作。 当确保发送方和接收方同步工作很重要时，可以使用无缓冲通道。 缓冲通道：\n缓冲通道允许在通道中存储一定数量的数据，当通道中的数据数量达到缓冲区大小时，发送方才会被阻塞。只有在通道满了时，发送方才会被阻塞。同样，当通道中没有数据时，接收方才会被阻塞。缓冲通道的声明方式为 make(chan T, capacity)。\n适用场景：\n在解耦发送方和接收方的情况下，允许发送方发送数据到通道，然后继续执行其他操作，而不必等待接收方。 在生产者-消费者模式中，可以使用缓冲通道来平衡生产者和消费者之间的速度差异 通道由make函数创建，该函数指定chan关键字和通道的元素类型。\n这是创建无缓冲和缓冲通道的代码块：\n语法\nUnbuffered:=make(chan int)\t//整型无缓冲通道 buffered:=make(chan int,10)\t//整型有缓冲通道 使用内置函数make创建无缓冲和缓冲通道。\nmake的第一个参数需要关键字chan,然后是通道允许交换的数据类型。\npackage Base import ( \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) var channel = make(chan int) func send() { rand.Seed(time.Now().UnixNano()) random := rand.Intn(10) println(\u0026#34;随机值：\u0026#34;, random) time.Sleep(2 * time.Second) channel \u0026lt;- random } func GoRoutine() { defer close(channel) go send() println(\u0026#34;wait...\u0026#34;) receive := \u0026lt;-channel println(\u0026#34;接收值：\u0026#34;, receive) println(\u0026#34;end...\u0026#34;) } channel 遍历 package Base func Channel() { c := make(chan int) go func() { for i := 0; i \u0026lt; 5; i++ { c \u0026lt;- i } close(c) }() for v := range c { println(v) } } 并发编程-\u0026gt;WaitGroup实现同步 查看添加WaitGroup和不添加WaitGroup的区别\npackage Base import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var wg sync.WaitGroup func showMsg(i int) { defer wg.Done() fmt.Println(i) } func GoRoutine() { for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go showMsg(i) } wg.Wait() } // StuData 请求参数验证结构 type StuData struct { File *multipart.FileHeader `form:\u0026#34;file\u0026#34; binding:\u0026#34;required\u0026#34;` } func dealStuData(row []string, buff chan map[string]string, wg *sync.WaitGroup, userList chan map[string]string, errData chan []string) { errMsg := make(map[string]string, 0) // 不能提交空数据 for _, val := range row { if val == \u0026#34;\u0026#34; { errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = \u0026#34;数据不能为空\u0026#34; errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } if row[common.EStuGender] != \u0026#34;男\u0026#34; \u0026amp;\u0026amp; row[common.EStuGender] != \u0026#34;女\u0026#34; { errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = \u0026#34;性别格式错误\u0026#34; errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // 比对学院代码是否正确 org := common.Organization{} err := org.GetOrgByCode(row[common.EStuCollegeCode]) if err != nil { msg := fmt.Sprintf(\u0026#34;查询目标学院代码错误:%v\u0026#34;, err) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } if errors.Is(err, sql.ErrNoRows) || org.Name != row[common.EStuCollege] { var msg string if org.Code != \u0026#34;\u0026#34; { msg = fmt.Sprintf(\u0026#34;同一个学院出现不同的学院代码：正确：【%v,%v】，错误：【%v,%v】\u0026#34;, org.Code, org.Name, row[common.EStuCollegeCode], row[common.EStuCollege]) } else { msg = fmt.Sprintf(\u0026#34;不存在代码为：%v的学院\u0026#34;, row[common.EStuCollegeCode]) } logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } ab := common.AddrBook{} // 通过同步系统数据库查看企业微信中是否有对应的学院部门 collegeDep, err := ab.GetDepByDbID(row[common.EStuCollegeCode], row[common.EStuLevel]) if err != nil \u0026amp;\u0026amp; !errors.Is(err, sql.ErrNoRows) { msg := fmt.Sprintf(\u0026#34;查询同步系统库失败:%s\u0026#34;, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // 如果对应学院部门不存在 if errors.Is(err, sql.ErrNoRows) { parentDepid, _ := strconv.Atoi(pid[row[common.EStuLevel]]) depid, err := ab.GetAndUpdateConf() if err != nil { // TODO 数据库异常概率小，故直接返回500 logger.Error(err.Error()) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // TODO 在企业微信中新建学院部门 err = Wxapi.CreateDept(row[common.EStuCollege], int64(parentDepid), depid, depid) if err != nil { logger.Error(fmt.Sprintf(\u0026#34;新建学院部门失败: %s,错误数据为:[%s],\u0026#34;, err.Error(), strings.Join(row, \u0026#34;,\u0026#34;))) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } collegeDep.WxName = row[common.EStuCollege] collegeDep.WxParentID = pid[row[common.EStuLevel]] collegeDep.WxCollegeID = \u0026#34;None\u0026#34; collegeDep.DbID = row[common.EStuCollegeCode] collegeDep.Grade = \u0026#34;None\u0026#34; collegeDep.WxGrade = \u0026#34;None\u0026#34; collegeDep.Level = 3 // TODO 将部门信息写入数据库 err = ab.NewDep(\u0026amp;collegeDep, row[common.EStuLevel], depid) if err != nil { msg := fmt.Sprintf(\u0026#34;将部门信息写入数据库失败: %s,\u0026#34;, err.Error()) logger.Error(msg) // TODO 删除创建的部门 err := Wxapi.DelDept(depid) if err != nil { logger.Error(fmt.Sprintf(\u0026#34;删除部门失败：%s\u0026#34;, err.Error())) } errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } // 通过同步系统数据库查看企业微信中是否有对应的年级部门 gradeDep, err := ab.GetDepByParentIdAndName(collegeDep.WxID, row[common.EStuGrade], row[common.EStuLevel]) if err != nil \u0026amp;\u0026amp; !errors.Is(err, sql.ErrNoRows) { msg := fmt.Sprintf(\u0026#34;查询同步数据库失败: %s\u0026#34;, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // 如果年级部门不存在 if errors.Is(err, sql.ErrNoRows) { parentId, _ := strconv.Atoi(collegeDep.WxID) depid, err := ab.GetAndUpdateConf() if err != nil { // TODO 数据库异常概率小，故直接返回500 logger.Error(fmt.Sprintf(\u0026#34;查询同步数据库失败:%s\u0026#34;, err.Error())) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // TODO 在企业微信中新建年级部门 err = Wxapi.CreateDept(row[common.EStuGrade], int64(parentId), depid, depid) if err != nil { logger.Error(fmt.Sprintf(\u0026#34;新建年级部门失败: %s\u0026#34;, err.Error())) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } gradeDep.WxName = row[common.EStuGrade] gradeDep.WxParentID = collegeDep.WxID gradeDep.WxCollegeID = collegeDep.WxID gradeDep.DbID = \u0026#34;None\u0026#34; gradeDep.Grade = \u0026#34;None\u0026#34; gradeDep.WxGrade = \u0026#34;None\u0026#34; gradeDep.Level = collegeDep.Level + 1 // TODO 将部门信息写入数据库 err = ab.NewDep(\u0026amp;gradeDep, row[common.EStuLevel], depid) if err != nil { msg := fmt.Sprintf(\u0026#34;将部门信息写入数据库失败: %s,\u0026#34;, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } // 先查询是否有该新生数据 bts := common.TStudent{} err1 := bts.QueryStudentByIdCard(row[common.EStuIdCard]) if err1 != nil \u0026amp;\u0026amp; !errors.Is(err1, gorm.ErrRecordNotFound) { msg := fmt.Sprintf(\u0026#34;查询学生信息错误:%s\u0026#34;, err) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // 录入新生数据 ts := common.TStudent{ Name: row[common.EStuName], IdCard: row[common.EStuIdCard], StuId: row[common.EStuStuId], Gender: WxGender[row[common.EStuGender]], Birthday: row[common.EStuBirth], College: row[common.EStuCollege], CollegeCode: row[common.EStuCollegeCode], Grade: row[common.EStuGrade], Level: row[common.EStuLevel], } curUser := make(map[string]string, 0) curUser[\u0026#34;name\u0026#34;] = row[common.EStuName] curUser[\u0026#34;idcard\u0026#34;] = row[common.EStuIdCard] curUser[\u0026#34;stu_id\u0026#34;] = row[common.EStuStuId] curUser[\u0026#34;gender\u0026#34;] = WxGender[row[common.EStuGender]] curUser[\u0026#34;birth\u0026#34;] = row[common.EStuBirth] curUser[\u0026#34;college\u0026#34;] = row[common.EStuCollege] curUser[\u0026#34;college_code\u0026#34;] = row[common.EStuCollegeCode] curUser[\u0026#34;grade\u0026#34;] = row[common.EStuGrade] curUser[\u0026#34;level\u0026#34;] = row[common.EStuLevel] exist := false // 如果已有信息 if err1 == nil { if bts.Status == \u0026#34;已核验\u0026#34; { errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = \u0026#34;success\u0026#34; buff \u0026lt;- errMsg wg.Done() return } err := ts.UpdateStudentByIdCard(ts.IdCard) if err != nil { msg := fmt.Sprintf(\u0026#34;修改学生信息失败:%s,错误数据:[%s]\u0026#34;, err, strings.Join(row, \u0026#34;,\u0026#34;)) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } exist = true } //TODO 判断中间库中是否有该研究生的信息（要从中间库中本科生，研究生，教职工表中查询） if row[common.EStuLevel] != \u0026#34;本科生\u0026#34; { pgStu := common.PGStudent{} originPosition, err2 := pgStu.GetStudentByIdCard(row[common.EStuIdCard]) if err2 != nil \u0026amp;\u0026amp; !errors.Is(err2, sql.ErrNoRows) { logger.Error(fmt.Sprintf(\u0026#34;中间库操作错误：%s\u0026#34;, err2)) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err2.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } // TODO 如果该研究生信息在中间库中存在 if err2 == nil { user, err3 := Wxapi.GetUser(pgStu.StuID) if err3 != nil { msg := fmt.Sprintf(\u0026#34;在企业微信中获取研究生:%s 的信息失败,ERROR:%s\u0026#34;, pgStu.Name, err3.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } var depid []int64 d, _ := strconv.Atoi(gradeDep.WxID) for _, val := range user.Departments { if val.DeptID != int64(d) { depid = append(depid, val.DeptID) } } // TODO 给企业微信中存在数据的研究生添加新部门 depid = append(depid, int64(d)) extattr := user.Extattr err4 := Wxapi.UpdateUser(pgStu.StuID, pgStu.Name, depid, WxGender[row[common.EStuGender]], extattr) if err4 != nil { msg := fmt.Sprintf(\u0026#34;更新已有研究生部门失败:%s\u0026#34;, err4.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } ts.Status = \u0026#34;已核验\u0026#34; ts.InMidDb = \u0026#34;y\u0026#34; //记录该成员信息在中间库中存在 ts.OriginalPosition = originPosition curUser[\u0026#34;status\u0026#34;] = \u0026#34;已核验\u0026#34; curUser[\u0026#34;in_middb\u0026#34;] = \u0026#34;y\u0026#34; curUser[\u0026#34;originPosition\u0026#34;] = originPosition } } // 获取标签列表 taglist, err := Wxapi.GetTagList() if err != nil { logger.Error(fmt.Sprintf(\u0026#34;获取企业微信标签列表失败:%s\u0026#34;, err.Error())) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = err.Error() errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } flag := false // 判断标签是否存在 tmp := strings.Replace(row[common.EStuGrade], \u0026#34;级\u0026#34;, \u0026#34;\u0026#34;, -1) tmp = fmt.Sprintf(\u0026#34;%s/所有学院%s级部门\u0026#34;, row[common.EStuLevel], tmp) for _, values := range taglist.TagList { if values.TagName == tmp { flag = true break } } tagId := int64(-1) // 标签不存在 if !flag { var err error tagId, err = Wxapi.CreateTag(tmp) if err != nil { msg := fmt.Sprintf(\u0026#34;创建标签失败：%s,ERR: %s\u0026#34;, tmp, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } // 将对应年级部门加入到标签 if tagId != -1 { curDepid, _ := strconv.Atoi(gradeDep.WxID) err := Wxapi.AddTagUserOrDep(tagId, []string{}, []int64{int64(curDepid)}) if err != nil { msg := fmt.Sprintf(\u0026#34;为部门%v添加标签：[%v]失败，ERR: %s\u0026#34;, gradeDep.WxID, tmp, err.Error()) logger.Error(msg) errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = msg errData \u0026lt;- row buff \u0026lt;- errMsg wg.Done() return } } errMsg[\u0026#34;name\u0026#34;] = row[common.EStuName] errMsg[\u0026#34;reason\u0026#34;] = \u0026#34;success\u0026#34; if !exist { userList \u0026lt;- curUser } buff \u0026lt;- errMsg wg.Done() } func (st *StuHandle) ImportStuData(context *gin.Context) { var resp = gin.H{ \u0026#34;status\u0026#34;: 200, \u0026#34;msg\u0026#34;: \u0026#34;操作成功\u0026#34;, \u0026#34;err_data_url\u0026#34;: \u0026#34;\u0026#34;, } var form StuData if err := context.ShouldBind(\u0026amp;form); err != nil { logger.Error(err.Error()) Response(context, http.StatusBadRequest, \u0026#34;请求不合法\u0026#34;, resp) return } tmpFile := `./fileTmp/test.xlsx` if _, err := os.Stat(tmpFile); os.IsNotExist(err) { logger.Info(\u0026#34;文件不存在\u0026#34;) } else { logger.Info(\u0026#34;文件存在\u0026#34;) err := os.Remove(tmpFile) if err != nil { msg := fmt.Sprintf(\u0026#34;删除文件失败: %s\u0026#34;, err) logger.Error(msg) Response(context, http.StatusInternalServerError, \u0026#34;操作失败，请稍后再试\u0026#34;, resp) return } } // 接收并处理上传的excel表格 err := context.SaveUploadedFile(form.File, tmpFile) if err != nil { msg := fmt.Sprintf(\u0026#34;保存上传文件失败: %s\u0026#34;, err) logger.Error(msg) Response(context, http.StatusInternalServerError, \u0026#34;操作失败，请稍后再试\u0026#34;, resp) return } f, err := excelize.OpenFile(tmpFile) if err != nil { msg := fmt.Sprintf(\u0026#34;打开文件失败:%s\u0026#34;, err) logger.Error(msg) Response(context, http.StatusInternalServerError, \u0026#34;操作失败，请稍后再试\u0026#34;, resp) return } // 关闭文件 defer func() { if err := f.Close(); err != nil { msg := fmt.Sprintf(\u0026#34;关闭文件失败:%s\u0026#34;, err) logger.Error(msg) } }() rows, err := f.GetRows(\u0026#34;Sheet1\u0026#34;) if err != nil { msg := fmt.Sprintf(\u0026#34;读取Excel文件失败: %s\u0026#34;, err.Error()) logger.Error(msg) Response(context, http.StatusAccepted, \u0026#34;解析Excel数据错误，请确保提交正确的Excel数据\u0026#34;, resp) return } if len(rows) == 0 { logger.Error(\u0026#34;不能提交空文件\u0026#34;) Response(context, http.StatusAccepted, \u0026#34;不能提交空文件\u0026#34;, resp) return } row := rows[0] if len(row) != 9 || row[common.EStuName] != \u0026#34;姓名\u0026#34; || row[common.EStuIdCard] != \u0026#34;身份证号\u0026#34; || row[common.EStuStuId] != \u0026#34;学号\u0026#34; || row[common.EStuGender] != \u0026#34;性别\u0026#34; || row[common.EStuBirth] != \u0026#34;出生日期\u0026#34; || row[common.EStuCollege] != \u0026#34;学院名称\u0026#34; || row[common.EStuCollegeCode] != \u0026#34;学院代码\u0026#34; || row[common.EStuGrade] != \u0026#34;年级\u0026#34; || row[common.EStuLevel] != \u0026#34;层次\u0026#34; { logger.Error(\u0026#34;Excel格式不符合模板要求\u0026#34;) Response(context, http.StatusBadRequest, \u0026#34;Excel格式不符合模板要求\u0026#34;, resp) return } var wg sync.WaitGroup wg.Add(len(rows) - 1) buff := make(chan map[string]string, len(rows)-1) //建立缓冲区，记录不能导入的数据对应的姓名 _failInfo := make([]map[string]string, 0) userBuff := make(chan map[string]string, len(rows)-1) errBuff := make(chan []string, len(rows)-1) // 多进程处理，为每条数据分配一个goroutine for _, data := range rows[1:] { if len(data) != 9 { msg := fmt.Sprintf(\u0026#34;数据不符合要求：【%v】\u0026#34;, data) logger.Error(msg) tmp := make(map[string]string, 0) tmp[\u0026#34;name\u0026#34;] = row[common.EStuName] tmp[\u0026#34;reason\u0026#34;] = msg errBuff \u0026lt;- data buff \u0026lt;- tmp } // 多线程处理，为每条数据开一个线程 go dealStuData(data, buff, \u0026amp;wg, userBuff, errBuff) } wg.Wait() close(buff) close(userBuff) close(errBuff) for val := range buff { _failInfo = append(_failInfo, val) } ts := common.TStudent{} userList := make([]common.TStudent, 0) for val := range userBuff { t := common.TStudent{ Name: val[\u0026#34;name\u0026#34;], IdCard: val[\u0026#34;idcard\u0026#34;], StuId: val[\u0026#34;stu_id\u0026#34;], Gender: val[\u0026#34;gender\u0026#34;], Birthday: val[\u0026#34;birth\u0026#34;], College: val[\u0026#34;college\u0026#34;], CollegeCode: val[\u0026#34;college_code\u0026#34;], Grade: val[\u0026#34;grade\u0026#34;], Level: val[\u0026#34;level\u0026#34;], } t.Status = val[\u0026#34;status\u0026#34;] t.InMidDb = val[\u0026#34;in_middb\u0026#34;] t.OriginalPosition = val[\u0026#34;originPosition\u0026#34;] userList = append(userList, t) } failData := make([][]string, 0) for val := range errBuff { failData = append(failData, val) } err = ts.CreateStudent(userList) if err != nil { logger.Error(err.Error()) Response(context, http.StatusInternalServerError, err.Error(), resp) return } success := 0 fail := 0 var failInfo []string for _, val := range _failInfo { if val[\u0026#34;reason\u0026#34;] != \u0026#34;success\u0026#34; { fail++ failInfo = append(failInfo, val[\u0026#34;reason\u0026#34;]) continue } success++ } if len(failData) == 0 { resp[\u0026#34;err_data_url\u0026#34;] = \u0026#34;\u0026#34; } else { fileName, _ := golib.NewErrDataFile(failData, failInfo) fileName = strings.Replace(fileName, \u0026#34;.xlsx\u0026#34;, \u0026#34;\u0026#34;, -1) resp[\u0026#34;err_data_url\u0026#34;] = fmt.Sprintf(\u0026#34;%v/student/err?name=%v\u0026#34;, config.HostName, fileName) } msg := fmt.Sprintf(\u0026#34;成功导入条数:%d 导入失败条数:%d 总计条数:%d\u0026#34;, success, len(failData), len(rows)-1) status := http.StatusOK if fail != 0 { status = http.StatusAccepted } Response(context, status, msg, resp) return } // 下载不能导入的信息 type reqErrFile struct { FileName int `form:\u0026#34;name\u0026#34; binding:\u0026#34;required\u0026#34;` } func (st *StuHandle) StuErrFile(ctx *gin.Context) { resp := gin.H{ \u0026#34;status\u0026#34;: 200, \u0026#34;msg\u0026#34;: \u0026#34;操作成功\u0026#34;, } err := golib.DelOldFile() if err != nil { logger.Error(fmt.Sprintf(\u0026#34;删除旧文件失败：%v\u0026#34;, err)) Response(ctx, http.StatusInternalServerError, \u0026#34;操作失败\u0026#34;, resp) return } var form reqErrFile if err := ctx.ShouldBind(\u0026amp;form); err != nil { logger.Error(fmt.Sprintf(\u0026#34;参数错误：%v\u0026#34;, err)) Response(ctx, http.StatusBadRequest, \u0026#34;操作不合法\u0026#34;, resp) return } file, err := ioutil.ReadFile(fmt.Sprintf(\u0026#34;./fileTmp/%v.xlsx\u0026#34;, form.FileName)) if err != nil { logger.Error(fmt.Sprintf(\u0026#34;读取文件失败:%v\u0026#34;, err)) Response(ctx, http.StatusNotFound, \u0026#34;找不到资源\u0026#34;, resp) return } ctx.Header(\u0026#34;content-disposition\u0026#34;, `attachment; filename=`+fmt.Sprintf(\u0026#34;%v.xlsx\u0026#34;, form.FileName)) ctx.Data(200, \u0026#34;application/octet-stream\u0026#34;, file) } d := make(map[string]int,6) d[\u0026#34;name\u0026#34;] = 0 d[\u0026#34;content\u0026#34;] = 1 d[\u0026#34;org\u0026#34;] = 2 d[\u0026#34;year\u0026#34;] = 3 d[\u0026#34;user_id\u0026#34;] = 4 d[\u0026#34;username\u0026#34;] = 5 data 并发编程-\u0026gt;runtime runtime包里面定义了一些协程管理相关的api\nruntime.Gosched() 让出CPU时间片，重新等待安排任务\nfunc showMsg1(s string) { for i := 0; i \u0026lt; 2; i++ { fmt.Println(s) } } func RunTime() { go showMsg1(\u0026#34;java\u0026#34;) for i := 0; i \u0026lt; 2; i++ { runtime.Gosched() fmt.Println(\u0026#34;golang\u0026#34;) } fmt.Println(\u0026#34;end...\u0026#34;) } java java golang golang end... 如果没有第11行，可能main协程直接结束啦 golang golang end... runtime.Goexit() 退出协程\nruntime.Goexit() runtime.GOMAXPROCS() func showA() { for i := 0; i \u0026lt; 15; i++ { fmt.Printf(\u0026#34;A:%v\\n\u0026#34;, i) } } func showB() { for i := 0; i \u0026lt; 15; i++ { fmt.Printf(\u0026#34;B:%v\\n\u0026#34;, i) } } func RunTime() { cpuNum := runtime.NumCPU() // 我这是 8 核 println(cpuNum) runtime.GOMAXPROCS(1) // 如果设置为 1 ，则不会交替执行。除非有睡眠在。 go showA() go showB() time.Sleep(time.Second) } 并发编程-\u0026gt;Mutex互斥锁实现同步 除了使用 channel 实现同步之外，还可以使用Mutex互斥锁的方式实现同步。\nGo语言提供了sync包和channel机制来解决并发机制中不同goroutine之间的同步和通信\n没加锁 package Base import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func addOne(i int) { i++ } func subOne(i int) { i-- } func Mutex() { var i = 1 for ; i \u0026lt;= 1000; i++ { go addOne(i) go subOne(i) } time.Sleep(time.Second * 1) fmt.Println(\u0026#34;Sum:\u0026#34;, i) } Sum: 1001 加了锁 package Base import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var mutex sync.Mutex func addOne(i int) { mutex.Lock() i++ mutex.Unlock() } func subOne(i int) { mutex.Lock() i-- mutex.Unlock() } func Mutex() { i := 0 for ; i \u0026lt; 1000; i++ { go addOne(i) go subOne(i) } time.Sleep(time.Second * 1) fmt.Println(\u0026#34;Sum:\u0026#34;, i) } Sum: 1000 锁 Locker Go语言使用go语句开启新的goroutine，由于goroutine非常轻量除了对其分配栈空间外，所占的空间也是微乎其微的。但当多个goroutine同时处理时会遇到比如同时抢占一个资源，某个goroutine会等待等一个goroutine处理完毕某才能继续执行的问题。对于这种情况，官方并不希望依靠共享内存的方式来实现进程的协同操作，而是希望通过channel信道的方式来处理。但在某些特殊情况下，依然需要使用到锁，为此sync包提供了锁。\n当在并发情况下，多个goroutine同时修改某一个变量时，就会出现资源抢占，因此会导致数据不一致的问题。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { var num = 0 for i := 0; i \u0026lt; 100000; i++ { go func(i int) { num++ fmt.Printf(\u0026#34;goroutine %d: num = %d\\n\u0026#34;, i, num) }(i) } time.Sleep(time.Second)//主goroutine等待1秒以确保所有工作goroutine执行完毕 } ... goroutine 10018: num = 98635 goroutine 12646: num = 98635 goroutine 12844: num = 98635 goroutine 12950: num = 98635 ... 上例中goroutine一依次从寄存器中读取num的值后做加法运算，然后将其结果回写到寄存器中。运行中会发现存在一个goroutine取出num的值时做加法运算时，另一个goroutine也取出了num的值。因为上一个goroutine运行结果还没有回写到寄存器，最终导致多个goroutine产生的相同的结果。\n并发编程中同步原语-锁，为了保证多个线程或goroutine在访问同一块内存时不出现混乱，Go语言的sync包提供了常见的并发编程同步原语的控制锁。\nsync包围绕着Locker锁接口展开，Locker接口中提供了两个方法Lock()和Unlock()。\ntype Locker interface { Lock() Unlock() } Go语言标准库sync中提供了两种锁分别是互斥锁sync.Mutex和读写互斥锁sync.RWMutex\n互斥锁sync.Mutex sync.Mutex是一个互斥锁，可以由不同的goroutine加锁和解锁。\nsync.Mutex是Golang标准库提供的一个互斥锁，当一个goroutine获得互斥锁权限后，其他请求锁的goroutine会阻塞在Lock()方法的调用上，直到调用Unlock()方法被释放。\n例如：10个并发的goroutine打印同一个数字100，为避免重复打印，实现printOnce(num int)函数，使用集合set记录已打印过的数字。若数字已经打印过，则不再打印。\n$ vim mutex_test.go package test import ( \u0026#34;fmt\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) var set = make(map[int]bool, 0) func printOnce(index int, num int) { if _, ok := set[num]; !ok { fmt.Println(index, num) } set[num] = true } func TestPrint(t *testing.T) { for i := 0; i \u0026lt; 10; i++ { go printOnce(i, 100) } time.Sleep(time.Second) } $ go test -v mutex_test.go === RUN TestPrint 9 100 3 100 --- PASS: TestPrint (1.00s) PASS ok command-line-arguments 1.304s 程序多次运行后会发现打印次数多次，因为对同一个数据结构set的访问发生了冲突。\n并发访问中比如多个goroutine并发更新同一个资源，比如计时器、账户余额、秒杀系统、向同一个缓存中并发写入数据等等。如果没有互斥控制，很容易会出现异常，比如计时器计数不准确、用户账户可能出现透支、秒杀系统出现超卖、缓存出现数据缓存等等，后果会很严重。\n互斥锁是并发控制的一种基本手段，是为了避免竞争而建立的一种并发控制机制。学习前首先需要弄清楚一个概念-临界区。在并发编程中，如果程序中的一部分会被并发访问或修改，为了避免并发访问导致的意想不到的结果，这部分程序需要被保护起来，这部分被保护起来的程序就叫做临界区。\n临界区是一个被共享的资源，或者说是一个整体的共享资源，比如对数据库的访问，对某个共享数据结构的操作。对一个I/O设备的使用，对一个连接池中的连接的调用等等。\n如果很多线程同步访问临界区就会造成访问或操作错误，这并不是我们希望看到的结果。所以，使用互斥锁，限定临界区只能同时由一个线程持有。当临界区由一个线程持有的时候，其他线程如果想进入临界区就会返回失败，或者是等待。直到持有的线程退出临界区，这些等待线程中的某一个才有机会接着持有这个临界区。\n互斥锁\n互斥锁可以很好的解决资源竞争的问题，因此也有人称之为排它锁。Golang标准库中使用Mutex来实现互斥锁。根据2019年分析Go并发Bug的论文Understanding Real-World Concurrency Bugs in Go中，Mutex是使用最为广泛的同步原语（Synchronization primitives， 并发原语或同步原语）。关于同步原语并没有一个严格的定义，可将其看作是解决并发问题的一个基础的数据结构。\ntype Mutex struct { state int32 //状态标识 sema uint32 //信号量 } Go标准库提供了sync.Mutex互斥锁类型以及两个方法分别是Lock加锁和Unlock释放锁。可以通过在代码前调用Lock方法，在代码后调用Unlock方法来保证一段代码的互斥执行，也可以使用defer语句来保证互斥锁一定会被解锁。当一个goroutine调用Lock方法获得锁后，其它请求的goroutine都会阻塞在Lock方法直到锁被释放。\n一个互斥锁只能同时被一个goroutine锁定，其它goroutine将阻塞直到互斥锁被解锁，也就是重新争抢对互斥锁的锁定。需要注意的是，对一个未锁定的互斥锁解锁时将会产生运行时错误。\nsync.Mutex不区分读写锁，只有Lock()和Lock()之间才会导致阻塞的情况。若在一个地方Lock()，在另一个地方不Lock()而是直接修改或访问共享数据，对于sync.Mutext类型是允许的，因为mutex不会和goroutine进行关联。若要区分读锁和写锁，可使用sync.RWMutex类型。\n在Lock()和Unlock()之间的代码段成为资源临界区（critical section），在这一区间内的代码是严格被Lock()保护的，是线程安全的，任何一个时间点都只能有一个goroutine执行这段区间的代码。\n例如：使用互斥锁的Lock()和Unlock()方法将冲突包裹\npackage test import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) var m sync.Mutex var set = make(map[int]bool, 0) func printOnce(index int, num int) { m.Lock() defer m.Unlock() if _, ok := set[num]; !ok { fmt.Println(index, num) } set[num] = true } func TestPrint(t *testing.T) { for i := 0; i \u0026lt; 10; i++ { go printOnce(i, 100) } time.Sleep(time.Second) } 相同的数字只会比打印一次，当一个goroutine调用了Lock()方法时，其他goroutine被阻塞了，直到Unlock()调用将锁释放。因此被包裹部分的代码就能避免冲突，实现互斥。\n互斥即不能同时运行，使用互斥锁的两个代码片段相互排斥，只有其中一个代码片段执行完毕后，另一个才能执行。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var num = 0 var locker sync.Mutex for i := 0; i \u0026lt; 100000; i++ { go func(i int) { locker.Lock() defer locker.Unlock() num++ fmt.Printf(\u0026#34;goroutine %d: num = %d\\n\u0026#34;, i, num) }(i) } time.Sleep(time.Second) } 从上例中可以发现，添加互斥锁后，不仅没有出现抢占资源导致的重复输出，而且输出结果顺序递增。\nGo语言中的Mutex类型的互斥锁Lock()锁定与其它语言不同的是，Lock()锁定的是互斥锁而非一段代码。其他语言比如Java中使用同步锁锁定的是一段代码，以确保多线程并发誓只有一个线程可以控制运行此代码块直到释放同步锁。Go语言是在goroutine中锁定互斥锁，其它goroutine执行到有锁的位置时，由于获取不到互斥锁的锁定，因此会发生阻塞而等待，从而达到控制同步的目的。\nrace detector Golang提供了一个检测并发访问共享资源是否存在问题的工具 - race detector，它可以帮助自动发现城中有没有data race的问题。\nGolang的race detector是基于Google的C/C++ sanitizers技术实现的，编译器通过探测所有的内存访问，加入代码能监视对这些内存地址的访问（读或是写）。代码运行时race detector能监控对共享变量的非同步访问，出现race时就会打印出警告信息。\nhttps://blog.golang.org/race-detector\n读写锁sync.RWMutex 在银行存取钱时，对账户余额的修改是需要加锁的，因此此时可能有人汇款到你的账户，如果对金额的修改不加锁，很可能导致最后的金额发生错误。读取账户余额也需要等待修改操作结束，才能读取到正确的余额。大部分情况下，读取余额的操作会更加频繁，如果能保证读取余额的操作能并发执行，程序的效率会很大地提升。\n保证读操作的安全，只需要保证并发读时没有写操作在进行就行。在这种场景下就需要一种特殊类型的锁，即允许多个只读操作并行执行，但写操作会完全互斥。这种锁称之为多读单写锁（multiple readers, single writer lock），简称读写锁。读写锁分为读锁和写锁，读锁允许同时执行，但写锁是互斥的。\nsync.RWMutex读写锁是基于sync.Mutex实现的，读写锁的特点是针对读写操作的互斥锁，读写锁与互斥锁最大不同之处在于分别对读、写进行了锁定。一般用在大量读操作少量写操作中。\n同时只能具有一个goroutine能够获得写锁定 同时可以具有任意多个goroutine获得读锁定 同时只能存在写锁定或读锁定，即读和写互斥。 换句话说\n当只有一个goroutine获得写锁定时，其它无论是读锁定还是写锁定都将会阻塞直到写解锁。 当只有一个goroutine获得读锁定时，其它读锁定仍然可以继续执行。 当有一个或多个读锁定时，写锁定将等待所有读锁定解锁之后才能进行写锁定。 这里所谓的读锁定（RLock）目的是为了告诉写锁定（Lock），此时有很多人正在读取数据，写锁定需要排队等待。\n一般来说，读写锁会分为几种情况：\n读锁之间不互斥，在没有写锁的情况下，读锁是无堵塞的，多个goroutine可以同时获得读锁。 写锁之间是互斥的，当存在写锁时，其它写锁会阻塞。 写锁与读锁互斥，若存在读锁则写锁阻塞，若存在写锁则读锁阻塞。 Go标准库sync.RWMutex读写互斥锁提供了四个方法\n读写互斥锁 描述 Lock 添加写锁 Unlock 释放写锁 RLock 添加读锁 RUnlock 释放读锁 并发编程-\u0026gt;select switch 1.select是Go中的一个控制结构，类似于switch语句，用于处理异步IO操作。select会监听case语句中channel的读写操作，当case中channel读写操作为非阻塞状态（即能读写）时，将会触发相应的动作。\nselect中的case语句必须是一个channel操作. select中的default子句总是可运行的。\n2.如果有多个case都可以运行，select会随机公平地选出一个执行，其他不会执行。\n3.如果没有可运行的case语句，且有default语句，那么就会执行default的动作。\n4.如果没有可运行的case语句，且没有default语句，select将阻塞，直到某个case通信可以运行.\n实例\npackage Base import \u0026#34;time\u0026#34; var chanInt = make(chan int) var chanStr = make(chan string) func Channel() { go func() { chanInt \u0026lt;- 100 chanStr \u0026lt;- \u0026#34;Hello\u0026#34; defer close(chanInt) defer close(chanStr) }() for { select { case r := \u0026lt;-chanInt: println(\u0026#34;chanInt\u0026#34;, r) case r := \u0026lt;-chanStr: println(\u0026#34;chanStr\u0026#34;, r) default: println(\u0026#34;default\u0026#34;) } time.Sleep(time.Second) } } default chanInt 100 chanStr Hello chanStr chanStr chanInt 0 chanInt 0 \u0026hellip;\u0026hellip;\n并发编程-\u0026gt;Timer Timer顾名思义，就是定时器的意思，可以实现一些定时操作，内部也是通过channel来实现的。\npackage Base import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func Timer() { // 第一种创建方式 timer := time.NewTimer(time.Second * 2) fmt.Println(time.Now()) c := \u0026lt;-timer.C fmt.Println(c) // 相差两秒 //2022-09-13 11:28:25.6609052 +0800 +08 m=+0.004536701 //2022-09-13 11:28:27.6616643 +0800 +08 m=+2.005295801 } 并发编程-\u0026gt;Ticker Timer只执行一次，TickerT可以周期的执行。\n实例\nfunc Ticker() { ticker := time.NewTicker(time.Second) count := 0 for range ticker.C { fmt.Println(\u0026#34;ticker...\u0026#34;) count++ if count \u0026gt;= 5 { ticker.Stop() break } } } 并发编程-\u0026gt;原子变量 package Base import ( \u0026#34;fmt\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) var num int64 = 1 func Add(i int64) { atomic.AddInt64(\u0026amp;i, 1) } func Sub(i int64) { atomic.AddInt64(\u0026amp;i, -1) } func Atomic() { for ; num \u0026lt; 1000; num++ { go Add(num) go Sub(num) } time.Sleep(time.Second * 1) fmt.Println(\u0026#34;Sum:\u0026#34;, num) } Advanced level fmt https://www.bilibili.com/read/cv14519061/?from=readlist\n文件常见操作/读写 (os, io, bufio包) https://www.bilibili.com/read/cv14586068/?from=readlist\n错误/日志/单元测试 错误处理\nfunc Errors() { defer func() { err := recover() fmt.Println(\u0026#34;捕捉到了错误:\u0026#34;, err) }() err1 := errors.New(\u0026#34;可爱的错误\u0026#34;) fmt.Println(\u0026#34;err1=\u0026#34;, err1) err2 := fmt.Errorf(\u0026#34;%s的错误\u0026#34;, \u0026#34;温柔\u0026#34;) fmt.Println(\u0026#34;err2=\u0026#34;, err2) panic(err1) } 单元测试 6.10.1 命名规范\n文件名: xxx_test.go (通常xxx为被测试文件名)\n6.10.2 测试函数\n测试函数: func TestXxx(*testing.T) (通常Xxx为被测试函数名)\n性能测试函数: func BenchmarkXxx(*testing.B) (通常Xxx为被测试函数名)\n6.10.3 testing.T与testing.B\ntesting.T与testing.B是testing包定义的结构体，下面简称t与b\n6.10.4 测试命令(go mod下)\n项目名可以简写为\u0026rdquo;.\u0026quot;，下面同一为\u0026quot;.\u0026quot;\n测试指定包: go test ./文件夹路径\n将自动调用所有_test.go文件中的所有TestXxx函数\n测试指定文件: go test ./文件夹路径/xxx_test.go ./go/文件夹路径/xxx.go\n将自动调用xxx_test.go中的所有TestXxx函数\nflag\nflag可以写在 ./\u0026hellip; 前也可以写在 ./\u0026hellip; 之后\n也运行BenchmarkXxx函数: go test -bench ./…\n详细输出(verbose): go test -v ./…\n即使运行成功也输出日志\n规定测试时间: go test -benchtime XhXmXs ./…\n规定测试次数: go test -benchtime Nx ./…\n指定测试cpu数量: go test -cpu N ./…\n指定测试函数: go test -run TestXxx ./…\n只测试TestXxx函数\n超时限制: go test -timeout XhXmXs ./…\n默认限制为10min\n打印测试的内存使用统计: go test -benchmem ./…\n作者：FangChannel https://www.bilibili.com/read/cv14614760/?from=readlist 出处：bilibili\nfor range package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) type Detail struct{ Rid int TeamName string Member string } type TeamMember struct{ Rid int Member string } func main() { d1:=Detail{ Rid: 10, TeamName: \u0026#34;ddd10\u0026#34;, Member: \u0026#34;\u0026#34;, } d2:=Detail{ Rid: 11, TeamName: \u0026#34;ddd11\u0026#34;, Member: \u0026#34;\u0026#34;, } d3:=Detail{ Rid: 12, TeamName: \u0026#34;ddd12\u0026#34;, Member: \u0026#34;\u0026#34;, } t1:=TeamMember{ Rid: 10, Member: \u0026#34;10的Member\u0026#34;, } var ds []Detail ds = append(ds,d1,d2,d3) var ts []TeamMember ts = append(ts, t1) fmt.Println(ts) fmt.Println(ds) for i := 0; i \u0026lt; len(ds); i++ { for j := 0; j \u0026lt; len(ts); j++ { if ds[i].Rid == ts[j].Rid { ds[i].Member = ts[j].Member break } } } // ==== ?? ==== for _, v := range ds { for _, v2 := range ts { if v.Rid == v2.Rid { v.member = v2.menber } } } fmt.Println(ts) fmt.Println(ds) } ","permalink":"https://Bin-lin-rgb.github.io/posts/go/base/","summary":"Base go 常用命令 build: 编译包和依赖 clean: 移除对象文件 doc: 显示包或者符号的文档 env: 打印go的环境信息 bug: 启动错误报告 fix: 运行go tool fix fmt: 运行gofmt进行格式化 generate: 从processing source生成go文件 get: 下载并安装包和依赖 install: 编译并安装包和依赖 list: 列出包 run: 编译并运行go程序 test: 运行测试 tool: 运行go提供的工","title":"Golang 基础语法"},{"content":"","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%AF%87/","summary":"","title":"Go 并发编程篇"},{"content":"","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%AF%87/","summary":"","title":"Go 内存管理篇"},{"content":"","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B%E7%AF%87/","summary":"","title":"Go 调度模型篇"},{"content":"","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-goroutine%E7%AF%87/","summary":"","title":"Go Goroutine篇"},{"content":"","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-mutex%E7%AF%87/","summary":"","title":"Go Mutex篇"},{"content":"1.Go channel 的底层实现原理 概念：\nGo 中的 channel 是一个队列，遵循先进先出的原则，负责协程之间的通信（Go 语言提倡不要通过共享内存来通信，而要通过通信来实现内存共享，CSP(Communicating Sequential Process)并发模型，就是通过 goroutine 和 channel 来实现的）\n使用场景：\n停止信号监听\n定时任务\n生产方和消费方解耦\n控制并发数\n底层数据结构：\n通过 var 声明或者 make 函数创建的 channel 变量是一个存储在函数栈帧上的指针，占用 8 个字节，指向堆上的 hchan 结构体\n源码包中 src/runtime/chan.go 定义了 hchan 的数据结构：\nhchan hchan 结构体：\ntype hchan struct { closed uint32 // channel是否关闭的标志 elemtype *_type // channel中的元素类型 // channel分为无缓冲和有缓冲两种。 // 对于有缓冲的channel存储数据，使用了 ring buffer（环形缓冲区) 来缓存写入的数据，本质是循环数组 // 为啥是循环数组？普通数组不行吗，普通数组容量固定更适合指定的空间，弹出元素时，普通数组需要全部都前移 // 当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置 buf unsafe.Pointer // 指向底层循环数组的指针（环形缓冲区） qcount uint // 循环数组中的元素数量 dataqsiz uint // 循环数组的长度 elemsize uint16 // 元素的大小 sendx uint // 下一次写下标的位置 recvx uint // 下一次读下标的位置 // 尝试读取channel或向channel写入数据而被阻塞的goroutine recvq waitq // 读等待队列 sendq waitq // 写等待队列 lock mutex //互斥锁，保证读写channel时不存在并发竞争问题 } 等待队列：\n双向链表，包含一个头结点和一个尾结点\n每个节点是一个 sudog 结构体变量，记录哪个协程在等待，等待的是哪个 channel，等待发送/接收的数据在哪里\ntype waitq struct { first *sudog last *sudog } type sudog struct { g *g next *sudog prev *sudog elem unsafe.Pointer c *hchan ... } 操作：\n创建 使用 make(chan T, cap) 来创建 channel，make 语法会在编译时，转换为 makechan64 和 makechan\nfunc makechan64(t *chantype, size int64) *hchan { if int64(int(size)) != size { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } return makechan(t, int(size)) } 创建 channel 有两种，一种是带缓冲的 channel，一种是不带缓冲的 channel\n// 带缓冲\nch := make(chan int, 3)\n// 不带缓冲\nch := make(chan int)\n创建时会做一些检查:\n元素大小不能超过 64K 元素的对齐大小不能超过 maxAlign 也就是 8 字节 计算出来的内存是否超过限制 创建时的策略:\n如果是无缓冲的 channel，会直接给 hchan 分配内存 如果是有缓冲的 channel，并且元素不包含指针，那么会为 hchan 和底层数组分配一段连续的地址 如果是有缓冲的 channel，并且元素包含指针，那么会为 hchan 和底层数组分别分配地址 发送 发送操作，编译时转换为 runtime.chansend 函数\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool\n阻塞式：\n调用 chansend 函数，并且 block=true\nch \u0026lt;- 10\n非阻塞式：\n调用 chansend 函数，并且 block=false\nselect { case ch \u0026lt;- 10: ... default } 向 channel 中发送数据时大概分为两大块：检查和数据发送，数据发送流程如下：\n如果 channel 的读等待队列存在接收者 goroutine\n将数据直接发送给第一个等待的 goroutine， 唤醒接收的 goroutine 如果 channel 的读等待队列不存在接收者 goroutine\n如果循环数组 buf 未满，那么将会把数据发送到循环数组 buf 的队尾 如果循环数组 buf 已满，这个时候就会走阻塞发送的流程，将当前 goroutine 加入写等待队列，并挂起等待唤醒 接收 接受操作，编译时转换为 runtime.chanrecv 函数\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool)\n阻塞式：\n调用 chanrecv 函数，并且 block=true\n\u0026lt;-ch v := \u0026lt;ch v, ok := \u0026lt;ch // 当 channel 关闭时，for 循环会自动退出，无需主动监测 channel 是否关闭，可以防止读取已经关闭的 channel,造成读到数据为通道所存储的数据类型的零值 for i := range ch { fmt.Println(i) } 非阻塞式：\n调用 chanrecv 函数，并且 block=false\nselect { case \u0026lt;-ch: ... default } 向 channel 中接收数据时大概分为两大块，检查和数据发送，而数据接收流程如下：\n如果 channel 的写等待队列存在发送者 goroutine\n如果是无缓冲 channel，直接从第一个发送者 goroutine 那里把数据拷贝给接收变量，唤醒发送的 goroutine 如果是有缓冲 channel（已满），将循环数组 buf 的队首元素拷贝给接收变量，将第一个发送者 goroutine 的数据拷贝到 buf 循环数组队尾，唤醒发送的 goroutine 如果 channel 的写等待队列不存在发送者 goroutine\n如果循环数组 buf 非空，将循环数组 buf 的队首元素拷贝给接收变量 如果循环数组 buf 为空，这个时候就会走阻塞接收的流程，将当前 goroutine 加入读等待队列，并挂起等待唤醒 关闭 关闭操作，调用 close 函数，编译时转换为 runtime.closechan 函数\nclose(ch)\nfunc closechan(c *hchan)\n案例分析：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { // ch 是长度为 4 的带缓冲的 channel // 初始 hchan 结构体重的 buf 为空，sendx 和 recvx 均为 0 ch := make(chan string, 4) fmt.Println(ch, unsafe.Sizeof(ch)) go sendTask(ch) go receiveTask(ch) time.Sleep(1 \\* time.Second) } // G1 是发送者 // 当 G1 向 ch 里发送数据时，首先会对 buf 加锁，然后将 task 存储的数据 copy 到 buf 中，然后 sendx++，然后释放对 buf 的锁 func sendTask(ch chan string) { taskList := []string{\u0026#34;this\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;demo\u0026#34;} for \\_, task := range taskList { ch \u0026lt;- task //发送任务到 channel } } // G2 是接收者 // 当 G2 消费 ch 的时候，会首先对 buf 加锁，然后将 buf 中的数据 copy 到 task 变量对应的内存里，然后 recvx++,并释放锁 func receiveTask(ch chan string) { for { task := \u0026lt;-ch //接收任务 fmt.Println(\u0026#34;received\u0026#34;, task) //处理任务 } } 总结 hchan 结构体的主要组成部分有四个：\n用来保存 goroutine 之间传递数据的循环数组：buf 用来记录此循环数组当前发送或接收数据的下标值：sendx 和 recvx 用于保存向该 chan 发送和从该 chan 接收数据被阻塞的 goroutine 队列： sendq 和 recvq 保证 channel 写入和读取数据时线程安全的锁：lock 2.Go channel有无缓冲的区别 无缓冲：一个送信人去你家送信，你不在家他不走，你一定要接下信，他才会走。\n有缓冲：一个送信人去你家送信，扔到你家的信箱转身就走，除非你的信箱满了，他必须等信箱有多余空间才会走。\n无缓冲 有缓冲 创建方式 make(chan TYPE) make(chan TYPE, SIZE) 发送阻塞 数据接收前发送阻塞 缓冲满时发送阻塞 接收阻塞 数据发送前接收阻塞 缓冲空时接收阻塞 非缓冲 channel\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func loop(ch chan int) { for { select { case i := \u0026lt;-ch: fmt.Println(\u0026#34;this value of unbuffer channel\u0026#34;, i) } } } func main() { ch := make(chan int) ch \u0026lt;- 1 go loop(ch) time.Sleep(1 * time.Millisecond) } 这里会报错 fatal error: all goroutines are asleep - deadlock! 就是因为 ch\u0026lt;-1 发送了，但是同时没有接收者，所以就发生了阻塞\n但如果我们把 ch \u0026lt;- 1 放到 go loop(ch) 下面，程序就会正常运行\n缓冲 channel\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func loop(ch chan int) { for { select { case i := \u0026lt;-ch: fmt.Println(\u0026#34;this value of unbuffer channel\u0026#34;, i) } } } func main() { ch := make(chan int,3) ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 ch \u0026lt;- 4 go loop(ch) time.Sleep(1 * time.Millisecond) } 这里也会报 fatal error: all goroutines are asleep - deadlock! ，这是因为 channel 的大小为 3 ，而我们要往里面塞 4 个数据，所以就会阻塞住，解决的办法有两个:\n把 channel 长度调大一点 把 channel 的信息发送者 ch \u0026lt;- 1 这些代码移动到 go loop(ch) 下面 ，让 channel 实时消费就不会导致阻塞了 4.Go channel为什么是线程安全的？ 为什么设计成线程安全？\n不同协程通过channel进行通信，本身的使用场景就是多线程，为了保证数据的一致性，必须实现线程安全\n如何实现线程安全的？\nchannel的底层实现中，hchan结构体中采用Mutex锁来保证数据读写安全。在对循环数组buf中的数据进行入队和出队操作时，必须先获取互斥锁，才能操作channel数据\n5.Go channel如何控制goroutine并发执行顺序？ 多个goroutine并发执行时，每一个goroutine抢到处理器的时间点不一致，gorouine的执行本身不能保证顺序。即代码中先写的gorouine并不能保证先执行\n思路：使用channel进行通信通知，用channel去传递信息，从而控制并发执行顺序\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var wg sync.WaitGroup func main() { ch1 := make(chan struct{}, 1) ch2 := make(chan struct{}, 1) ch3 := make(chan struct{}, 1) ch1 \u0026lt;- struct{}{} wg.Add(3) start := time.Now().Unix() go print(\u0026#34;gorouine1\u0026#34;, ch1, ch2) go print(\u0026#34;gorouine2\u0026#34;, ch2, ch3) go print(\u0026#34;gorouine3\u0026#34;, ch3, ch1) wg.Wait() end := time.Now().Unix() fmt.Printf(\u0026#34;duration:%d\\n\u0026#34;, end-start) } func print(gorouine string, inputchan chan struct{}, outchan chan struct{}) { // 模拟内部操作耗时 time.Sleep(1 * time.Second) select { case \u0026lt;-inputchan: fmt.Printf(\u0026#34;%s\\n\u0026#34;, gorouine) outchan \u0026lt;- struct{}{} } wg.Done() } 输出： gorouine1 gorouine2 gorouine3 duration:1 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-channel%E7%AF%87/","summary":"1.Go channel 的底层实现原理 概念： Go 中的 channel 是一个队列，遵循先进先出的原则，负责协程之间的通信（Go 语言提倡不要通过共享内存来通信，而要通过通信来实现内存共享，CSP(Communicating Sequential Process)并发模型，就是通过 goroutine 和 channel 来实现的） 使用场景： 停止信号监听 定时任务 生产方和消费方解","title":"Go Channel篇"},{"content":"1. map数据结构 Golang的map使用哈希表作为底层实现，一个哈希表里可以有多个哈希表节点，也即bucket，而每个bucket就保存了map中的一个或一组键值对。\nmap数据结构由runtime/map.go/hmap定义:\n// A header for a Go map. type hmap struct { count int // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。 flags uint8 // 状态标志（是否处于正在写入的状态等） B uint8 // buckets（桶）的对数 // 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶 buckets unsafe.Pointer // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。 oldbuckets unsafe.Pointer // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。 nevacuate uintptr // 表示扩容进度，小于此地址的buckets代表已搬迁完成。 extra *mapextra // 存储溢出桶，这个字段是为了优化GC扫描而设计的 } 2. bucket数据结构 bucket数据结构由runtime/map.go/bmap定义：\ntype bmap struct { tophash [8]uint8 //存储哈希值的高8位 data byte[1] //key value数据:key/key/key/.../value/value/value... overflow *bmap //溢出bucket的地址 } 每个bucket可以存储8个键值对。\ntophash是个长度为8的数组，哈希值相同的键（准确的说是哈希值低位相同的键）存入当前bucket时会将哈希值的高位存储在该数组中，以方便后续匹配。 data区存放的是key-value数据，存放顺序是key/key/key/\u0026hellip;value/value/value，如此存放是为了节省字节对齐带来的空间浪费。 overflow 指针指向的是下一个bucket，据此将所有冲突的键连接起来。 注意：上述中data和overflow并不是在结构体中显示定义的，而是直接通过指针运算进行访问的。 3. 哈希冲突 当有两个或以上数量的键被哈希到了同一个bucket时，我们称这些键发生了冲突。Go使用链地址法来解决键冲突。 由于每个bucket可以存放8个键值对，所以同一个bucket存放超过8个键值对时就会再创建一个键值对，用类似链表的方式将bucket连接起来。\n4. 负载因子 负载因子用于衡量一个哈希表冲突情况，公式为：\n负载因子 = 键数量/bucket数量\n例如，对于一个bucket数量为4，包含4个键值对的哈希表来说，这个哈希表的负载因子为1.\n哈希表需要将负载因子控制在合适的大小，超过其阀值需要进行rehash，也即键值对重新组织：\n哈希因子过小，说明空间利用率低 哈希因子过大，说明冲突严重，存取效率低 每个哈希表的实现对负载因子容忍程度不同，比如Redis实现中负载因子大于1时就会触发rehash，而Go则在在负载因子达到6.5时才会触发rehash，因为Redis的每个bucket只能存1个键值对，而Go的bucket可能存8个键值对，所以Go可以容忍更高的负载因子。\n5. 渐进式扩容 5.1 扩容的前提条件 为了保证访问效率，当新元素将要添加进map时，都会检查是否需要扩容，扩容实际上是以空间换时间的手段。 触发扩容的条件有二个：\n负载因子 \u0026gt; 6.5时，也即平均每个bucket存储的键值对达到6.5个。 overflow数量 \u0026gt; 2^15时，也即overflow数量超过32768时。\n5.2 增量扩容 当负载因子过大时，就新建一个bucket，新的bucket长度是原来的2倍，然后旧bucket数据搬迁到新的bucket。\n考虑到如果map存储了数以亿计的key-value，一次性搬迁将会造成比较大的延时\nGo采用逐步搬迁策略，即每次访问map时都会触发一次搬迁，每次搬迁2个键值对。\n5.3 等量扩容 所谓等量扩容，实际上并不是扩大容量，buckets数量不变，重新做一遍类似增量扩容的搬迁动作，把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。 在极端场景下，比如不断的增删，而键值对正好集中在一小部分的bucket，这样会造成overflow的bucket数量增多，但负载因子又不高，从而无法执行增量搬迁的情况\n6. 查找过程 查找过程如下：\n跟据key值算出哈希值 取哈希值低位与hmpa.B取模确定bucket位置 取哈希值高位在tophash数组中查询 如果tophash[i]中存储值也哈希值相等，则去找到该bucket中的key值进行比较 当前bucket没有找到，则继续从下个overflow的bucket中查找。 如果当前处于搬迁过程，则优先从oldbuckets查找 注：如果查找不到，也不会返回空值，而是返回相应类型的0值。\n7. 插入过程 新员素插入过程如下：\n跟据key值算出哈希值 取哈希值低位与hmap.B取模确定bucket位置 查找该key是否已经存在，如果存在则直接更新值 如果没找到将key，将key插入 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-map%E7%AF%87/","summary":"1. map数据结构 Golang的map使用哈希表作为底层实现，一个哈希表里可以有多个哈希表节点，也即bucket，而每个bucket就保存了map中的一个或一组键值对。 map数据结构由runtime/map.go/hmap定义: // A header for a Go map. type hmap struct { count int // 代表哈希表中的元素个数，调","title":"Go Map篇"},{"content":"Slice实现原理 Slice依托数组实现，底层数组对用户屏蔽，在底层数组容量不足时可以实现自动重分配并生成新的Slice。 接下来按照实际使用场景分别介绍其实现机制。\n3.1 Slice数据结构 源码包中src/runtime/slice.go:slice定义了Slice的数据结构：\ntype slice struct { array unsafe.Pointer len int cap int } 从数据结构看Slice很清晰, array指针指向底层数组，len表示切片长度，cap表示底层数组容量。\n3.2 创建Slice // 初始化方式1：直接声明 var slice1 []int // 初始化方式2：使用字面量 slice2 := []int{1, 2, 3, 4} // 初始化方式3：使用make创建slice slice3 := make([]int, 3, 5) // 初始化方式4: 从切片或数组“截取” slcie4 := arr[1:3] 3.3 Slice 扩容 使用append向Slice追加元素时，如果Slice空间不足，将会触发Slice扩容，扩容实际上是重新配一块更大的内存，将原Slice数据拷贝进新Slice，然后返回新Slice，扩容后再将数据追加进去。\n扩容容量的选择遵循以下规则：\n如果原Slice容量小于1024，则新Slice容量将扩大为原来的2倍； 如果原Slice容量大于等于1024，则新Slice容量将扩大为原来的1.25倍；\n使用append()向Slice添加一个元素的实现步骤如下：\n假如Slice容量够用，则将新元素追加进去，Slice.len++，返回原Slice 原Slice容量不够，则将Slice先扩容，扩容后得到新Slice。将新元素追加进新Slice，Slice.len++，返回新的Slice。 3.5 Slice Copy 使用copy()内置函数拷贝两个切片时，会将源切片的数据逐个拷贝到目的切片指向的数组中，拷贝数量取两个切片长度的最小值。\n例如长度为10的切片拷贝到长度为5的切片时，将会拷贝5个元素。\n也就是说，copy过程中不会发生扩容。\n3.6 特殊切片 跟据数组或切片生成新的切片一般使用slice := array[start:end]方式，这种新生成的切片并没有指定切片的容量，实际上新切片的容量是从start开始直至array的结束。\n比如下面两个切片，长度和容量都是一致的，使用共同的内存地址：\nsliceA := make([]int, 5, 10) sliceB := sliceA[0:5]\n根据数组或切片生成切片还有另一种写法，即切片同时也指定容量，即slice[start:end:cap], 其中cap即为新切片的容量，当然容量不能超过原切片实际值，如下所示：\nsliceA := make([]int, 5, 10) //length = 5; capacity = 10\rsliceB := sliceA[0:5] //length = 5; capacity = 10\rsliceC := sliceA[0:5:5] //length = 5; capacity = 5\r这切片方法不常见，在Golang源码里能够见到，不过非常利于切片的理解。\n编程Tips 创建切片时可跟据实际需要预分配容量，尽量避免追加过程中扩容操作，有利于提升性能； 切片拷贝时需要判断实际拷贝的元素个数 谨慎使用多个切片操作同一个数组，以防读写冲突 Slice总结 每个切片都指向一个底层数组 每个切片都保存了当前切片的长度、底层数组可用容量 使用len()计算切片长度时间复杂度为O(1)，不需要遍历切片 使用cap()计算切片容量时间复杂度为O(1)，不需要遍历切片 通过函数传递切片时，不会拷贝整个切片，因为切片本身只是个结构体而矣 使用append()向切片追加元素时有可能触发扩容，扩容后将会生成新的切片 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go-slice%E7%AF%87/","summary":"Slice实现原理 Slice依托数组实现，底层数组对用户屏蔽，在底层数组容量不足时可以实现自动重分配并生成新的Slice。 接下来按照实际使用场景分别介绍其实现机制。 3.1 Slice数据结构 源码包中src/runtime/slice.go:slice定义了Slice的数据结构： type slice struct {","title":"Go Slice篇"},{"content":"Go 方法与函数的区别？ 在 Go 语言中，有方法（method）和函数（function）两个概念，它们之间有一些重要的区别，主要体现在以下几个方面：\n定义方式：\n函数：函数是一段独立的代码块，它可以在任何地方定义和调用。函数的定义是全局的，可以在不同包中调用。\n方法：方法是与类型（结构体或接口）关联的函数。方法的定义是与类型绑定的，它们通常用于对类型进行操作和处理。通过实例来调用这些方法。\n方法的接收者：\n方法：方法通常有一个接收者（receiver），它指定了方法可以作用于哪种类型。接收者可以是值接收者（value receiver）或指针接收者（pointer receiver）。\n函数：函数没有接收者，它们是独立的代码块，不与特定类型关联。\n下面是一个简单的示例，演示了方法和函数之间的区别：\npackage main import ( \u0026#34;fmt\u0026#34; ) type Rectangle struct { Width float64 Height float64 } // 方法，使用值接收者 func (r Rectangle) Area() float64 { return r.Width * r.Height } // 函数，计算两个数的和 func Add(a, b int) int { return a + b } func main() { r := Rectangle{Width: 5, Height: 3} // 调用方法 area := r.Area() fmt.Println(\u0026#34;面积:\u0026#34;, area) // 调用函数 sum := Add(2, 3) fmt.Println(\u0026#34;和:\u0026#34;, sum) } Go 方法值接收者和指针接收者的区别? 如果方法的接收者是指针类型，无论调用者是对象还是对象指针，修改的都是对象本身，会影响调用者；\n如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者；\npackage main import \u0026#34;fmt\u0026#34; type Person struct { age int } // 如果实现了接收者是指针类型的方法，会隐含地也实现了接收者是值类型的IncrAge1方法。 // 会修改age的值 func (p *Person) IncrAge1() { p.age += 1 } // 如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的IncrAge2方法。 // 不会修改age的值 func (p Person) IncrAge2() { p.age += 1 } // 如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的GetAge方法。 func (p Person) GetAge() int { return p.age } func main() { // p1 是值类型 p := Person{age: 10} // 值类型 调用接收者是指针类型的方法 p.IncrAge1() fmt.Println(p.GetAge()) // 值类型 调用接收者是值类型的方法 p.IncrAge2() fmt.Println(p.GetAge()) // ---------------------- // p2 是指针类型 p2 := \u0026amp;Person{age: 20} // 指针类型 调用接收者是指针类型的方法 p2.IncrAge1() fmt.Println(p2.GetAge()) // 指针类型 调用接收者是值类型的方法 p2.IncrAge2() fmt.Println(p2.GetAge()) } 上述代码中：\n实现了接收者是指针类型的 IncrAge1 函数，不管调用者是值类型还是指针类型，都可以调用IncrAge1方法，并且它的 age 值都改变了。 实现了接收者是指针类型的 IncrAge2 函数，不管调用者是值类型还是指针类型，都可以调用IncrAge2方法，并且它的 age 值都没有被改变。\n通常我们使用指针类型作为方法的接收者的理由：\n使用指针类型能够修改调用者的值。 使用指针类型可以避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做会更加高效。 总结：\n值接收者用于不需要修改原始数据的情况，适用于只读操作。 指针接收者用于需要修改原始数据的情况，适用于读写操作。 选择接收者类型取决于方法的需求，需要考虑是否要修改原始数据以及性能等因素。 Go 函数返回局部变量的指针是否安全? 一般来说，局部变量会在函数返回后被销毁，因此被返回的引用就成为了\u0026quot;无所指\u0026quot;的引用，程序会进入未知状态。\n但这在 Go 中是安全的，Go 编译器将会对每个局部变量进行逃逸分析。如果发现局部变量的作用域超出该函数，则不会将内存分配在栈上，而是分配在堆上，因为他们不在栈区，即使释放函数，其内容也不会受影响。\npackage main import \u0026#34;fmt\u0026#34; func add(x, y int) *int { res := 0 res = x + y return \u0026amp;res } func main() { fmt.Println(add(1, 2)) } 这个例子中，函数 add 局部变量 res 发生了逃逸。res作为返回值，在 main 函数中继续使用，因此 res 指向的内存不能够分配在栈上，随着函数结束而回收，只能分配在堆上。\n编译时可以借助选项 -gcflags=-m，查看变量逃逸的情况\n~/GoTest$ go build -gcflags=-m main.go # command-line-arguments ./main.go:5:6: can inline add ./main.go:12:16: inlining call to add ./main.go:12:12: inlining call to fmt.Println ./main.go:6:1: moved to heap: res ./main.go:12:16: moved to heap: res ./main.go:12:12: []interface {}{...} does not escape \u0026lt;autogenerated\u0026gt;:1: leaking param content: .this res escapes to heap 即表示 res 逃逸到堆上了。\nGo 函数参数传递到底是值传递还是引用传递？ 结论：\nGo语言中所有的传参都是值传递（传值），都是一个副本，一个拷贝。\n参数如果是非引用类型（int、string、struct），这样就在函数中就无法修改原内容数据；如果是引用类型（指针、map、slice、chan），这样就可以修改原内容数据。\n是否可以修改原内容数据，和传值、传引用没有必然的关系。在C++中，传引用肯定是可以修改原内容数据的，在Go语言里,需要看参数是值类型还是引用类型。\n值类型 值类型：值类型的实例在分配给变量、作为函数参数传递或复制时会创建副本。这意味着每个值类型的实例都是独立的，对其进行修改不会影响其他实例。以下是一些常见的值类型：\n基本数据类型：包括整数、浮点数、布尔值和字符串。\n数组（Array）：数组的大小在声明时是固定的，数组是值类型。\n结构体（Struct）：结构体由一组字段组成，是值类型。\n引用类型 引用类型：引用类型的实例在分配给变量、作为函数参数传递或复制时，不会创建副本，而是会共享同一个底层数据。这意味着对引用类型的修改可能会影响其他引用该数据的实例。以下是一些常见的引用类型：\n切片（Slice）：切片是对数组的引用，它可以动态调整大小，并且多个切片可以引用相同的底层数组。\n映射（Map）：映射是一种键值对集合，多个映射可以引用不同数据，但它们可以共享相同的底层数据结构。\n通道（Channel）：通道用于在不同的 Go 协程之间进行通信，多个通道可以引用不同的数据，但它们可以共享相同的通道。\n接口（Interface）：接口类型包含一个具体类型和该类型的值。多个接口可以引用不同类型的数据，但它们可以引用相同类型的值。\n函数（Function）：函数是一种引用类型，可以将函数作为参数传递给其他函数。\n引用类型和引用传递 什么是值传递？\n将实参的值传递给形参，形参是实参的一份拷贝，实参和形参的内存地址不同。函数内对形参值内容的修改，是否会影响实参的值内容，取决于参数是否是引用类型\n什么是引用传递？\n将实参的地址传递给形参，函数内对形参值内容的修改，将会影响实参的值内容。Go语言是没有引用传递的，在C++中，函数参数的传递方式有引用传递。\ndefer 关键字 defer定义的延迟函数参数在defer语句出时就已经确定下来了 defer定义顺序与实际执行顺序相反 return不是原子操作，执行过程是: 保存返回值(若有)\u0026ndash;\u0026gt;执行defer（若有）\u0026ndash;\u0026gt;执行ret跳转 申请资源后立即使用defer关闭资源是好习惯 示例题目 1、\nfunc deferFuncParameter() { var aInt = 1 defer fmt.Println(aInt) aInt = 2 return } 参考答案： 输出1。延迟函数fmt.Println(aInt)的参数在defer语句出现时就已经确定了，所以无论后面如何修改aInt变量都不会影响延迟函数。\n2、\n下面函数输出什么？\nfunc deferFuncReturn() (result int) { i := 1 defer func() { result++ }() return i } 参考答案： 函数输出2。函数的return语句并不是原子的，实际执行分为设置返回值\u0026ndash;\u0026gt;ret，defer语句实际执行在返回前， 即拥有defer的函数返回过程是：设置返回值\u0026ndash;\u0026gt;执行defer\u0026ndash;\u0026gt;ret。 所以return语句先把result设置为i的值，即1，defer语句中又把result递增1，所以最终返回2。\nGo 内置函数make和new的区别？ 首先纠正下make和new是内置函数，不是关键字\n变量初始化，一般包括2步，变量声明 + 变量内存分配，var关键字就是用来声明变量的，new和make函数主要是用来分配内存的\nvar声明值类型的变量时，系统会默认为他分配内存空间，并赋该类型的零值\n比如布尔、数字、字符串、结构体\n如果指针类型或者引用类型的变量，系统不会为它分配内存，默认就是nil。此时如果你想直接使用，那么系统会抛异常，必须进行内存分配后，才能使用。\nnew 和 make 两个内置函数，主要用来分配内存空间，有了内存，变量就能使用了，主要有以下2点区别：\n使用场景区别：\nmake 只能用来分配及初始化类型为 slice、map、chan 的数据。\nnew 可以分配任意类型的数据，并且置零。\n返回值区别：\nmake函数原型如下，返回的是slice、map、chan类型本身 这3种类型是引用类型，就没有必要返回他们的指针\nfunc make(t Type, size ...IntegerType) Type new函数原型如下，返回一个指向该类型内存地址的指针\nfunc new(Type) *Type ","permalink":"https://Bin-lin-rgb.github.io/posts/go/go%E5%9F%BA%E7%A1%80%E7%AF%87/","summary":"Go 方法与函数的区别？ 在 Go 语言中，有方法（method）和函数（function）两个概念，它们之间有一些重要的区别，主要体现在以下几个方面： 定义方式： 函数：函数是一段独立的代码块，它可以在任何地方定义和调用。函数的定义是全局的，可以在不同包中调用。 方法：方法是与类型（结构体或接口","title":"Go 基础篇"},{"content":"前言 今天发现后端使用雪花算法生成的 PostId 传给前端之后，居然不一致！\n导致文章详情页带参数查询为空！\n为啥会这样呢？\n什么是雪花算法？ 雪花算法，Twitter 的分布式自增 ID 算法\nsnowflake 优缺点：\n优点：\n（1）经测试 snowflake 每秒能生成 26 万个自增可排序的 ID。 （2）snowflake 生成的 ID 结果是一个 64bit 大小的整数，转换成字符串后长度最多 19。[注意这里的 19 位数，后面会用] （3）分布式系统内不会产生 ID 碰撞（datacenter 和 workerId 作区分）并且效率高。 缺点：依赖机器时钟，如果机器时钟回拨，会导致 id 重复。由于是部署到分布式环境，每台机器上的时钟不可能完全同步，有时候出现不是全局递增的情况。\nGolang 如何实现？ 这里使用的是 sonyflake 库，基本实现和 snowflake 差不多，不过是配位不太一样，影响不大。\n地址在这里：https://github.com/sony/sonyflake\n具体使用代码：\npackage snowflake import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/sony/sonyflake\u0026#34; ) var ( sonyFlake *sonyflake.Sonyflake\t// 实例 sonyMachineID uint16\t// 机器ID ) func getMachineID() (uint16, error) { // 返回全局定义的机器ID return sonyMachineID, nil } // 需传入当前的机器ID func Init(machineId uint16) (err error) { sonyMachineID = machineId t, _ := time.Parse(\u0026#34;2006-01-02\u0026#34;, \u0026#34;2020-01-01\u0026#34;)\t// 初始化一个开始的时间 settings := sonyflake.Settings{\t// 生成全局配置 StartTime: t, MachineID: getMachineID,\t// 指定机器ID } sonyFlake = sonyflake.NewSonyflake(settings)\t// 用配置生成sonyflake节点 return } // GetID 返回生成的id值 func GetID() (id uint64, err error) {\t// 拿到sonyflake节点生成id值 if sonyFlake == nil { err = fmt.Errorf(\u0026#34;snoy flake not inited\u0026#34;) return } id, err = sonyFlake.NextID() return } func main() { if err := Init(1);err!=nil{ fmt.Printf(\u0026#34;Init failed,err:%v\\n\u0026#34;,err) return } id, _ := GetID() fmt.Println(id) } 如何解决返回前端的 id 不一致？ 看一下哪里不一样：\n139677942874636289 ==\u0026gt; 139677942874636290\n好家伙怎么就差一位数！我当时以为是精度的问题，上网一查发现 Number 精度是 16 位（雪花 ID 是 19 位的），所以是 JS 的 Number 数据类型导致的精度丢失。\n解决方案：后端的 ID(uint64) ==\u0026gt; uint64 转 String ==\u0026gt; 前端使用 String 类型的 ID，这样精度就不会丢失了。那前端再把 String 类型的 19 位数字传回服务端的时候，再转 uint64 。\n总结 提前发现 bug 也是一种好事，哈哈。\n解决方案：前端用 String 类型的 ID，后端及数据库继续使用 uint64 类型不影响数据库查询执行效率。\n","permalink":"https://Bin-lin-rgb.github.io/posts/go/%E9%9B%AA%E8%8A%B1id%E7%94%9F%E6%88%90%E5%89%8D%E5%90%8E%E7%AB%AF%E4%BC%A0%E8%BE%93%E4%B8%8D%E4%B8%80%E8%87%B4/","summary":"前言 今天发现后端使用雪花算法生成的 PostId 传给前端之后，居然不一致！ 导致文章详情页带参数查询为空！ 为啥会这样呢？ 什么是雪花算法？ 雪花算法，Twitter 的分布式自增 ID 算法 snowflake 优缺点： 优点： （1）经测试 snowflake 每秒能生成 26 万个自增可排序的 ID。 （2）snowflake 生成的 ID 结果是一个 64bit 大小的整","title":"雪花id生成，前后端传输不一致"},{"content":"","permalink":"https://Bin-lin-rgb.github.io/posts/basics/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%AF%87/","summary":"","title":"计算机网络之基础篇"},{"content":"数组/字符串 [27. 移除元素] (https://leetcode.cn/problems/remove-element/)\n简单\n给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\n不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。\n元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。\n示例 1：\n输入：nums = [3,2,2,3], val = 3 输出：2, nums = [2,2] 解释：函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 2 ，而 nums = [2,2,3,3] 或 nums = [2,2,0,0]，也会被视作正确答案。 示例 2： 输入：nums = [0,1,2,2,3,0,4,2], val = 2 输出：5, nums = [0,1,4,0,3] 解释：函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。 func removeElement(nums []int, val int) int { left, right := 0, len(nums) for left \u0026lt; right { if nums[left] == val { nums[left] = nums[right-1] right-- } else { left++ } } return left } [26. 删除有序数组中的重复项] (https://leetcode.cn/problems/remove-duplicates-from-sorted-array/)\n给你一个 非严格递增排列 的数组 nums ，请你** 原地** 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。然后返回 nums 中唯一元素的个数。\n考虑 nums 的唯一元素的数量为 k ，你需要做以下事情确保你的题解可以被通过：\n更改数组 nums ，使 nums 的前 k 个元素包含唯一元素，并按照它们最初在 nums 中出现的顺序排列。nums 的其余元素与 nums 的大小不重要。 返回 k 。 示例 1：\n输入：nums = [1,1,2] 输出：2, nums = [1,2,_] 解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。 示例 2：\n输入：nums = [0,0,1,1,1,2,2,3,3,4] 输出：5, nums = [0,1,2,3,4] 解释：函数应该返回新的长度 5 ， 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4 。不需要考虑数组中超出新长度后面的元素。 func removeDuplicates(nums []int) int { n := len(nums) if n \u0026lt; 2 { return n } slow, fast := 0, 0 for i:=0; i\u0026lt;n; i++ { if nums[fast] != nums[slow] { // 遇到不一致的先让慢指针前移后赋值 slow++ nums[slow] = nums[fast] } fast++ } return slow+1 } [88. 合并两个有序数组] (https://leetcode.cn/problems/merge-sorted-array/)\n给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。\n请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。\n**注意：**最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。\n示例 1：\n输入：nums1 = [1,2,3,0,0,0], m = 3, nums2 = [2,5,6], n = 3 输出：[1,2,2,3,5,6] 解释：需要合并 [1,2,3] 和 [2,5,6] 。 合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。 示例 2：\n输入：nums1 = [1], m = 1, nums2 = [], n = 0 输出：[1] 解释：需要合并 [1] 和 [] 。 合并结果是 [1] 。 示例 3：\n输入：nums1 = [0], m = 0, nums2 = [1], n = 1 输出：[1] 解释：需要合并的数组是 [] 和 [1] 。 合并结果是 [1] 。 注意，因为 m = 0 ，所以 nums1 中没有元素。nums1 中仅存的 0 仅仅是为了确保合并结果可以顺利存放到 nums1 中。 func merge(nums1 []int, m int, nums2 []int, n int) { for p1, p2, tail := m-1, n-1, m+n-1; p1 \u0026gt;= 0 || p2 \u0026gt;= 0; tail-- { var cur int if p1 == -1 { cur = nums2[p2] p2-- } else if p2 == -1 { cur = nums1[p1] p1-- } else if nums1[p1] \u0026gt; nums2[p2] { cur = nums1[p1] p1-- } else { cur = nums2[p2] p2-- } nums1[tail] = cur } } [125. 验证回文串] (https://leetcode.cn/problems/valid-palindrome/)\n如果在将所有大写字符转换为小写字符、并移除所有非字母数字字符之后，短语正着读和反着读都一样。则可以认为该短语是一个 回文串 。\n字母和数字都属于字母数字字符。\n给你一个字符串 s，如果它是 回文串 ，返回 true ；否则，返回 false 。\n示例 1：\n输入: s = \u0026#34;A man, a plan, a canal: Panama\u0026#34; 输出：true 解释：\u0026#34;amanaplanacanalpanama\u0026#34; 是回文串。 示例 2：\n输入：s = \u0026#34;race a car\u0026#34; 输出：false 解释：\u0026#34;raceacar\u0026#34; 不是回文串。 func isPalindrome(s string) bool { var sgood string for i := 0; i \u0026lt; len(s); i++ { if isalnum(s[i]) { sgood += string(s[i]) } } n := len(sgood) sgood = strings.ToLower(sgood) for i := 0; i \u0026lt; n/2; i++ { if sgood[i] != sgood[n-1-i] { return false } } return true } func isalnum(ch byte) bool { return (ch \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; ch \u0026lt;= \u0026#39;Z\u0026#39;) || (ch \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; ch \u0026lt;= \u0026#39;z\u0026#39;) || (ch \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; ch \u0026lt;= \u0026#39;9\u0026#39;) } 双指针 [392. 判断子序列] (https://leetcode.cn/problems/is-subsequence/)\n给定字符串 s 和 t ，判断 s 是否为 t 的子序列。\n字符串的一个子序列是原始字符串删除一些（也可以不删除）字符而不改变剩余字符相对位置形成的新字符串。（例如，\u0026quot;ace\u0026quot;是\u0026quot;abcde\u0026quot;的一个子序列，而\u0026quot;aec\u0026quot;不是）。\n示例 1：\n输入：s = \u0026#34;abc\u0026#34;, t = \u0026#34;ahbgdc\u0026#34; 输出：true 示例 2：\n输入：s = \u0026#34;axc\u0026#34;, t = \u0026#34;ahbgdc\u0026#34; 输出：false func isSubsequence(s string, t string) bool { n, m := len(s), len(t) i, j := 0, 0 for i \u0026lt; n \u0026amp;\u0026amp; j \u0026lt; m { if s[i] == t[j] { i++ } j++ } return i == n } 区间 [56. 合并区间] (https://leetcode.cn/problems/merge-intervals/)\n以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。\n示例 1：\n输入：intervals = [[1,3],[2,6],[8,10],[15,18]] 输出：[[1,6],[8,10],[15,18]] 解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 示例 2：\n输入：intervals = [[1,4],[4,5]] 输出：[[1,5]] 解释：区间 [1,4] 和 [4,5] 可被视为重叠区间。 func merge(intervals [][]int) (ans [][]int) { // 先根据每个区间的起始值进行排序 sort.Slice(intervals, func(i, j int) bool { return intervals[i][0] \u0026lt; intervals[j][0] }) // 初始化答案切片，并将第一个区间加入 ans = append(ans, intervals[0]) // 遍历每个区间，合并重叠的区间 for _, e := range intervals[1:] { if ans[len(ans)-1][1] \u0026lt; e[0] { // 如果当前区间的起始值大于答案切片中最后一个区间的结束值，说明它们不重叠 // 直接将当前区间加入答案切片 ans = append(ans, e) } else { // 如果当前区间和答案切片中最后一个区间重叠 // 更新答案切片中最后一个区间的结束值，取两者中的较大值 ans[len(ans)-1][1] = max(ans[len(ans)-1][1], e[1]) } } return } func max(a, b int) int { if a \u0026gt; b { return a } return b } 排序 快速排序 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; ) func main() { nums := []int{1, 2, 4, 2, 5, 6, 9, 90, 3} fmt.Println(nums) fmt.Println(sortArray(nums)) } func sortArray(nums []int) []int { quick(nums, 0, len(nums)-1) return nums } func quick(arr []int, i, j int) { if i \u0026gt;= j { return } mid := partition(arr, i, j) quick(arr, i, mid-1) quick(arr, mid+1, j) } func partition(nums []int, i int, j int) int { p := rand.Intn(j-i+1) + i // 随机选取“支点” nums[i], nums[p] = nums[p], nums[i] for i \u0026lt; j { for nums[i] \u0026lt; nums[j] \u0026amp;\u0026amp; i \u0026lt; j { j-- } if i \u0026lt; j { nums[i], nums[j] = nums[j], nums[i] i++ } for nums[i] \u0026lt; nums[j] \u0026amp;\u0026amp; i \u0026lt; j { i++ } if i \u0026lt; j { nums[i], nums[j] = nums[j], nums[i] j-- } } return i } ","permalink":"https://Bin-lin-rgb.github.io/posts/leetcode/top150/","summary":"数组/字符串 [27. 移除元素] (https://leetcode.cn/problems/remove-element/) 简单 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。 不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。 元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 示例 1： 输入：nums = [3,2,2,3], val = 3","title":"Top150"},{"content":"Docker 为什么使用Docker\n企业环境中存在的某个痛点 企业使用一项技术是为了解决当前企业环境中存在的某个痛点。\n目前整个软件行业存在着以下几个痛点。\n1.软件更新发布及部署低效，过程烦琐且需要人工介入。\n2.环境一致性难以保证。\n3.不同环境之间迁移成本太高。\nDocker能解决的问题 首先，Docker的使用十分简单，\n从开发的角度来看就是“三步走\u0026quot;：构建、运输、运行。\n其中，关键步骤是构建环节，即打包镜像文件。\n但是从测试和运维的角度来看，那就只有两步：复制、运行。\n有了这个镜像文件，想复制到哪里运行都可以，完全和平台无关。\nDocker这种容器技术隔离出了独立的运行空间，不会和其他应用争用系统资源，不需要考虑应用之间的相互影响。\n其次，因为在构建镜像时就处理完了服务程序对于系统的所有依赖，所以在使用时，可以忽略原本程序的依赖以及开发语言。对测试和运维人员而言，可以更专注于自己的业务内容。\n最后，Docker为开发者提供了一种开发环境的管理办法，帮助测试人员保证环境的同步，为运维人员提供了可移植的标准化部署流程。\n类 \u0026ndash;\u0026gt; 对象\n镜像 \u0026ndash;\u0026gt; 容器\n安装 centos uname -r yum update yum makecache fast yum install docker-ce docker version systemctl status docker systemctl start docker // 测试 docker pull hello-world docker run hello-world Ubuntu curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 常用命令 https://www.bilibili.com/video/BV1gr4y1U7CY?p=18\u0026amp;spm_id_from=pageDriver\u0026amp;vd_source=6168fe2db91f9a8c4c41d41f39d1703e\n启动docker:\tsystemctl start docker 停止docker:\tsystemctl stop docker 重启docker:\tsystemctl restart docker 查看docker状态:\tsystemctl status docker 开机启动:\tsystemctl enable docker 查看docker概要信息:\tdocker info 查看docker 总体帮助文档:\tdocker-help 查看docker 命令帮助文档:\tdocker具体命令-help docker 中央仓库 存放镜像的网站\n官网：https://hub.docker.com/\ndaocloud：http://hub.daocloud.io/\ndocker 镜像操作 拉取到本地 docker pull daocloud.io/library/tomcat:8.0.45 查看本地所有镜像 docker images 删除 // 查看正在运行的 docker ps -a docker rm a66\u0026lt;id前几位\u0026gt; docker rmi 镜像标识\u0026lt;id前几位\u0026gt; 镜像导出导入 docker save -o 路径 镜像id\u0026lt;前两位即可\u0026gt; docker load -i 镜像文件 修改镜像名称 docker tag 镜像id 新镜像名称:版本 docker tag fa tomcat:8.0 docker 容器操作 1、运行容器 基本操作\ndocker run 镜像的标识镜像名称[:tag] 常用的参数\ndocker run -d -p 宿主机端口:容器端口 --name 容器名称 镜像的标识镜像名称[:tag] docker run -d -p 8080:8080 --name tomcat fa 跑起来后直接访问即可 -d: 代表后台运行容器 -p 宿主机端口：容器端口：为了映射当前Liux的端口和容器的端口 \u0026ndash;name 容器名称：指定容器的名称 2、查看正在运行的容器 docker ps [-qa] -a：查看全部的容器，包括没有运行 -q：只查看容器得到标识 3、查看容器的日志 docker logs -f 容器id [root@localhost linbin]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS b01afd80c224 fa \u0026#34;catalina.sh run\u0026#34; 5 minutes ago Up 5 minutes [root@localhost linbin]# docker logs -f b0 08-Sep-2022 00:49:48.918 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.0.45 08-Sep-2022 00:49:48.921 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Jun 26 2017 20:06:07 UTC 8.0.45.0 08-Sep-2022 00:49:48.921 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux 4、进入到容器内部 docker exec -it 容器id bash [root@localhost linbin]# docker exec -it b0 bash root@b01afd80c224:/usr/local/tomcat# pwd /usr/local/tomcat root@b01afd80c224:/usr/local/tomcat# ls LICENSE NOTICE RELEASE-NOTES\tRUNNING.txt bin conf\tinclude lib logs native-jni-lib temp webapps work root@b01afd80c224:/usr/local/tomcat# cd webapps root@b01afd80c224:/usr/local/tomcat/webapps# ls ROOT docs examples host-manager manager root@b01afd80c224:/usr/local/tomcat/webapps# exit exit 5、删除容器 (删除容器前，需要先停止容器)\n#停止指定的容器 docker stop 容器id #停止全部容器 docker stop $(docker ps -qa) #删除指定容器 docker rm 容器id #删除全部容器 docker rm $(docker ps -qa) #启动容器 docker start 容器id 创建 mysql 容器 创建MySQL镜像\ndocker pull daocloud.io/library/mysq1:5.7.5-m15 查看MySQL镜像\ndocker images 创建MySQL容器\ndocker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root --name msyql 镜像tag eg： docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=Admin666 --name mysql 644 然后使用连接工具 Navicat 测试。\n坑1\u0026ndash;中文字符 查看里面的字符集，好家伙，Latin1\nmysql\u0026gt; SHOW VARIABLES LIKE \u0026#39;character%\u0026#39;; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | latin1 | | character_set_connection | latin1 | | character_set_database | utf8 | | character_set_filesystem | binary | | character_set_results | latin1 | | character_set_server | latin1 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.00 sec) 关键点2\u0026ndash;开启数据卷 删除容器后，里面的mysql数据如何办 容器实例一删除，啥数据也没了！\n解决办法 1、新增数据卷\ndocker run -d -p 3306:3306 --privileged=true -v /zzyyuse/mysql/log:/var/log/mysql -v /zzyyuse/mysql/data:/var/lib/mysql -v /zzyyuse/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:5.7 2、/zzyyuse/mysql/conf 下新增 my.cnf\n[client] default_character_set=utf8 [mysqld] collation_server = utf8_general_ci character_set_server = utf8 然后restart一下\n之前的DB 无效\n修改字符集操作+重启mysql容器实例\n之后的DB 有效，需要新建\n结论：docker安装完MySQL并run出容器后，建议请先修改完字符集编码后再新建mysql库-表-插数据\n将项目部署到Tomcat 上传项目 上传项目\n进入容器目录 docker exec -it 容器tag bash\n将项目拷贝到tomcat:容器的webapps目录下面 docker cp demo a17:/usr/local/tomcat/webapps\n查看tomcat运行日志 docker logs -f 容器tag\ndocker 数据卷 为了部署我们的demo工程，需要使用到 cp 的命令将宿主机内的 demo文件复制到容器内部\n数据卷：将宿主机的一个目录，映射到容器的一个目录中，可以在宿主机中操作目录中的内容，那么容器内部映射的文件，也会跟着一起改变。\n在挂载目录后多加一个参数 --privileged=true\n1.创建数据卷 docker volume create 数据卷名称 #创建数据卷之后，默认会存放在一个目录下/var/Tb/docker/volumes./数据卷名称/_data 2.查看数据卷的详细信息 docker volume inspect 数据卷名称 3.查看全部数据卷 docker volume ls 4.删除数据卷 docker volume rm 数据卷名称 5.应用数据卷 当你映射数据卷时，如果数据卷不存在。Docker会帮你自动创建，会将容器内部自带的文件，存储在默认的存放路径中。\ndocker run -v 数据卷名称:容器内部的路径镜像id #直接指定一个路径作为数据卷的存放位置。这个路径下是空的。 docker run -V 宿主机路径:容器内部的路径 镜像id docker run -d -p 8080:8080 -v /home/tomcat_webapps:/usr/local/tomcat/webapps/ --name tomcat fa6 测试 docker run -d --privileged=true -v /tmp/host_data/:/tmp/docker_data/ --name u1 ubuntu [root@iZwz982ksp86xdjeeirtsdZ tmp]# cd /tmp/host_data/ [root@iZwz982ksp86xdjeeirtsdZ host_data]# touch test.txt [root@iZwz982ksp86xdjeeirtsdZ host_data]# ls test.txt [root@iZwz982ksp86xdjeeirtsdZ host_data]# docker exec -it afb bash root@afb5e67ee3d4:/# cd /tmp/docker_data/ root@afb5e67ee3d4:/tmp/docker_data# ls test.txt root@afb5e67ee3d4:/tmp/docker_data# 查看是否挂载成功\n[root@iZwz982ksp86xdjeeirtsdZ host_data]# docker inspect af \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;bind\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/tmp/host_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/tmp/docker_data\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;rprivate\u0026#34; } ], 如果 docker stop 了，然后在宿主机绑定的目录新增了一个文件，然后在 start 一下，发现会同步过来。\n是共享的意思。\n只读 上面默认rw\ndocker run -it -privileged=true -v /宿主机绝对路径目录:/容器内目录:ro 镜像名 /容器目录:ro 镜像名 就能完成功能，此时容器自己只能读取不能写\nro = read only\n此时如果宿主机写入内容，可以同步给容器内，容器可以读取到。\n继承 容器1完成和宿主机的映射 容器2继承容器1的卷规则 一\ndocker run -it --privileged=true --volumes-from 父亲 --name u2 ubuntu Dockerfile 什么是Dockerfile? DockerFile详解\nDockerfile是一个包含用于组合映像的命令的文本文档。可以使用在命令行中调用的任何命令。\nDocker通过读取Dockerfile中的指令自动生成映像。\ndocker build 命令用于从 Dockerfile 构建映像。\n可以在docker buiId命令中使用-f标志指向文件系统中任何位置的Dockerfile。\n例：\ndocker build -f /path/to/a/Dockerfile Dockerfile的基本结构 Dockerfile一般分为四部分：\n1.基础镜像信息\n2.维护者信息\n3.镜像操作指令\n4.容器启动时执行指令\nDockerfile文件说明 Docker以从上到下的顺序运行 Dockerfile 的指令。为了指定基本映像，第一条指令必须是FROM。一个声明以#字符开头则被视为注释。可以在Docker文件中使用RUN,CMD,FROM,EXPOSE,ENV等指令。\n在这里列出了一些堂用的指令.\n指令 FROM 指定基础镜像，必须为第一个命令\n格式： FROM \u0026lt;image\u0026gt; FROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; FROM \u0026lt;image\u0026gt;@\u0026lt;digest\u0026gt; 示例： FROM mysq1:5.6 注：tag或digest是可选的，如果不使用这两个值时，会使用jlatest版本的基础镜像\nMAINTAINER 维护者信息\n格式： MAINTAINER \u0026lt;name\u0026gt; 示例： MAINTAINER Jasper Xu MAINTAINER sorex@163.com MAINTAINER Jasper Xu \u0026lt;sorex@163.com\u0026gt; RUN 构建镜像时执行的命令\nRUN用于在镜像容器中执行命令，其有以下两种命令执行方式： shell执行 格式： RUN \u0026lt;command\u0026gt; exec执行 格式： RUN [\u0026#34;executable\u0026#34;,\u0026#34;paraml\u0026#34;,\u0026#34;param2\u0026#34;] 示例： RUN [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] RUN apk update RUN [\u0026#34;/etc/execfile\u0026#34;,\u0026#34;arg1\u0026#34;,\u0026#34;arg1\u0026#34;] 注：RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定\u0026ndash;no-cache参数，如：docker build \u0026ndash;no-cache\nADD ADD 指令和 COPY 的使用格类似（同样需求下，官方推荐使用 COPY）。功能也类似，不同之处如下：\nADD 的优点：在执行 \u0026lt;源文件\u0026gt; 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会自动复制并解压到 \u0026lt;目标路径\u0026gt;。 ADD 的缺点：在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。 格式： ADD \u0026lt;src\u0026gt;...\u0026lt;dest\u0026gt; ADD[\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,...\u0026#34;\u0026lt;dest\u0026gt;\u0026#34; 用于支持包含空格的路径 示例： ADD hom* /mydir/\t#添加所有以\u0026#34;hom\u0026#34;开头的文件 ADD hom?.txt /mydir/\t#?替代一个单字符，例如：\u0026#34;home.txt\u0026#34; ADD test relativeDir/\t#添加\u0026#34;test\u0026#34;到`WORKDIR`/relativeDir/ ADD test /absoluteDir/\t#添加\u0026#34;test\u0026#34;到/absoluteDir/ CMD 类似于 RUN 指令，用于运行程序，但二者运行的时间点不同:\nCMD 在docker run 时运行。 RUN 是在 docker build。 作用：为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。\n注意：如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。\n格式：\nCMD \u0026lt;shell 命令\u0026gt; CMD [\u0026#34;\u0026lt;可执行文件或命令\u0026gt;\u0026#34;,\u0026#34;\u0026lt;param1\u0026gt;\u0026#34;,\u0026#34;\u0026lt;param2\u0026gt;\u0026#34;,...] CMD [\u0026#34;\u0026lt;param1\u0026gt;\u0026#34;,\u0026#34;\u0026lt;param2\u0026gt;\u0026#34;,...] # 该写法是为 ENTRYPOINT 指令指定的程序提供默认参数 推荐使用第二种格式，执行过程比较明确。第一种格式实际上在运行的过程中也会自动转换成第二种格式运行，并且默认可执行文件是 sh。\nCOPY 复制指令，从上下文目录中复制文件或者目录到容器里指定路径。\n格式：\nCOPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] \u0026lt;源路径1\u0026gt;... \u0026lt;目标路径\u0026gt; COPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] [\u0026#34;\u0026lt;源路径1\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;目标路径\u0026gt;\u0026#34;] [\u0026ndash;chown=:]：可选参数，用户改变复制到容器内文件的拥有者和属组。\n\u0026lt;源路径\u0026gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如：\nCOPY hom* /mydir/ COPY hom?.txt /mydir/ \u0026lt;目标路径\u0026gt;：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。\nFROM centos # 添加文件到目录下 COPY test.txt /mydir/ # 将文件内容写入 mytest COPY test.txt /mytest # 压缩文件,自动解压 COPY jmeter.log.zip /myzipdir/ # 添加目录 COPY TeamFile / # 其他文件 COPY jmeter.log /mydir/ # 多个文件 COPY test1.txt test2.txt /mydir/ # 通配符,dest 不存在自动创建 COPY test*.txt /mydir/test/ # 特殊字符串 COPY COPY[[]0].txt /mydir/ WORKDIR /data # 相对路径 COPY test.txt test/ VOLUME 定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷。\n作用：\n避免重要的数据，因容器重启而丢失，这是非常致命的。 避免容器不断变大。 格式：\nVOLUME [\u0026#34;\u0026lt;路径1\u0026gt;\u0026#34;, \u0026#34;\u0026lt;路径2\u0026gt;\u0026#34;...] VOLUME \u0026lt;路径\u0026gt; 尚 docker 自定义镜像 自定义镜像\ndocker-compose 需求\n之前运行一个镜像，需要添加大量的参数。\n可以通过Docker-Compose编写这些参数。\nDocker-Compose可以帮助我们批量的管理容器。\n只需要通过一个docker-compose.yml文件去维护即可。\n下载安装\n1.去github官网搜索docker-compose,下载Docker-Compose\ndocker-compose-Linux-x86_64\n2.将下载好的文件，拖拽到Liux操作系统中\n3.需要将DockerCompose文件的名称修改一下，基于DockerCompose文件一个可执行的权限\n[root@localhost compose]# mv docker-compose-linux-x86_64 docker-compose [root@localhost compose]# mv docker-compose /usr/local/bin //放到路径中 [root@localhost compose]# cd /usr/local/bin [root@localhost bin]# ls docker-compose [root@localhost bin]# chmod 777 docker-compose //可执行权限 [root@localhost bin]# ls -al total 3000 drwxr-xr-x. 2 root root 28 Sep 7 23:23 . drwxr-xr-x. 12 root root 131 Aug 14 01:15 .. -rwxrwxrwx. 1 linbin linbin 3072000 Sep 7 23:19 docker-compose [root@localhost bin]# 4.方便后期操作，配置一个环境变量，让在其他目录也可以执行\nvi /etc/profile yml 文件 Jenkins gitlab Jenkins sh docker stop jenkins \u0026gt; /dev/null 2\u0026gt; /dev/null || : docker container rm jenkins \u0026gt; /dev/null 2\u0026gt; /dev/null || : docker run \\ --name jenkins \\ -d \\ -p 8080:8080 \\ -p 50000:50000 \\ -v jenkins_home:/var/jenkins_home:z \\ --env=\u0026#34;JENKINS_OPTS=--prefix=/jenkins\u0026#34; \\ -v deploy:/var/deploy:z \\ --network bridge \\ jenkins:1.0 gitlab sh docker pull gitlab/gitlab-ce:15.4.0-ce.0\ndocker stop gitlab \u0026gt; /dev/null 2\u0026gt; /dev/null || : docker container rm gitlab \u0026gt; /dev/null 2\u0026gt; /dev/null || : docker run -d \\ --name gitlab \\ --hostname my-gitlab \\ --publish 19080:80 --publish 19022:22 \\ --restart always \\ --volume /gitLabs/config:/etc/gitlab:Z \\ --volume /gitLabs/logs:/var/log/gitlab:Z \\ --volume /gitLabs/data:/var/opt/gitlab:Z \\ gitlab/gitlab-ce:15.4.0-ce.0 https://www.cnblogs.com/diaomina/p/12830449.html\n修改 hostname\nvi /opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml Windows 编译后部署 [juejin] server windows 编译\n// 注意 --\u0026gt; 使用 cmd 而不是 powershell SET GOOS=linux SET GOARCH=amd64 go build ./main.go 将编译形成的二进制文件\ndockerfile\nFROM alpine:latest RUN mkdir \u0026#34;/app\u0026#34; RUN mkdir \u0026#34;/app/config\u0026#34; WORKDIR \u0026#34;/app\u0026#34; COPY main /app/ COPY config.ini /app/config/ ENTRYPOINT [\u0026#34;./main\u0026#34;] 在 Linux 下的 docker 打包构建镜像\nsudo docker image build --platform linux/amd64 -t juejin_blog:v2.2 . docker image ls sudo docker run -it -p 9000:9000 juejin_blog:v2.2 nginx docker pull nginx ;新建目录结构：nginx文件夹下新建conf.d文件夹，html文件夹 /docker |---juejin |----nginx |----conf.d |----html default.conf\nserver { listen 80; server_name 49.109.50.48; location / { root /usr/share/nginx/html; try_files $uri $uri/ /index.html; index index.html index.htm; } location /api/ { proxy_pass http://49.109.50.48:9000; proxy_redirect default; rewrite ^/api/(.*) /$1 break; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } run.sh\nsudo docker run -d -p 80:80 \\ --name nginx_v1.3 \\ -v /docker/juejin/nginx/conf.d:/etc/nginx/conf.d \\ -v /docker/juejin/nginx/html/dist:/usr/share/nginx/html \\ nginx:latest 先用 builder 构建再 run [sms] go dockerfile FROM golang:alpine as builder ENV GOPROXY=https://goproxy.cn,direct WORKDIR /home COPY . . RUN go mod tidy RUN go build -o sms main.go FROM alpine as runner ENV WORKDIR=/home WORKDIR $WORKDIR RUN apk add tzdata --no-cache \\ \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ \u0026amp;\u0026amp; echo \u0026#34;Asia/Shanghai\u0026#34; \u0026gt; /etc/timezone \\ \u0026amp;\u0026amp; apk del tzdata COPY --from=builder $WORKDIR/sms $WORKDIR CMD [\u0026#34;./sms\u0026#34;] nginx dockerfile └─frontend ├─conf.d └─html └─dist └─assets nginx.conf\nserver { listen 80; server_name 43.139.40.48; location / { root /usr/share/nginx/html; try_files $uri $uri/ /index.html; index index.html index.htm; } location /api/ { proxy_pass http://43.139.40.48:8082; proxy_redirect default; rewrite ^/api/(.*) /$1 break; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } # 使用 Nginx 作为基础镜像 FROM nginx:alpine # 将构建好的前端应用静态文件复制到 Nginx 的 HTML 目录 COPY ./html /usr/share/nginx/html COPY ./conf.d /etc/nginx/conf.d # 暴露端口，如果需要的话 EXPOSE 80 # Nginx 会自动启动，无需手动启动 Nginx 服务 docker-compose version: \u0026#39;3\u0026#39; services: backend: build: context: ./sms-backend dockerfile: ./Dockerfile image: smsbackend container_name: \u0026#34;smsbackend_container\u0026#34; ports: - \u0026#34;8082:8080\u0026#34; environment: - PG_USER=postgres - PG_PASSWORD=admin666 - PG_DBNAME=sms - PG_SSLMODE=disable - PG_HOST=43.139.40.48 - PG_PORT=5432 nginx: build: context: ./sms-frontend dockerfile: ./Dockerfile image: nginx:sms container_name: \u0026#34;smsnginx_container\u0026#34; ports: - \u0026#34;17000:80\u0026#34; - \u0026#34;443:443\u0026#34; volumes: - /sms-frontend/conf.d:/etc/nginx/conf.d - /sms-frontend/html:/usr/share/nginx/html restart: always other WSL2 Ubuntu22.04 安装 Docker ，发现 daemon 启动失败 root@LAPTOP-O0KBCH8Q:~# service docker start * Starting Docker: docker [ OK ] root@LAPTOP-O0KBCH8Q:~# docker version Client: Docker Engine - Community Version: 20.10.18 API version: 1.41 Go version: go1.18.6 Git commit: b40c2f6 Built: Thu Sep 8 23:11:43 2022 OS/Arch: linux/amd64 Context: default Experimental: true Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? root@LAPTOP-O0KBCH8Q:~# sudo systemctl enable docker Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install. Executing: /lib/systemd/systemd-sysv-install enable docker root@LAPTOP-O0KBCH8Q:~# /lib/systemd/systemd-sysv-install enable docker root@LAPTOP-O0KBCH8Q:~# dockerd \u0026amp; failed to start daemon: Error initializing network controller: error obtaining controller instance: unable to add return rule in DOCKER-ISOLATION-STAGE-1 chain: (iptables failed: iptables --wait -A DOCKER-ISOLATION-STAGE-1 -j RETURN: iptables v1.8.7 (nf_tables): RULE_APPEND failed (No such file or directory): rule in chain DOCKER-ISOLATION-STAGE-1 (exit status 4)) [1]+ Exit 1 dockerd root@LAPTOP-O0KBCH8Q:~# iptables -L -t nat # Warning: iptables-legacy tables present, use iptables-legacy to see them Chain PREROUTING (policy ACCEPT) target prot opt source destination Chain INPUT (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination Chain POSTROUTING (policy ACCEPT) target prot opt source destination Chain DOCKER (0 references) target prot opt source destination root@LAPTOP-O0KBCH8Q:~# sudo update-alternatives --config iptables There are 2 choices for the alternative iptables (providing /usr/sbin/iptables). Selection Path Priority Status ------------------------------------------------------------ * 0 /usr/sbin/iptables-nft 20 auto mode 1 /usr/sbin/iptables-legacy 10 manual mode 2 /usr/sbin/iptables-nft 20 manual mode Press \u0026lt;enter\u0026gt; to keep the current choice[*], or type selection number: 1 update-alternatives: using /usr/sbin/iptables-legacy to provide /usr/sbin/iptables (iptables) in manual mode root@LAPTOP-O0KBCH8Q:~# service docker start * Starting Docker: docker [ OK ] root@LAPTOP-O0KBCH8Q:~# service docker status * Docker is running root@LAPTOP-O0KBCH8Q:~# docker pull hello-world Using default tag: latest latest: Pulling from library/hello-world 2db29710123e: Pull complete Digest: sha256:62af9efd515a25f84961b70f973a798d2eca956b1b2b026d0a4a63a3b0b6a3f2 Status: Downloaded newer image for hello-world:latest docker.io/library/hello-world:latest root@LAPTOP-O0KBCH8Q:~# docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ docker: Error response from daemon: network qnear not found. 改成 bridge 。\n","permalink":"https://Bin-lin-rgb.github.io/posts/deploy/docker/","summary":"Docker 为什么使用Docker 企业环境中存在的某个痛点 企业使用一项技术是为了解决当前企业环境中存在的某个痛点。 目前整个软件行业存在着以下几个痛点。 1.软件更新发布及部署低效，过程烦琐且需要人工介入。 2.环境一致性难以保证。 3.不同环境之间迁移成本太高。 Docker能解决的问题 首先，Do","title":"Docker 基础"},{"content":"1. 介绍 scan命令的作用和keys *的作用类似，主要用于查找redis中的键，但是在正式的生产环境中一般不会直接使用keys *这个命令，因为他会返回所有的键，如果键的数量很多会导致查询时间很长，进而导致服务器阻塞，所以需要scan来进行更细致的查找\nscan总共有这几种命令：scan、sscan、hscan、zscan，分别用于迭代数据库中的：数据库中所有键、集合键、哈希键、有序集合键，命令具体结构如下：\nscan cursor [MATCH pattern] [COUNT count] [TYPE type] sscan key cursor [MATCH pattern] [COUNT count] hscan key cursor [MATCH pattern] [COUNT count] zscan key cursor [MATCH pattern] [COUNT count] 2. scan scan cursor [MATCH pattern] [COUNT count] [TYPE type]，cursor表示游标，指查询开始的位置，count默认为10，查询完后会返回下一个开始的游标，当返回0的时候表示所有键查询完了\n127.0.0.1:6379[2]\u0026gt; scan 0 1) \u0026#34;3\u0026#34; 2) 1) \u0026#34;mystring\u0026#34; 2) \u0026#34;myzadd\u0026#34; 3) \u0026#34;myhset\u0026#34; 4) \u0026#34;mylist\u0026#34; 5) \u0026#34;myset2\u0026#34; 6) \u0026#34;myset1\u0026#34; 7) \u0026#34;mystring1\u0026#34; 8) \u0026#34;mystring3\u0026#34; 9) \u0026#34;mystring4\u0026#34; 10) \u0026#34;myset\u0026#34; 127.0.0.1:6379[2]\u0026gt; scan 3 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;myzadd1\u0026#34; 2) \u0026#34;mystring2\u0026#34; 3) \u0026#34;mylist2\u0026#34; 4) \u0026#34;myhset1\u0026#34; 5) \u0026#34;mylist1\u0026#34; MATCH可以采用模糊匹配找出自己想要查找的键，这里的逻辑是先查出20个，再匹配，而不是先匹配再查询，这里加上count 20是因为默认查出的10个数中可能不能包含所有的相关项，所以把范围扩大到查20个，我这里测试的键总共有15个\n127.0.0.1:6379[2]\u0026gt; scan 0 match mylist* count 20 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;mylist\u0026#34; 2) \u0026#34;mylist2\u0026#34; 3) \u0026#34;mylist1\u0026#34; TYPE可以根据具体的结构类型来匹配该类型的键\n127.0.0.1:6379[2]\u0026gt; scan 0 count 20 type list 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;mylist\u0026#34; 2) \u0026#34;mylist2\u0026#34; 3) \u0026#34;mylist1\u0026#34; 3. sscan sscan key cursor [MATCH pattern] [COUNT count]，sscan的第一个参数总是集合类型的key\n127.0.0.1:6379[2]\u0026gt; sadd myset1 a b c d (integer) 4 127.0.0.1:6379[2]\u0026gt; smembers myset1 1) \u0026#34;d\u0026#34; 2) \u0026#34;a\u0026#34; 3) \u0026#34;c\u0026#34; 4) \u0026#34;b\u0026#34; 127.0.0.1:6379[2]\u0026gt; sscan myset1 0 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;d\u0026#34; 2) \u0026#34;c\u0026#34; 3) \u0026#34;b\u0026#34; 4) \u0026#34;a\u0026#34; 127.0.0.1:6379[2]\u0026gt; sscan myset1 0 match a 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;a\u0026#34; 4. hscan hscan key cursor [MATCH pattern] [COUNT count]，sscan的第一个参数总是哈希类型的key\n127.0.0.1:6379[2]\u0026gt; hset myhset1 kk1 vv1 kk2 vv2 kk3 vv3 (integer) 3 127.0.0.1:6379[2]\u0026gt; hgetall myhset1 1) \u0026#34;kk1\u0026#34; 2) \u0026#34;vv1\u0026#34; 3) \u0026#34;kk2\u0026#34; 4) \u0026#34;vv2\u0026#34; 5) \u0026#34;kk3\u0026#34; 6) \u0026#34;vv3\u0026#34; 127.0.0.1:6379[2]\u0026gt; hscan myhset1 0 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;kk1\u0026#34; 2) \u0026#34;vv1\u0026#34; 3) \u0026#34;kk2\u0026#34; 4) \u0026#34;vv2\u0026#34; 5) \u0026#34;kk3\u0026#34; 6) \u0026#34;vv3\u0026#34; 5. zscan zscan key cursor [MATCH pattern] [COUNT count]，sscan的第一个参数总是有序集合类型的key\n127.0.0.1:6379[2]\u0026gt; zadd myzadd1 1 zz1 2 zz2 3 zz3 (integer) 3 127.0.0.1:6379[2]\u0026gt; zrange myzadd1 0 -1 withscores 1) \u0026#34;zz1\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;zz2\u0026#34; 4) \u0026#34;2\u0026#34; 5) \u0026#34;zz3\u0026#34; 6) \u0026#34;3\u0026#34; 127.0.0.1:6379[2]\u0026gt; zscan myzadd1 0 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;zz1\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;zz2\u0026#34; 4) \u0026#34;2\u0026#34; 5) \u0026#34;zz3\u0026#34; 6) \u0026#34;3\u0026#34; ","permalink":"https://Bin-lin-rgb.github.io/posts/tech/tech/","summary":"1. 介绍 scan命令的作用和keys *的作用类似，主要用于查找redis中的键，但是在正式的生产环境中一般不会直接使用keys *这个命令，因为他会返回所有的键，如果键的数量很多会导致查询时间很长，进而导致服务器阻塞，所以需要scan来进行更细致的查找 scan总共有这几种命令：sca","title":"Redis scan命令学习"},{"content":"前言 zap 的使用。\n安装 运行下面的命令安装zap\ngo get -u go.uber.org/zap 实现 logger.go 文件 先在 logger 下新建一个文件\n具体内容如下：\npackage Logger import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;go.uber.org/zap/zapcore\u0026#34; \u0026#34;gopkg.in/natefinch/lumberjack.v2\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httputil\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime/debug\u0026#34; \u0026#34;server/Config\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) var lg *zap.Logger // InitLogger 初始化Logger func InitLogger(cfg *Config.LogConfig) (err error) { writeSyncer := getLogWriter(cfg.Filename, cfg.MaxSize, cfg.MaxBackups, cfg.MaxAge) encoder := getEncoder() var l = new(zapcore.Level) err = l.UnmarshalText([]byte(cfg.Level)) if err != nil { return } core := zapcore.NewCore(encoder, writeSyncer, l) lg = zap.New(core, zap.AddCaller()) zap.ReplaceGlobals(lg) // 替换zap包中全局的logger实例，后续在其他包中只需使用zap.L()调用即可 return } func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.TimeKey = \u0026#34;time\u0026#34; encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder encoderConfig.EncodeDuration = zapcore.SecondsDurationEncoder encoderConfig.EncodeCaller = zapcore.ShortCallerEncoder return zapcore.NewJSONEncoder(encoderConfig) } func getLogWriter(filename string, maxSize, maxBackup, maxAge int) zapcore.WriteSyncer { lumberJackLogger := \u0026amp;lumberjack.Logger{ Filename: filename, MaxSize: maxSize, MaxBackups: maxBackup, MaxAge: maxAge, } return zapcore.AddSync(lumberJackLogger) } // GinLogger 接收gin框架默认的日志 func GinLogger() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() path := c.Request.URL.Path query := c.Request.URL.RawQuery c.Next() cost := time.Since(start) lg.Info(path, zap.Int(\u0026#34;status\u0026#34;, c.Writer.Status()), zap.String(\u0026#34;method\u0026#34;, c.Request.Method), zap.String(\u0026#34;path\u0026#34;, path), zap.String(\u0026#34;query\u0026#34;, query), zap.String(\u0026#34;ip\u0026#34;, c.ClientIP()), zap.String(\u0026#34;user-agent\u0026#34;, c.Request.UserAgent()), zap.String(\u0026#34;errors\u0026#34;, c.Errors.ByType(gin.ErrorTypePrivate).String()), zap.Duration(\u0026#34;cost\u0026#34;, cost), ) } } // GinRecovery recover掉项目可能出现的panic，并使用zap记录相关日志 func GinRecovery(stack bool) gin.HandlerFunc { return func(c *gin.Context) { defer func() { if err := recover(); err != nil { // Check for a broken connection, as it is not really a // condition that warrants a panic stack trace. var brokenPipe bool if ne, ok := err.(*net.OpError); ok { if se, ok := ne.Err.(*os.SyscallError); ok { if strings.Contains(strings.ToLower(se.Error()), \u0026#34;broken pipe\u0026#34;) || strings.Contains(strings.ToLower(se.Error()), \u0026#34;connection reset by peer\u0026#34;) { brokenPipe = true } } } httpRequest, _ := httputil.DumpRequest(c.Request, false) if brokenPipe { lg.Error(c.Request.URL.Path, zap.Any(\u0026#34;error\u0026#34;, err), zap.String(\u0026#34;request\u0026#34;, string(httpRequest)), ) // If the connection is dead, we can\u0026#39;t write a status to it. c.Error(err.(error)) // nolint: errcheck c.Abort() return } if stack { lg.Error(\u0026#34;[Recovery from panic]\u0026#34;, zap.Any(\u0026#34;error\u0026#34;, err), zap.String(\u0026#34;request\u0026#34;, string(httpRequest)), zap.String(\u0026#34;stack\u0026#34;, string(debug.Stack())), ) } else { lg.Error(\u0026#34;[Recovery from panic]\u0026#34;, zap.Any(\u0026#34;error\u0026#34;, err), zap.String(\u0026#34;request\u0026#34;, string(httpRequest)), ) } c.AbortWithStatus(http.StatusInternalServerError) } }() c.Next() } } 配置 新建一个 config.go 用来， 定义日志相关的配置， 具体内容如下：\npackage Config import ( \u0026#34;encoding/json\u0026#34; \u0026#34;io/ioutil\u0026#34; ) // Config 整个项目的配置 type Config struct { Mode string `json:\u0026#34;mode\u0026#34;` Port int `json:\u0026#34;port\u0026#34;` *LogConfig `json:\u0026#34;log\u0026#34;` } // LogConfig 日志配置 type LogConfig struct { Level string `json:\u0026#34;level\u0026#34;` Filename string `json:\u0026#34;filename\u0026#34;` MaxSize int `json:\u0026#34;maxsize\u0026#34;` MaxAge int `json:\u0026#34;max_age\u0026#34;` MaxBackups int `json:\u0026#34;max_backups\u0026#34;` } // Conf 全局配置变量 var Conf = new(Config) // Init 初始化配置；从指定文件加载配置文件 func Init(filePath string) error { b, err := ioutil.ReadFile(filePath) if err != nil { return err } return json.Unmarshal(b, Conf) } config.json\n{ \u0026#34;mode\u0026#34;: \u0026#34;debug\u0026#34;, \u0026#34;port\u0026#34;: 8080, \u0026#34;log\u0026#34;: { \u0026#34;level\u0026#34;: \u0026#34;debug\u0026#34;, \u0026#34;filename\u0026#34;: \u0026#34;app.log\u0026#34;, \u0026#34;maxsize\u0026#34;: 200, \u0026#34;max_age\u0026#34;: 7, \u0026#34;max_backups\u0026#34;: 10 } } 可以看到 在 config.json 中 的 filename 为 app.log ，是log 输出文件。\nmain.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;server/Config\u0026#34; \u0026#34;server/Logger\u0026#34; \u0026#34;server/Router\u0026#34; \u0026#34;server/pkg/snowflake\u0026#34; ) func main() { r := gin.Default() // load config from config.json if len(os.Args) \u0026lt; 1 { return } if err := Config.Init(os.Args[1]); err != nil { panic(err) } // init logger if err := Logger.InitLogger(Config.Conf.LogConfig); err != nil { fmt.Printf(\u0026#34;init logger failed, err:%v\\n\u0026#34;, err) return } gin.SetMode(Config.Conf.Mode) Router.Start(r) // 注册zap相关中间件 r.Use(Logger.GinLogger(), Logger.GinRecovery(true)) err := r.Run() if err != nil { log.Println(\u0026#34;r.Run() Failed!\u0026#34;) } } 在项目中先从配置文件加载配置信息，再调用logger.InitLogger(config.Conf.LogConfig)即可完成logger实例的初识化。其中，通过r.Use(logger.GinLogger(), logger.GinRecovery(true))注册我们的中间件来使用zap接收gin框架自身的日志，在项目中需要的地方通过使用zap.L().Xxx()方法来记录自定义日志信息。\n使用 比如这里：\n使用到了 zap.Error() .\n查看官方文档，还有其他的形式。 文档：https://pkg.go.dev/go.uber.org/zap\n常用的：\n[Debug] func (log *Logger) Debug(msg string, fields ...Field) Debug logs a message at DebugLevel. The message includes any fields passed at the log site, as well as any fields accumulated on the logger.\n[Error] func (log *Logger) Error(msg string, fields ...Field) Error logs a message at ErrorLevel. The message includes any fields passed at the log site, as well as any fields accumulated on the logger.\n[Fatal] func (log *Logger) Fatal(msg string, fields ...Field) Fatal logs a message at FatalLevel. The message includes any fields passed at the log site, as well as any fields accumulated on the logger.\nThe logger then calls os.Exit(1), even if logging at FatalLevel is disabled.\n[Info] func (log *Logger) Info(msg string, fields ...Field) Info logs a message at InfoLevel. The message includes any fields passed at the log site, as well as any fields accumulated on the logger.\n总结 日志是用来记录，用户操作，系统状态，错误信息等等内容的文件，是一个软件系统的重要组成部分。一个良好的日志规范，对于系统运行状态的分析，以及线上问题的解决具有重大的意义。\n重要功能日志尽可能的完善。 不要随意打印无用的日志，过多无用的日志会增加分析日志的难度。 日志要区分等级 如 debug，warn，info，error 等。 捕获到未处理错误时最好打印错误堆栈信息 ","permalink":"https://Bin-lin-rgb.github.io/posts/go/zap%E6%97%A5%E5%BF%97%E5%BA%93/","summary":"前言 zap 的使用。 安装 运行下面的命令安装zap go get -u go.uber.org/zap 实现 logger.go 文件 先在 logger 下新建一个文件 具体内容如下： package Logger import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;go.uber.org/zap/zapcore\u0026#34; \u0026#34;gopkg.in/natefinch/lumberjack.v2\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httputil\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime/debug\u0026#34; \u0026#34;server/Config\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) var lg *zap.Logger // InitLogger 初始化Logger func InitLogger(cfg *Config.LogConfig) (err error) { writeSyncer := getLogWriter(cfg.Filename, cfg.MaxSize, cfg.MaxBackups, cfg.MaxAge) encoder := getEncoder() var l = new(zapcore.Level) err = l.UnmarshalText([]byte(cfg.Level)) if err != nil { return } core := zapcore.NewCore(encoder, writeSyncer, l) lg = zap.New(core, zap.AddCaller()) zap.ReplaceGlobals(lg) // 替换zap包中全局的logger实例，后续在","title":"Zap日志库"},{"content":"gorm基础使用及解决部分疑惑 这是我参与「第三届青训营 -后端场」笔记创作活动的第4篇笔记。\n01 简介 本文主要介绍在项目中集成 gorm 的大致方法、一些错误的解决方法、规范包及目录。\n02 规范包及目录 这只是其中的一种分包方式，具体使用哪种可以根据自己需求。\ncontroller //处理函数 ​ dao //数据库相关，gorm相关接口 ​ router //路由 ​ model //生成数据表相关的结构体 ​ assets //静态资源 ​ templates //模板文件、HTML 03 集成gorm 这里分两种情况：\n如果还未建表，可以先声明结构体数据之后再使用 gorm 自动建表功能。 若已经建好表了，则可以使用一些便捷的网站快速生成相应的结构体，然后再根据实际需求更改（比如外键）。 1.自动建表 1、go get 一下\n我这里使用 mysql 所以执行go get -u gorm.io/driver/mysql.\n如果你们使用其他数据库可以参考gorm官方文档：GORM 指南 | GORM - The fantastic ORM library for Golang, aims to be developer friendly.\ngo get -u gorm.io/gorm go get -u gorm.io/driver/mysql 2、声明结构体\n在这一个案例中是还没有建表的。这里后面的字段不需要指定数据库列。后边使用 db.AutoMigrate(\u0026amp;model.User{}) 就可以自动建表\nmodel.go package model ​ import \u0026#34;gorm.io/gorm\u0026#34; ​ type User struct { gorm.Model Username string `json:\u0026#34;username\u0026#34;` Password string `json:\u0026#34;password\u0026#34;` } 在dsn记得换上自己的 数据库密码 。\ndao.go package dao ​ import ( \u0026#34;blog/model\u0026#34; \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;log\u0026#34; ) ​ type Manager interface { AddUser(user *model.User) } ​ type manager struct { db *gorm.DB } ​ func (mgr manager) AddUser(user *model.User) { mgr.db.Create(user) } ​ var Mgr Manager ​ func init() { // 在dsn记得换上自己的 数据库密码 dsn := \u0026#34;root:xxxxxx@tcp(127.0.0.1:3306)/golang_blog?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { log.Fatal(\u0026#34;Failed to init db:\u0026#34;, err) } Mgr = \u0026amp;manager{db: db} err1 := db.AutoMigrate(\u0026amp;model.User{}) if err1 != nil { log.Fatal(err1) } } main.go package main ​ import ( \u0026#34;blog/dao\u0026#34; \u0026#34;blog/model\u0026#34; ) ​ func main() { user := model.User{ Username: \u0026#34;tom\u0026#34;, Password: \u0026#34;123456\u0026#34;, } dao.Mgr.AddUser(\u0026amp;user) } 测试 测试AddUser是否成功\nmysql\u0026gt; use golang_blog Database changed mysql\u0026gt; show tables; +-----------------------+ | Tables_in_golang_blog | +-----------------------+ | users | +-----------------------+ 1 row in set (0.00 sec) ​ mysql\u0026gt; select * from users; +----+-------------------------+-------------------------+------------+----------+----------+ | id | created_at | updated_at | deleted_at | username | password | +----+-------------------------+-------------------------+------------+----------+----------+ | 1 | 2022-05-22 09:13:22.688 | 2022-05-22 09:13:22.688 | NULL | tom | 123456 | +----+-------------------------+-------------------------+------------+----------+----------+ 1 row in set (0.00 sec) 2.手动建表 这种情况先把SQL建表语句复制到这个网站：在线sql转go, json转go - 球儿工具 (qetool.com)\n然后就可以愉快根据需要转成相应的结构体。\nSQL转struct 1、Navicat 直接粘贴过来的 t_video 表的SQL :\nCREATE TABLE `t_video` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;视频id\u0026#39;, `author_id` int(11) NOT NULL COMMENT \u0026#39;作者id\u0026#39;, `play_url` varchar(512) NOT NULL COMMENT \u0026#39;视频播放地址\u0026#39;, `cover_url` varchar(255) NOT NULL COMMENT \u0026#39;视频封面地址\u0026#39;, `favorite_count` int(11) unsigned DEFAULT NULL COMMENT \u0026#39;视频的点赞总数\u0026#39;, `comment_count` int(11) unsigned DEFAULT NULL COMMENT \u0026#39;视频的评论总数\u0026#39;, `title` varchar(255) CHARACTER SET utf8 NOT NULL COMMENT \u0026#39;视频标题\u0026#39;, `created_at` datetime DEFAULT NULL COMMENT \u0026#39;投稿时间\u0026#39;, `deleted_at` datetime DEFAULT NULL COMMENT \u0026#39;删除时间\u0026#39;, `updated_at` datetime DEFAULT NULL COMMENT \u0026#39;更新时间\u0026#39;, `is_favorite` tinyint(1) DEFAULT NULL, PRIMARY KEY (`id`), KEY `author_id` (`author_id`), KEY `normal_favorite_count` (`favorite_count`) USING BTREE, CONSTRAINT `author_id` FOREIGN KEY (`author_id`) REFERENCES `t_userinfo` (`id`) ) 2、然后在网站勾选 json 、gorm ，就出现了：\ntype Video struct { ID int64 `gorm:\u0026#34;column:id\u0026#34; json:\u0026#34;id\u0026#34;` // 视频id AuthorId int64 `gorm:\u0026#34;column:author_id\u0026#34; json:\u0026#34;author_id\u0026#34;` // 作者id PlayUrl string `gorm:\u0026#34;column:play_url\u0026#34; json:\u0026#34;play_url\u0026#34;` // 视频播放地址 CoverUrl string `gorm:\u0026#34;column:cover_url\u0026#34; json:\u0026#34;cover_url\u0026#34;` // 视频封面地址 FavoriteCount int64 `gorm:\u0026#34;column:favorite_count\u0026#34; json:\u0026#34;favorite_count\u0026#34;` // 视频的点赞总数 CommentCount int64 `gorm:\u0026#34;column:comment_count\u0026#34; json:\u0026#34;comment_count\u0026#34;` // 视频的评论总数 Title string `gorm:\u0026#34;column:title\u0026#34; json:\u0026#34;title\u0026#34;` // 视频标题 CreatedAt time.Time `gorm:\u0026#34;column:created_at\u0026#34; json:\u0026#34;created_at\u0026#34;` // 投稿时间 DeletedAt time.Time `gorm:\u0026#34;column:deleted_at\u0026#34; json:\u0026#34;deleted_at\u0026#34;` // 删除时间 UpdatedAt time.Time `gorm:\u0026#34;column:updated_at\u0026#34; json:\u0026#34;updated_at\u0026#34;` // 更新时间 IsFavorite int64 `gorm:\u0026#34;column:is_favorite\u0026#34; json:\u0026#34;is_favorite\u0026#34;` } 3、修改\n比如这里的需求是 t_video 表中需要携带作者 userinfo 的数据。\n这里新增 Author Userinfo 连接 Userinfo 结构体，并声明 gorm 字段为 \u0026quot;foreignKey:AuthorId;\u0026quot; 。 把UpdatedAt、DeletedAt、CreatedAt字段删掉，新增 gorm.Model ，因为它自带这些参数。 type Video struct { gorm.Model ID int64 `gorm:\u0026#34;column:id\u0026#34; json:\u0026#34;id\u0026#34;` // 视频id Author Userinfo `json:\u0026#34;author\u0026#34; gorm:\u0026#34;foreignKey:AuthorId;\u0026#34;` // -新增- AuthorId int64 `gorm:\u0026#34;column:author_id\u0026#34; json:\u0026#34;author_id\u0026#34;` // 作者id PlayUrl string `gorm:\u0026#34;column:play_url\u0026#34; json:\u0026#34;play_url\u0026#34;` // 视频播放地址 CoverUrl string `gorm:\u0026#34;column:cover_url\u0026#34; json:\u0026#34;cover_url\u0026#34;` // 视频封面地址 FavoriteCount int64 `gorm:\u0026#34;column:favorite_count\u0026#34; json:\u0026#34;favorite_count\u0026#34;` // 视频的点赞总数 CommentCount int64 `gorm:\u0026#34;column:comment_count\u0026#34; json:\u0026#34;comment_count\u0026#34;` // 视频的评论总数 Title string `gorm:\u0026#34;column:title\u0026#34; json:\u0026#34;title\u0026#34;` // 视频标题 // CreatedAt time.Time `gorm:\u0026#34;column:created_at\u0026#34; json:\u0026#34;created_at\u0026#34;` // 投稿时间 // DeletedAt time.Time `gorm:\u0026#34;column:deleted_at\u0026#34; json:\u0026#34;deleted_at\u0026#34;` // 删除时间 // UpdatedAt time.Time `gorm:\u0026#34;column:updated_at\u0026#34; json:\u0026#34;updated_at\u0026#34;` // 更新时间 IsFavorite int64 `gorm:\u0026#34;column:is_favorite\u0026#34; json:\u0026#34;is_favorite\u0026#34;` } ​ 注意的问题 1、比如使用 Navicat 建表的表名是 t_video ，但是想关联的结构体名是 Video ， 那 gorm 怎么知道关联想要的东西呢？\n这里需要在连接数据库时进行一些配置，这里只需要使用前两个：\ndsn := \u0026#34;root:xxxxxx@tcp(127.0.0.1:3306)/golang_blog?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(\u0026#34;gorm.db\u0026#34;), \u0026amp;gorm.Config{ NamingStrategy: schema.NamingStrategy{ TablePrefix: \u0026#34;t_\u0026#34;, // table name prefix, table for `User` would be `t_users` SingularTable: true, // use singular table name, table for `User` would be `user` with this option enabled //NoLowerCase: true, // skip the snake_casing of names //NameReplacer: strings.NewReplacer(\u0026#34;CID\u0026#34;, \u0026#34;Cid\u0026#34;), // use name replacer to change struct/field name before convert it to db name }, }) 2、若需要的字段可能有中文，为了避免报错，建表时设置该字段的字符集为utf8，排序规则为utf8_general_ci。\n3.Preload 预加载 在上述嵌套的情况下，此时直接查询返回一个 video 是没有 Userinfo 的信息的，需要使用 Preload 。\nGORM 允许在 Preload 的其它 SQL 中直接加载关系。\n比如：直接链式添加 .Preload(\u0026quot;Author\u0026quot;) ：\nfunc (mgr manager) GetAllVideo(latestTime int64) ([]model.Video, error) { var videos []model.Video timeLayout := \u0026#34;2006-01-02 15:04:05\u0026#34; result := mgr.db.Model(\u0026amp;model.Video{}).Where(\u0026#34;created_at \u0026lt;= ?\u0026#34;, time.Unix(latestTime, 0).Format(timeLayout)). Order(\u0026#34;created_at DESC\u0026#34;).Preload(\u0026#34;Author\u0026#34;).Limit(30).Count(\u0026amp;count).Find(\u0026amp;videos) ​ return videos, result.Error } 04 总结 gorm使用下来是比较方便的orm工具，建议读者如果出问题了多看看官方文档。\n参考资料：\ngorm官方文档：GORM 指南 | GORM - The fantastic ORM library for Golang, aims to be developer friendly.\n","permalink":"https://Bin-lin-rgb.github.io/posts/go/golang%E9%9B%86%E6%88%90gorm/","summary":"gorm基础使用及解决部分疑惑 这是我参与「第三届青训营 -后端场」笔记创作活动的第4篇笔记。 01 简介 本文主要介绍在项目中集成 gorm 的大致方法、一些错误的解决方法、规范包及目录。 02 规范包及目录 这只是其中的一种分包方式，具体使用哪种可以根据自己需求。 controller //处理函数 ​ dao //数据库相关，gorm","title":"Golang集成gorm"},{"content":"运行准备 由于需要使用 FFmpeg 第三方工具来完成视频截取第一帧作为封面并存储到本机，\n所以运行之前需要预先安装 FFmpeg 到本机并配置好环境变量。\n我这里使用的是 ffmpeg version 5.0.1-full_build 版本。\n参考链接：FFmpeg\n项目结构 假设有这样一个案例：assets 文件夹中是专门存放视频的，现在的要求就是将该视频的第一帧截取为图片并保存。\nD:. │ go.mod │ go.sum │ ├─.idea │ .gitignore │ modules.xml │ testvideo.iml │ thriftCompiler.xml │ workspace.xml │ ├─assets │ test.mp4 │ └─controller main.go 主要是调用 GetSnapshot() 函数\n第一个参数是 视频的相对地址，第二个参数是截出来的图片的名称，返回值是图片的相对路径\nfunc GetSnapshot(videoPath, snapshotPath string) (snapshotName string, err error)\nmain.go package main ​ import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/disintegration/imaging\u0026#34; ffmpeg \u0026#34;github.com/u2takey/ffmpeg-go\u0026#34; ) ​ func GetSnapshot(videoPath, snapshotPath string, frameNum int) (snapshotName string, err error) { snapshotPath = \u0026#34;./assets/\u0026#34; + snapshotPath buf := bytes.NewBuffer(nil) err = ffmpeg.Input(videoPath). Filter(\u0026#34;select\u0026#34;, ffmpeg.Args{fmt.Sprintf(\u0026#34;gte(n,%d)\u0026#34;, frameNum)}). Output(\u0026#34;pipe:\u0026#34;, ffmpeg.KwArgs{\u0026#34;vframes\u0026#34;: 1, \u0026#34;format\u0026#34;: \u0026#34;image2\u0026#34;, \u0026#34;vcodec\u0026#34;: \u0026#34;mjpeg\u0026#34;}). WithOutput(buf, os.Stdout). Run() if err != nil { log.Fatal(\u0026#34;生成缩略图失败：\u0026#34;, err) return \u0026#34;\u0026#34;, err } ​ img, err := imaging.Decode(buf) if err != nil { log.Fatal(\u0026#34;生成缩略图失败：\u0026#34;, err) return \u0026#34;\u0026#34;, err } ​ err = imaging.Save(img, snapshotPath+\u0026#34;.png\u0026#34;) if err != nil { log.Fatal(\u0026#34;生成缩略图失败：\u0026#34;, err) return \u0026#34;\u0026#34;, err } ​ fmt.Println(\u0026#34;--snapshotPath--\u0026#34;, snapshotPath) // --snapshotPath-- ./assets/testImage ​ names := strings.Split(snapshotPath, \u0026#34;\\\u0026#34;) fmt.Println(\u0026#34;----names----\u0026#34;, names) // ----names---- [./assets/testImage] // 这里把 snapshotPath 的 string 类型转换成 []string ​ snapshotName = names[len(names)-1] + \u0026#34;.png\u0026#34; fmt.Println(\u0026#34;----snapshotName----\u0026#34;, snapshotName) // ----snapshotName---- ./assets/testImage.png ​ return snapshotName, nil } ​ func main() { name, err := GetSnapshot(\u0026#34;./assets/test.mp4\u0026#34;, \u0026#34;testImage\u0026#34;, 1) if err != nil { log.Fatal(err) return } fmt.Println(\u0026#34;return:\u0026#34;, name) } ​ 完成之后发现项目的 assets 已经多了一个 testImage.png 文件，说明已经成功了！\nD:. │ go.mod │ go.sum │ ├─.idea │ .gitignore │ modules.xml │ testvideo.iml │ thriftCompiler.xml │ workspace.xml │ ├─assets │ test.mp4 │ testImage.png │ └─controller main.go 解决方法 若生成失败，可能存在的问题：\n1、安装 FFmpeg 之后，没有配置环境变量。可以使用 cmd 输入 ffmpeg -version 验证是否配置成功。\n2、可以尝试以管理员身份运行 goland\n","permalink":"https://Bin-lin-rgb.github.io/posts/go/%E4%BD%BF%E7%94%A8ffmpeg/","summary":"运行准备 由于需要使用 FFmpeg 第三方工具来完成视频截取第一帧作为封面并存储到本机， 所以运行之前需要预先安装 FFmpeg 到本机并配置好环境变量。 我这里使用的是 ffmpeg version 5.0.1-full_build 版本。 参考链接：FFmpeg 项目结构 假设有这样一个案例：assets 文件夹中是专门存放视频的，现在的要求就是将该视频的第一帧截取为图片并","title":"使用 FFmpeg 截取视频第一帧并保存案例"},{"content":"omitempty 关键字 用法 熟悉 Golang 的朋友对于 json 和 struct 之间的转换一定不陌生，为了将代码中的结构体与 json 数据解耦，通常我们会在结构体的 field 类型后加上解释说明，例如在表示一个地址的时候， json 数据如下所示\n{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; } 与之相对应的 Golang 结构体表示定义如下\ntype address struct { Street string `json:\u0026#34;street\u0026#34;` // 街道 Ste string `json:\u0026#34;suite\u0026#34;` // 单元（可以不存在） City string `json:\u0026#34;city\u0026#34;` // 城市 State string `json:\u0026#34;state\u0026#34;` // 州/省 Zipcode string `json:\u0026#34;zipcode\u0026#34;` // 邮编 } 这样无论代码中的变量如何改变，我们都能成功将 json 数据解析出来，获得正确的街道，城市等信息，到目前为止一切正常。但如果我们想要将地址结构体恢复成 json 格式时，问题就来了。比方说我们用下面这段代码读取了地址 json ，然后根据业务逻辑处理了之后恢复成正常的 json 打印出来\nfunc main() { data := `{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; }` addr := new(address) json.Unmarshal([]byte(data), \u0026amp;addr) // 处理了一番 addr 变量... addressBytes, _ := json.MarshalIndent(addr, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;) fmt.Printf(\u0026#34;%s\\n\u0026#34;, string(addressBytes)) } 可以得到运行结果\n{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;suite\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; } 多了一行 \u0026quot;suite\u0026quot;: \u0026quot;\u0026quot;, ，而这则信息在原本的 json 数据中是没有的（在美国的地址中，如果不是群租公寓或者共享办公楼， suite 这一条不存在很正常，人们直接用街道门牌号来表示地址就足够了），但我们更希望的是，在一个地址有 suite 号码的时候输出，不存在 suite 的时候就不输出，幸运的是，我们可以在 Golang 的结构体定义中添加 omitempty 关键字，来表示这条信息如果没有提供，在序列化成 json 的时候就不要包含其默认值。稍作修改，地址结构体就变成了\ntype address struct { Street string `json:\u0026#34;street\u0026#34;` Ste string `json:\u0026#34;suite,omitempty\u0026#34;` City string `json:\u0026#34;city\u0026#34;` State string `json:\u0026#34;state\u0026#34;` Zipcode string `json:\u0026#34;zipcode\u0026#34;` } 重新运行，即可得到正确的结果。\n陷阱 带来方便的同时，使用 omitempty 也有些小陷阱，一个是该关键字无法忽略掉嵌套结构体。还是拿地址类型说事，这回我们想要往地址结构体中加一个新 field 来表示经纬度，如果缺乏相关的数据，暂时可以忽略。新的结构体定义如下所示\ntype address struct { Street string `json:\u0026#34;street\u0026#34;` Ste string `json:\u0026#34;suite,omitempty\u0026#34;` City string `json:\u0026#34;city\u0026#34;` State string `json:\u0026#34;state\u0026#34;` Zipcode string `json:\u0026#34;zipcode\u0026#34;` Coordinate coordinate `json:\u0026#34;coordinate,omitempty\u0026#34;` } type coordinate struct { Lat float64 `json:\u0026#34;latitude\u0026#34;` Lng float64 `json:\u0026#34;longitude\u0026#34;` } 读入原来的地址数据，处理后序列化输出，我们就会发现即使加上了 omitempty 关键字，输出的 json 还是带上了一个空的坐标信息\n{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34;, \u0026#34;coordinate\u0026#34;: { \u0026#34;latitude\u0026#34;: 0, \u0026#34;longitude\u0026#34;: 0 } } 为了达到我们想要的效果，可以把坐标定义为指针类型，这样 Golang 就能知道一个指针的“空值”是多少了，否则面对一个我们自定义的结构， Golang 是猜不出我们想要的空值的。于是有了如下的结构体定义\ntype address struct { Street string `json:\u0026#34;street\u0026#34;` Ste string `json:\u0026#34;suite,omitempty\u0026#34;` City string `json:\u0026#34;city\u0026#34;` State string `json:\u0026#34;state\u0026#34;` Zipcode string `json:\u0026#34;zipcode\u0026#34;` Coordinate *coordinate `json:\u0026#34;coordinate,omitempty\u0026#34;` } type coordinate struct { Lat float64 `json:\u0026#34;latitude\u0026#34;` Lng float64 `json:\u0026#34;longitude\u0026#34;` } 相应的输出为\n{ \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; } 另一个“陷阱”是，对于用 omitempty 定义的 field ，如果给它赋的值恰好等于默认空值的话，在转为 json 之后也不会输出这个 field 。比如说上面定义的经纬度坐标结构体，如果我们将经纬度两个 field 都加上 omitempty\ntype coordinate struct { Lat float64 `json:\u0026#34;latitude,omitempty\u0026#34;` Lng float64 `json:\u0026#34;longitude,omitempty\u0026#34;` } 然后我们对非洲几内亚湾的“原点坐标”非常感兴趣，于是编写了如下代码\nfunc main() { cData := `{ \u0026#34;latitude\u0026#34;: 0.0, \u0026#34;longitude\u0026#34;: 0.0 }` c := new(coordinate) json.Unmarshal([]byte(cData), \u0026amp;c) // 具体处理逻辑... coordinateBytes, _ := json.MarshalIndent(c, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;) fmt.Printf(\u0026#34;%s\\n\u0026#34;, string(coordinateBytes)) } 最终我们得到了一个\n{} 这个坐标消失不见了！但我们的设想是，如果一个地点没有经纬度信息，则悬空，这没有问题，但对于“原点坐标”，我们在确切知道它的经纬度的情况下，（0.0, 0.0）仍然被忽略了。正确的写法也是将结构体内的定义改为指针\ntype coordinate struct { Lat *float64 `json:\u0026#34;latitude,omitempty\u0026#34;` Lng *float64 `json:\u0026#34;longitude,omitempty\u0026#34;` } 这样空值就从 float64 的 0.0 变为了指针类型的 nil ，我们就能看到正确的经纬度输出。\n{ \u0026#34;latitude\u0026#34;: 0, \u0026#34;longitude\u0026#34;: 0 } ","permalink":"https://Bin-lin-rgb.github.io/posts/go/omitempty/","summary":"omitempty 关键字 用法 熟悉 Golang 的朋友对于 json 和 struct 之间的转换一定不陌生，为了将代码中的结构体与 json 数据解耦，通常我们会在结构体的 field 类型后加上解释说明，例如在表示一个地址的时候， json 数据如下所示 { \u0026#34;street\u0026#34;: \u0026#34;200 Larkin St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zipcode\u0026#34;: \u0026#34;94102\u0026#34; } 与之相对应的 Golang 结构体表示定义如下 type address struct { Street string `json:\u0026#34;street\u0026#34;` // 街道 Ste string `json:\u0026#34;suite\u0026#34;` // 单元（可以不存在） City string","title":"omitempty 关键字"},{"content":"","permalink":"https://Bin-lin-rgb.github.io/posts/life/life/","summary":"","title":"Life"},{"content":"\rBlaine\u0026#39;s Blog\r一个记录技术、阅读、生活的博客\r👉友链格式\r名称： Blaine\u0026rsquo;s Blog 网址： https://bin-lin-rgb.github.io/ 图标： https://bin-lin-rgb.github.io/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求\r秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内\n","permalink":"https://Bin-lin-rgb.github.io/links/","summary":"Blaine\u0026#39;s Blog 一个记录技术、阅读、生活的博客 👉友链格式 名称： Blaine\u0026rsquo;s Blog 网址： https://bin-lin-rgb.github.io/ 图标： https://bin-lin-rgb.github.io/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内","title":"🤝友链"},{"content":"关于我\n英文名: Blaine 职业: 程序员 运动: 跑步、乒乓球 ","permalink":"https://Bin-lin-rgb.github.io/about/","summary":"关于我 英文名: Blaine 职业: 程序员 运动: 跑步、乒乓球","title":"🙋🏻‍♂️关于"},{"content":"使用 hugo + GitHub Pages + twikoo 完成\n","permalink":"https://Bin-lin-rgb.github.io/posts/tech/blog/","summary":"使用 hugo + GitHub Pages + twikoo 完成","title":"Blog"}]